=== config.py ===
import os
from dotenv import load_dotenv

# 先載入 .env（如果你想用檔案管理環境變數）
load_dotenv()

# ComfyUI API endpoint
COMFYUI_API_URL = os.getenv("COMFYUI_API_URL", "http://127.0.0.1:8188")

# ComfyUI 的輸出資料夾（圖片產出路徑）
COMFYUI_OUTPUT_DIR = os.getenv(
    "COMFYUI_OUTPUT_DIR",
    r"D:\comfyui\ComfyUI_windows_portable\ComfyUI\output"
)

# 最終要搬到哪裡、供前端透過 /get_image 讀取
TARGET_DIR = os.getenv("TARGET_DIR", r"D:\大模型文生圖")

# 對外組成 image_url 的基底網址
EXTERNAL_URL = os.getenv(
    "EXTERNAL_URL",
    "https://api.picturesmagician.com"
)

# CORS 白名單（正式版建議不要是 "*"）
ALLOWED_ORIGINS = os.getenv("ALLOWED_ORIGINS", "*").split(",")

=== lora人物姿勢控制.py ===
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import shutil
import time
import uuid
import base64
import urllib.request
import websocket               # pip install websocket-client
from flask import Flask, request, jsonify, send_from_directory, make_response
from flask_cors import CORS

app = Flask(__name__)
CORS(app)

# -----------------------------------
# ComfyUI & 目錄設定
# -----------------------------------
server_address     = "127.0.0.1:8188"
comfyui_output_dir = r"D:\comfyui\ComfyUI_windows_portable\ComfyUI\output"

target_dir_text  = r"D:\大模型文生圖姿勢控制"
target_dir_image = r"D:\大模型圖生圖姿勢控制"
os.makedirs(target_dir_text, exist_ok=True)
os.makedirs(target_dir_image, exist_ok=True)

temp_dir = r"D:\大模型姿勢控制\temp_input"
os.makedirs(temp_dir, exist_ok=True)

EXTERNAL_API_URL = "https://pose-lora.picturesmagician.com"

# -----------------------------------
# Workflow JSON（文生模式）
# -----------------------------------
WORKFLOW_TEXT_BASE = r"""
{
  "1": { "class_type": "CheckpointLoaderSimple",
         "inputs": {"ckpt_name": "meinamix_v12Final.safetensors"} },
  "2": { "class_type": "CLIPTextEncode",
         "inputs": {"text": "example prompt", "clip": ["1", 1]} },
  "3": { "class_type": "CLIPTextEncode",
         "inputs": {"text": "bad hands...", "clip": ["1", 1]} },
  "4": {
    "class_type": "KSampler",
    "inputs": {
      "seed": 87,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "dpmpp_2m_sde",
      "scheduler": "karras",
      "denoise": 1,
      "model": ["1", 0],
      "positive": ["2", 0],
      "negative": ["3", 0],
      "latent_image": ["47", 0]
    }
  },
  "7": {
    "class_type": "SaveImage",
    "inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}
  },
  "8": {
    "class_type": "VAEDecode",
    "inputs": {"samples": ["4", 0], "vae": ["9", 0]}
  },
  "9": {
    "class_type": "VAELoader",
    "inputs": {"vae_name": "kl-f8-anime2.safetensors"}
  },
  "47": {
    "class_type": "EmptyLatentImage",
    "inputs": {"width": 512, "height": 512, "batch_size": 1}
  }
}
""".strip()

WORKFLOW_TEXT_CN = r"""
{
  "1": { "class_type": "CheckpointLoaderSimple",
         "inputs": {"ckpt_name": "meinamix_v12Final.safetensors"} },
  "2": { "class_type": "CLIPTextEncode",
         "inputs": {"text": "example prompt", "clip": ["1", 1]} },
  "3": { "class_type": "CLIPTextEncode",
         "inputs": {"text": "bad hands...", "clip": ["1", 1]} },
  "4": {
    "class_type": "KSampler",
    "inputs": {
      "seed": 87,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "dpmpp_2m_sde",
      "scheduler": "karras",
      "denoise": 1,
      "model": ["1", 0],
      "positive": ["23", 0],
      "negative": ["23", 1],
      "latent_image": ["47", 0]
    }
  },
  "7": {
    "class_type": "SaveImage",
    "inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}
  },
  "8": {
    "class_type": "VAEDecode",
    "inputs": {"samples": ["4", 0], "vae": ["9", 0]}
  },
  "9": {
    "class_type": "VAELoader",
    "inputs": {"vae_name": "kl-f8-anime2.safetensors"}
  },
  "17": {
    "class_type": "OpenposePreprocessor",
    "inputs": {
      "detect_hand": "enable",
      "detect_body": "enable",
      "detect_face": "disable",
      "resolution": 512,
      "scale_stick_for_xinsr_cn": "disable",
      "image": ["48", 0]
    }
  },
  "18": {
    "class_type": "ControlNetApplyAdvanced",
    "inputs": {
      "strength": 1.2,
      "start_percent": 0,
      "end_percent": 1,
      "positive": ["2", 0],
      "negative": ["3", 0],
      "control_net": ["19", 0],
      "image": ["17", 0],
      "vae": ["9", 0]
    }
  },
  "19": {
    "class_type": "ControlNetLoader",
    "inputs": {"control_net_name": "control_sd15_openpose.pth"}
  },
  "23": {
    "class_type": "ControlNetApplyAdvanced",
    "inputs": {
      "strength": 1.0,
      "start_percent": 0,
      "end_percent": 1,
      "positive": ["18", 0],
      "negative": ["18", 1],
      "control_net": ["24", 0],
      "image": ["28", 0],
      "vae": ["9", 0]
    }
  },
  "24": {
    "class_type": "ControlNetLoader",
    "inputs": {"control_net_name": "control_sd15_depth.pth"}
  },
  "28": {
    "class_type": "MiDaS-DepthMapPreprocessor",
    "inputs": {
      "a": 0,
      "bg_threshold": 0.1,
      "resolution": 512,
      "image": ["50", 0]
    }
  },
  "48": {
    "class_type": "ZwngLoadImagePathOrURL",
    "inputs": {"image_path": "C:\\dummy_pose.png"}
  },
  "50": {
    "class_type": "ZwngLoadImagePathOrURL",
    "inputs": {"image_path": "C:\\dummy_pose.png"}
  },
  "47": {
    "class_type": "EmptyLatentImage",
    "inputs": {"width": 512, "height": 512, "batch_size": 1}
  }
}
""".strip()

# -----------------------------------
# 工作流程 JSON（圖生模式 - 無 ControlNet / 有 ControlNet）
# TEXT 模式用 47 為 latent；IMAGE 模式改用 37 為 VAEEncode latent
# -----------------------------------
WORKFLOW_IMAGE_BASE = r"""
{
  "1": { "class_type": "CheckpointLoaderSimple",
         "inputs": {"ckpt_name": "meinamix_v12Final.safetensors"} },
  "2": { "class_type": "CLIPTextEncode",
         "inputs": {"text": "example prompt", "clip": ["1", 1]} },
  "3": { "class_type": "CLIPTextEncode",
         "inputs": {"text": "bad hands...", "clip": ["1", 1]} },
  "4": {
    "class_type": "KSampler",
    "inputs": {
      "seed": 87,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "dpmpp_2m_sde",
      "scheduler": "karras",
      "denoise": 1,
      "model": ["1", 0],
      "positive": ["2", 0],
      "negative": ["3", 0],
      "latent_image": ["37", 0]
    }
  },
  "7": {
    "class_type": "SaveImage",
    "inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}
  },
  "8": {
    "class_type": "VAEDecode",
    "inputs": {"samples": ["4", 0], "vae": ["9", 0]}
  },
  "9": {
    "class_type": "VAELoader",
    "inputs": {"vae_name": "kl-f8-anime2.safetensors"}
  },
  "37": {
    "class_type": "VAEEncode",
    "inputs": {"pixels": ["47", 0], "vae": ["9", 0]}
  },
  "47": {
    "class_type": "ZwngLoadImagePathOrURL",
    "inputs": {"image_path": "C:\\dummy_main.png"}
  }
}
""".strip()

WORKFLOW_IMAGE_CN = r"""
{
  "1": { "class_type": "CheckpointLoaderSimple",
         "inputs": {"ckpt_name": "meinamix_v12Final.safetensors"} },
  "2": { "class_type": "CLIPTextEncode",
         "inputs": {"text": "example prompt", "clip": ["1", 1]} },
  "3": { "class_type": "CLIPTextEncode",
         "inputs": {"text": "bad hands...", "clip": ["1", 1]} },
  "4": {
    "class_type": "KSampler",
    "inputs": {
      "seed": 87,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "dpmpp_2m_sde",
      "scheduler": "karras",
      "denoise": 1,
      "model": ["1", 0],
      "positive": ["23", 0],
      "negative": ["23", 1],
      "latent_image": ["37", 0]
    }
  },
  "7": {
    "class_type": "SaveImage",
    "inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}
  },
  "8": {
    "class_type": "VAEDecode",
    "inputs": {"samples": ["4", 0], "vae": ["9", 0]}
  },
  "9": {
    "class_type": "VAELoader",
    "inputs": {"vae_name": "kl-f8-anime2.safetensors"}
  },
  "17": {
    "class_type": "OpenposePreprocessor",
    "inputs": {
      "detect_hand": "enable",
      "detect_body": "enable",
      "detect_face": "disable",
      "resolution": 512,
      "scale_stick_for_xinsr_cn": "disable",
      "image": ["49", 0]
    }
  },
  "18": {
    "class_type": "ControlNetApplyAdvanced",
    "inputs": {
      "strength": 1.2,
      "start_percent": 0,
      "end_percent": 1,
      "positive": ["2", 0],
      "negative": ["3", 0],
      "control_net": ["19", 0],
      "image": ["17", 0],
      "vae": ["9", 0]
    }
  },
  "19": {
    "class_type": "ControlNetLoader",
    "inputs": {"control_net_name": "control_sd15_openpose.pth"}
  },
  "23": {
    "class_type": "ControlNetApplyAdvanced",
    "inputs": {
      "strength": 1.0,
      "start_percent": 0,
      "end_percent": 1,
      "positive": ["18", 0],
      "negative": ["18", 1],
      "control_net": ["24", 0],
      "image": ["28", 0],
      "vae": ["9", 0]
    }
  },
  "24": {
    "class_type": "ControlNetLoader",
    "inputs": {"control_net_name": "control_sd15_depth.pth"}
  },
  "28": {
    "class_type": "MiDaS-DepthMapPreprocessor",
    "inputs": {
      "a": 0,
      "bg_threshold": 0.1,
      "resolution": 512,
      "image": ["50", 0]
    }
  },
  "37": {
    "class_type": "VAEEncode",
    "inputs": {"pixels": ["47", 0], "vae": ["9", 0]}
  },
  "47": {
    "class_type": "ZwngLoadImagePathOrURL",
    "inputs": {"image_path": "C:\\dummy_main.png"}
  },
  "49": {
    "class_type": "ZwngLoadImagePathOrURL",
    "inputs": {"image_path": "C:\\dummy_pose.png"}
  },
  "50": {
    "class_type": "ZwngLoadImagePathOrURL",
    "inputs": {"image_path": "C:\\dummy_pose.png"}
  }
}
""".strip()
# -----------------------------------
# Helper functions
# -----------------------------------
def queue_prompt(wf):
    client_id = str(uuid.uuid4())
    payload = {"prompt": wf, "client_id": client_id}
    data = json.dumps(payload).encode("utf-8")
    req = urllib.request.Request(f"http://{server_address}/prompt", data=data,
                                 headers={"Content-Type":"application/json"})
    with urllib.request.urlopen(req, timeout=60) as resp:
        result = json.loads(resp.read().decode("utf-8"))
        result["client_id"] = client_id
        return result

def wait_for_completion(prompt_id, client_id):
    ws = websocket.create_connection(f"ws://{server_address}/ws?clientId={client_id}", timeout=60)
    while True:
        msg = ws.recv()
        m = json.loads(msg) if isinstance(msg, str) else {}
        if m.get("type")=="executing":
            d = m.get("data",{})
            if d.get("prompt_id")==prompt_id and d.get("node") is None:
                break
    ws.close()

def move_output_files(prompt_id, target_folder):
    pngs = [f for f in os.listdir(comfyui_output_dir) if f.startswith("ComfyUI_") and f.endswith(".png")]
    if not pngs:
        return None
    pngs.sort(key=lambda fn: os.path.getmtime(os.path.join(comfyui_output_dir, fn)), reverse=True)
    src = os.path.join(comfyui_output_dir, pngs[0])
    dst = os.path.join(target_folder, pngs[0])
    shutil.move(src, dst)
    return pngs[0]

def apply_controlnet_params_text_cn(wf, cn):
    # 姿勢
    if "17" in wf:
        for k in ("detect_hand","detect_body","detect_face"):
            wf["17"]["inputs"][k] = cn.get(k, wf["17"]["inputs"].get(k))
    if "18" in wf:
        wf["18"]["inputs"]["strength"]      = cn.get("strength", wf["18"]["inputs"]["strength"])
        wf["18"]["inputs"]["start_percent"] = cn.get("start_percent", wf["18"]["inputs"]["start_percent"])
        wf["18"]["inputs"]["end_percent"]   = cn.get("end_percent", wf["18"]["inputs"]["end_percent"])
    # 深度
    if "28" in wf:
        wf["28"]["inputs"]["a"]            = cn.get("depth_angle", wf["28"]["inputs"]["a"])
        wf["28"]["inputs"]["bg_threshold"] = cn.get("depth_background", wf["28"]["inputs"]["bg_threshold"])
    if "23" in wf:
        wf["23"]["inputs"]["strength"]      = cn.get("depth_strength", wf["23"]["inputs"]["strength"])
        wf["23"]["inputs"]["start_percent"] = cn.get("depth_start_percent", wf["23"]["inputs"]["start_percent"])
        wf["23"]["inputs"]["end_percent"]   = cn.get("depth_end_percent", wf["23"]["inputs"]["end_percent"])

def apply_controlnet_params_image_cn(wf, cn):
    if "17" in wf:
        for k in ("detect_hand","detect_body","detect_face"):
            wf["17"]["inputs"][k] = cn.get(k, wf["17"]["inputs"].get(k))
    if "18" in wf:
        wf["18"]["inputs"]["strength"]      = cn.get("strength", wf["18"]["inputs"]["strength"])
        wf["18"]["inputs"]["start_percent"] = cn.get("start_percent", wf["18"]["inputs"]["start_percent"])
        wf["18"]["inputs"]["end_percent"]   = cn.get("end_percent", wf["18"]["inputs"]["end_percent"])
    # 深度
    if "28" in wf:
        wf["28"]["inputs"]["a"]            = cn.get("depth_angle", wf["28"]["inputs"]["a"])
        wf["28"]["inputs"]["bg_threshold"] = cn.get("depth_background", wf["28"]["inputs"]["bg_threshold"])
    if "23" in wf:
        wf["23"]["inputs"]["strength"]      = cn.get("depth_strength", wf["23"]["inputs"]["strength"])
        wf["23"]["inputs"]["start_percent"] = cn.get("depth_start_percent", wf["23"]["inputs"]["start_percent"])
        wf["23"]["inputs"]["end_percent"]   = cn.get("depth_end_percent", wf["23"]["inputs"]["end_percent"])


# ----------------------------
# 文生模式 Endpoint
# ----------------------------
@app.route("/pose_control_text", methods=["POST"])
def pose_control_text():
    data = request.get_json()
    if not data or "prompt" not in data:
        return jsonify({"error":"缺少 prompt"}), 400

    # 列印接收的參數
    expected = ["prompt","vae_name","checkpoint_name","cfg_scale","sampler",
                "scheduler","denoise_strength","seed","pose_image",
                "lora_name","strength_model","strength_clip","control_net_params"]
    received = {k: data.get(k) for k in expected if k in data}
    print("=== Received Params (Text Mode) ===")
    for k,v in received.items():
        print(f"{k}: {v}")
    print("===================================")

    # 取基本參數
    prompt_text = data["prompt"].strip()
    cfg_scale   = int(data.get("cfg_scale",7))
    sampler     = data.get("sampler","euler")
    scheduler   = data.get("scheduler","normal")
    seed        = int(data.get("seed",0))
    pose_b64    = data.get("pose_image","").strip()
    cn_params   = data.get("control_net_params",{})

    # 選 Workflow
    wf_str = WORKFLOW_TEXT_CN if pose_b64 else WORKFLOW_TEXT_BASE
    wf = json.loads(wf_str)

    # 動態切換 ckpt & vae
    if data.get("checkpoint_name"):
        wf["1"]["inputs"]["ckpt_name"] = data["checkpoint_name"]
    if data.get("vae_name"):
        wf["9"]["inputs"]["vae_name"] = data["vae_name"]

    # 動態套用 LoRA
    lora = data.get("lora_name")
    if lora:
        sm = float(data.get("strength_model",1.0))
        sc = float(data.get("strength_clip",1.0))
        for nid,node in wf.items():
            if node.get("class_type")=="LoraLoader":
                node["inputs"]["lora_name"]      = lora
                node["inputs"]["strength_model"] = sm
                node["inputs"]["strength_clip"]  = sc

    # 填 prompt & sampler 參數
    wf["2"]["inputs"]["text"]         = prompt_text
    wf["4"]["inputs"]["cfg"]          = cfg_scale
    wf["4"]["inputs"]["sampler_name"] = sampler
    wf["4"]["inputs"]["scheduler"]    = scheduler
    wf["4"]["inputs"]["seed"]         = seed

    # 注入姿勢圖
    if pose_b64:
        _,enc = pose_b64.split(",",1)
        fn = f"pose_{uuid.uuid4().hex}.png"
        path = os.path.join(temp_dir,fn)
        with open(path,"wb") as f:
            f.write(base64.b64decode(enc))
        wf["48"]["inputs"]["image_path"] = path
        wf["50"]["inputs"]["image_path"] = path
        apply_controlnet_params_text_cn(wf,cn_params)

    # 送出
    resp = queue_prompt(wf)
    if not resp or "prompt_id" not in resp:
        return jsonify({"error":"ComfyUI 無回應"}),500
    pid,cid = resp["prompt_id"], resp["client_id"]
    wait_for_completion(pid,cid)

    new_fn = move_output_files(pid, target_dir_text)
    if not new_fn:
        return jsonify({"error":"搬移檔案失敗"}),500
    url = f"{EXTERNAL_API_URL}/get_image/{new_fn}?t={int(time.time())}"
    return jsonify({"image_url":url})

# ----------------------------
# 圖生模式 Endpoint
# ----------------------------
@app.route("/pose_control_image", methods=["POST"])
def pose_control_image():
    data = request.get_json()
    if not data or "prompt" not in data or "image" not in data:
        return jsonify({"error":"缺少 prompt 或 image"}),400

    # 列印接收的參數
    expected = ["prompt","vae_name","checkpoint_name","cfg_scale","sampler",
                "scheduler","denoise_strength","seed","image","pose_image",
                "lora_name","strength_model","strength_clip","control_net_params"]
    received = {k: data.get(k) for k in expected if k in data}
    print("=== Received Params (Image Mode) ===")
    for k,v in received.items():
        print(f"{k}: {v}")
    print("====================================")

    # 基本
    prompt_text = data["prompt"].strip()
    main_b64    = data["image"].strip()
    cfg_scale   = int(data.get("cfg_scale",7))
    sampler     = data.get("sampler","euler")
    scheduler   = data.get("scheduler","normal")
    seed        = int(data.get("seed",0))
    pose_b64    = data.get("pose_image","").strip()
    cn_params   = data.get("control_net_params",{})

    wf_str = WORKFLOW_IMAGE_CN if pose_b64 else WORKFLOW_IMAGE_BASE
    wf = json.loads(wf_str)

    # 切換 ckpt & vae
    if data.get("checkpoint_name"):
        wf["1"]["inputs"]["ckpt_name"] = data["checkpoint_name"]
    if data.get("vae_name"):
        wf["9"]["inputs"]["vae_name"] = data["vae_name"]

    # LoRA
    lora = data.get("lora_name")
    if lora:
        sm = float(data.get("strength_model",1.0))
        sc = float(data.get("strength_clip",1.0))
        for nid,node in wf.items():
            if node.get("class_type")=="LoraLoader":
                node["inputs"]["lora_name"]      = lora
                node["inputs"]["strength_model"] = sm
                node["inputs"]["strength_clip"]  = sc

    # 填 prompt & sampler
    wf["2"]["inputs"]["text"]         = prompt_text
    wf["4"]["inputs"]["cfg"]          = cfg_scale
    wf["4"]["inputs"]["sampler_name"] = sampler
    wf["4"]["inputs"]["scheduler"]    = scheduler
    wf["4"]["inputs"]["seed"]         = seed

    # 解碼主圖
    _,enc = main_b64.split(",",1)
    fn = f"main_{uuid.uuid4().hex}.png"
    path = os.path.join(temp_dir,fn)
    with open(path,"wb") as f:
        f.write(base64.b64decode(enc))
    wf["47"]["inputs"]["image_path"] = path

    # 注入姿勢
    if pose_b64:
        _,enc2 = pose_b64.split(",",1)
        fn2 = f"pose_{uuid.uuid4().hex}.png"
        path2 = os.path.join(temp_dir,fn2)
        with open(path2,"wb") as f:
            f.write(base64.b64decode(enc2))
        wf["49"]["inputs"]["image_path"] = path2
        wf["50"]["inputs"]["image_path"] = path2
        apply_controlnet_params_image_cn(wf,cn_params)

    resp = queue_prompt(wf)
    if not resp or "prompt_id" not in resp:
        return jsonify({"error":"ComfyUI 無回應"}),500
    pid,cid = resp["prompt_id"], resp["client_id"]
    wait_for_completion(pid,cid)

    new_fn = move_output_files(pid, target_dir_image)
    if not new_fn:
        return jsonify({"error":"搬移檔案失敗"}),500
    url = f"{EXTERNAL_API_URL}/get_image/{new_fn}?t={int(time.time())}"
    return jsonify({"image_url":url})

# ----------------------------
# 取圖 Proxy
# ----------------------------
@app.route("/get_image/<path:filename>", methods=["GET"])
def get_image(filename):
    t = os.path.join(target_dir_text, filename)
    i = os.path.join(target_dir_image, filename)
    if os.path.exists(t):
        resp = make_response(send_from_directory(target_dir_text, filename))
    elif os.path.exists(i):
        resp = make_response(send_from_directory(target_dir_image, filename))
    else:
        return jsonify({"error":"檔案不存在"}),404
    resp.headers["Cache-Control"] = "no-store, no-cache, must-revalidate, max-age=0"
    resp.headers["Pragma"]        = "no-cache"
    return resp

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5015, debug=False)


=== lora創意繪畫.py ===
import json
import os
import shutil
import time
import uuid
import websocket  # pip install websocket-client
import urllib.request
import urllib.error
import base64
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from werkzeug.utils import secure_filename

app = Flask(__name__)
CORS(app)

# ================================
# ComfyUI & 檔案資料夾設定
# ================================
server_address     = "127.0.0.1:8188"  # ComfyUI 伺服器位址
comfyui_output_dir = r"D:\comfyui\ComfyUI_windows_portable\ComfyUI\output"
target_dir         = r"D:\大模型創意繪畫\output"
temp_input_dir     = r"D:\大模型創意繪畫\temp_input"

# 確保資料夾存在
os.makedirs(target_dir, exist_ok=True)
os.makedirs(temp_input_dir, exist_ok=True)

# 外網域名，用於回傳最終圖片連結
EXTERNAL_URL = "https://draw-lora.picturesmagician.com"

# ================================
# 與 ComfyUI 溝通的輔助函式
# ================================
def queue_prompt(workflow):
    client_id = str(uuid.uuid4())
    payload   = {"prompt": workflow, "client_id": client_id}
    data      = json.dumps(payload).encode("utf-8")
    url       = f"http://{server_address}/prompt"
    try:
        req = urllib.request.Request(url, data=data, headers={"Content-Type": "application/json"})
        with urllib.request.urlopen(req) as resp:
            result = json.loads(resp.read())
            result["client_id"] = client_id
            return result
    except urllib.error.HTTPError as e:
        body = e.read().decode()
        print(f"❌ HTTPError {e.code}: {body}")
        return None
    except Exception as e:
        print(f"❌ 無法連線至 ComfyUI API: {e}")
        return None

def wait_for_completion(prompt_id, client_id):
    ws_url = f"ws://{server_address}/ws?clientId={client_id}"
    try:
        ws = websocket.create_connection(ws_url)
        while True:
            raw = ws.recv()
            if isinstance(raw, bytes):
                try:
                    raw = raw.decode("utf-8")
                except UnicodeDecodeError:
                    continue
            if not isinstance(raw, str):
                continue
            msg = json.loads(raw)
            if msg.get("type") == "executing":
                data = msg.get("data", {})
                if data.get("node") is None and data.get("prompt_id") == prompt_id:
                    break
        ws.close()
    except Exception as e:
        print(f"❌ WebSocket 監聽錯誤: {e}")

def get_history(prompt_id):
    try:
        url = f"http://{server_address}/history/{prompt_id}"
        with urllib.request.urlopen(url) as resp:
            return json.loads(resp.read()).get(prompt_id, {})
    except Exception:
        return {}

def find_latest_png():
    pngs = [f for f in os.listdir(comfyui_output_dir) if f.lower().endswith(".png")]
    return max(pngs, key=lambda f: os.path.getctime(os.path.join(comfyui_output_dir, f))) if pngs else None

def get_final_image_filename(prompt_id):
    hist = get_history(prompt_id)
    for info in hist.get("outputs", {}).get("7", {}).get("images", []):
        fn = info.get("filename")
        if fn and fn.lower().endswith(".png"):
            return fn
    return find_latest_png()

def move_output_files(prompt_id):
    fn = get_final_image_filename(prompt_id)
    if not fn:
        return None
    src = os.path.join(comfyui_output_dir, fn)
    dst = os.path.join(target_dir, fn)
    if os.path.exists(src):
        shutil.move(src, dst)
        return fn
    return None

# ================================
# 創意繪畫 API Endpoint
# ================================
@app.route("/convert-image", methods=["POST"])
def convert_image_endpoint():
    data = request.get_json(force=True)
    print("▶ Received payload:", json.dumps(data, ensure_ascii=False))

    # 驗證必填
    if not data or "image" not in data:
        return jsonify({"error": "未提供圖像資料"}), 400

    # 解析 Base64 圖像並儲存
    try:
        header, encoded = data["image"].split(",", 1)
        file_ext = "jpg" if "jpeg" in header or "jpg" in header else "png"
        file_bytes = base64.b64decode(encoded)
    except Exception as e:
        return jsonify({"error": "圖像解析失敗", "details": str(e)}), 400

    fname            = f"upload_{uuid.uuid4().hex}.{file_ext}"
    input_path       = os.path.join(temp_input_dir, secure_filename(fname))
    with open(input_path, "wb") as f:
        f.write(file_bytes)
    print(f"✅ 已儲存繪製圖像：{input_path}")

    # 讀取並轉型參數
    cfg_scale        = int(data.get("cfgScale", 7))
    sampler_name     = data.get("samplerName", "euler")
    scheduler        = data.get("scheduler", "normal")
    denoise_strength = float(data.get("denoiseStrength", 0.7))
    vae_name         = data.get("vaeName", "kl-f8-anime2.safetensors")
    ckpt_name        = data.get("checkpointName", "meinamix_v12Final.safetensors")
    seed_val         = data.get("seed", "")
    prompt_text      = data.get("prompt", "").strip()
    lora_name        = data.get("loraName", "").strip()
    strength_model   = float(data.get("loraStrengthModel", 0.0))
    strength_clip    = float(data.get("loraStrengthClip", 1.0))

    try:
        seed = int(seed_val) if seed_val else int(uuid.uuid4().int % 1000000)
    except:
        seed = int(uuid.uuid4().int % 1000000)

    # 美化列印
    print("🔹 前端參數：")
    print(f"  • Checkpoint 名稱    : {ckpt_name}")
    print(f"  • VAE 名稱           : {vae_name}")
    print(f"  • CFG 強度           : {cfg_scale}")
    print(f"  • 採樣器             : {sampler_name}")
    print(f"  • 調度器             : {scheduler}")
    print(f"  • 去躁幅度           : {denoise_strength}")
    print(f"  • 隨機種子           : {seed}")
    print(f"  • 提示詞             : {prompt_text}")
    print(f"  • LoRA 名稱          : {lora_name}")
    print(f"  • LoRA 強度 (Model)  : {strength_model}")
    print(f"  • LoRA 強度 (CLIP)   : {strength_clip}")

    # ================================
    # ComfyUI Workflow JSON (含 LoRA 節點) :contentReference[oaicite:0]{index=0}:contentReference[oaicite:1]{index=1}
    # ================================
    workflow_template = r"""
{
  "1":  {"inputs":{"ckpt_name":"meinamix_v12Final.safetensors"},"class_type":"CheckpointLoaderSimple"},
  "2":  {"inputs":{"text":"","clip":["15",1]},"class_type":"CLIPTextEncode"},
  "3":  {"inputs":{"text":"","clip":["15",1]},"class_type":"CLIPTextEncode"},
  "4":  {"inputs":{
           "seed":0,"steps":20,"cfg":7,
           "sampler_name":"euler","scheduler":"normal",
           "denoise":0.7,
           "model":["15",0],
           "positive":["2",0],"negative":["3",0],
           "latent_image":["14",0]
         },"class_type":"KSampler"},
  "7":  {"inputs":{"filename_prefix":"ComfyUI","images":["8",0]},"class_type":"SaveImage"},
  "8":  {"inputs":{"samples":["4",0],"vae":["9",0]},"class_type":"VAEDecode"},
  "9":  {"inputs":{"vae_name":"kl-f8-anime2.safetensors"},"class_type":"VAELoader"},
  "13": {"inputs":{"pixels":["16",0],"vae":["9",0]},"class_type":"VAEEncode"},
  "14": {"inputs":{
           "upscale_method":"nearest-exact",
           "width":512,"height":512,"crop":"disabled",
           "samples":["13",0]
         },"class_type":"LatentUpscale"},
  "15": {"inputs":{
           "lora_name":"super-vanilla-newlora-ver1-p.safetensors",
           "strength_model":0,"strength_clip":1,
           "model":["1",0],"clip":["1",1]
         },"class_type":"LoraLoader"},
  "16": {"inputs":{"image_path":""},"class_type":"ZwngLoadImagePathOrURL"}
}
""".strip()

    workflow = json.loads(workflow_template)
    # 動態填值
    workflow["1"]["inputs"]["ckpt_name"]       = ckpt_name
    workflow["9"]["inputs"]["vae_name"]        = vae_name
    workflow["2"]["inputs"]["text"]            = prompt_text
    workflow["3"]["inputs"]["text"]            = ""  # 可修改為負向提示
    workflow["4"]["inputs"]["seed"]            = seed
    workflow["4"]["inputs"]["cfg"]             = cfg_scale
    workflow["4"]["inputs"]["sampler_name"]    = sampler_name
    workflow["4"]["inputs"]["scheduler"]       = scheduler
    workflow["4"]["inputs"]["denoise"]         = denoise_strength
    workflow["16"]["inputs"]["image_path"]     = input_path.replace("\\", "/")
    workflow["15"]["inputs"]["lora_name"]      = lora_name
    workflow["15"]["inputs"]["strength_model"] = strength_model
    workflow["15"]["inputs"]["strength_clip"]  = strength_clip

    # 發送、等待、搬檔、回傳
    resp = queue_prompt(workflow)
    if not resp or "prompt_id" not in resp:
        return jsonify({"error": "ComfyUI 回應錯誤"}), 500

    prompt_id = resp["prompt_id"]
    client_id = resp["client_id"]
    wait_for_completion(prompt_id, client_id)
    time.sleep(2)

    fn = move_output_files(prompt_id)
    if not fn:
        return jsonify({"error": "圖片搬移失敗"}), 500

    url = f"{EXTERNAL_URL}/get_image/{fn}?t={int(time.time())}"
    return jsonify({"image_url": url})

# ================================
# 靜態路由：對外提供已搬移圖片
# ================================
@app.route("/get_image/<filename>", methods=["GET"])
def get_image(filename):
    return send_from_directory(target_dir, filename)

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5014, debug=False)


=== lora圖生圖.py ===
import json
import os
import shutil
import time
import uuid
import websocket  # pip install websocket-client
import urllib.request
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from werkzeug.utils import secure_filename

app = Flask(__name__)
CORS(app)

# ================================
# ComfyUI 及資料夾設定
# ================================
SERVER_ADDR       = "127.0.0.1:8188"
COMFYUI_OUT_DIR   = r"D:\comfyui\ComfyUI_windows_portable\ComfyUI\output"
TARGET_DIR        = r"D:\大模型圖生圖"
TEMP_INPUT_DIR    = r"D:\大模型圖生圖\temp_input"
EXTERNAL_BASE_URL = "https://image.picturesmagician.com"

os.makedirs(TARGET_DIR, exist_ok=True)
os.makedirs(TEMP_INPUT_DIR, exist_ok=True)

# ================================
# 與 ComfyUI 互動：queue prompt
# ================================
def queue_prompt(prompt):
    client_id = str(uuid.uuid4())
    payload   = {"prompt": prompt, "client_id": client_id}
    data      = json.dumps(payload).encode("utf-8")
    url       = f"http://{SERVER_ADDR}/prompt"
    try:
        req = urllib.request.Request(url, data=data, headers={"Content-Type": "application/json"})
        with urllib.request.urlopen(req) as resp:
            result = json.loads(resp.read())
            result["client_id"] = client_id
            return result
    except Exception as e:
        print(f"❌ 無法連線至 ComfyUI API: {e}")
        return None

# ================================
# 等待 ComfyUI 完成：處理非 UTF-8 frame
# ================================
def wait_for_completion(prompt_id, client_id):
    ws_url = f"ws://{SERVER_ADDR}/ws?clientId={client_id}"
    try:
        ws = websocket.create_connection(ws_url)
        while True:
            raw = ws.recv()
            # 若為 bytes，嘗試 UTF-8 解碼，失敗則跳過
            if isinstance(raw, bytes):
                try:
                    raw = raw.decode("utf-8")
                except UnicodeDecodeError:
                    continue
            if not isinstance(raw, str):
                continue
            msg = json.loads(raw)
            if msg.get("type") == "executing":
                data = msg.get("data", {})
                if data.get("node") is None and data.get("prompt_id") == prompt_id:
                    break
        ws.close()
    except Exception as e:
        # 只印出非解碼問題的錯誤
        print(f"❌ WebSocket 監聽錯誤: {e}")

# ================================
# Helpers: history & file moves
# ================================
def get_history(prompt_id):
    try:
        url = f"http://{SERVER_ADDR}/history/{prompt_id}"
        with urllib.request.urlopen(url) as resp:
            hist = json.loads(resp.read())
        return hist.get(prompt_id, {})
    except:
        return {}

def find_latest_png():
    pngs = [f for f in os.listdir(COMFYUI_OUT_DIR) if f.lower().endswith(".png")]
    return max(pngs, key=lambda f: os.path.getctime(os.path.join(COMFYUI_OUT_DIR, f))) if pngs else None

def get_final_image_filename(prompt_id):
    hist = get_history(prompt_id)
    for info in hist.get("outputs", {}).get("7", {}).get("images", []):
        fn = info.get("filename")
        if fn and fn.lower().endswith(".png"):
            return fn
    return find_latest_png()

def move_output_files(prompt_id):
    fn = get_final_image_filename(prompt_id)
    if not fn:
        return None
    src = os.path.join(COMFYUI_OUT_DIR, fn)
    dst = os.path.join(TARGET_DIR, fn)
    if os.path.exists(src):
        shutil.move(src, dst)
        return fn
    return None

# ================================
# 主路由：接受 form-data 圖片上傳 + 參數
# ================================
@app.route("/image_to_image", methods=["POST"])
def image_to_image():
    # 1) 圖片檢查與儲存
    img = request.files.get("image")
    if not img or img.filename == "":
        return jsonify({"error": "未上傳圖片"}), 400
    filename = secure_filename(img.filename)
    input_path = os.path.join(TEMP_INPUT_DIR, filename)
    img.save(input_path)
    print(f"✅ 圖片已保存: {input_path}")

    # 2) 讀取表單參數
    cfg_scale        = int(request.form.get("cfgScale", 7))
    sampler_name     = request.form.get("samplerName", "euler")
    scheduler        = request.form.get("scheduler", "normal")
    denoise_strength = float(request.form.get("denoiseStrength", 0.7))
    vae_name         = request.form.get("vaeName", "kl-f8-anime2.safetensors")
    ckpt_name        = request.form.get("checkpointName", "meinamix_v12Final.safetensors")
    seed_str         = request.form.get("seed", "")
    prompt_text      = request.form.get("prompt", "").strip()
    lora_name        = request.form.get("loraName", "").strip()
    strength_model   = float(request.form.get("loraStrengthModel", 0.0))
    strength_clip    = float(request.form.get("loraStrengthClip", 1.0))

    try:
        seed = int(seed_str) if seed_str else int(uuid.uuid4().int % 1000000)
    except:
        seed = int(uuid.uuid4().int % 1000000)

    # 3) 參數換行列印
    print("🔹 收到前端參數：")
    print(f"  • Checkpoint 名稱    : {ckpt_name}")
    print(f"  • VAE 名稱           : {vae_name}")
    print(f"  • CFG 強度           : {cfg_scale}")
    print(f"  • 採樣器             : {sampler_name}")
    print(f"  • 調度器             : {scheduler}")
    print(f"  • 去躁幅度           : {denoise_strength}")
    print(f"  • 隨機種子           : {seed}")
    print(f"  • 提示詞             : {prompt_text}")
    print(f"  • LoRA 名稱          : {lora_name}")
    print(f"  • LoRA 強度 (Model)  : {strength_model}")
    print(f"  • LoRA 強度 (CLIP)   : {strength_clip}")

    # 4) ComfyUI Workflow 範本（含 LoRA 節點）&#8203;:contentReference[oaicite:0]{index=0}&#8203;:contentReference[oaicite:1]{index=1}
    workflow_template = r""
{
  "1":  {"inputs":{"ckpt_name":"meinamix_v12Final.safetensors"},"class_type":"CheckpointLoaderSimple"},
  "2":  {"inputs":{"text":"","clip":["15",1]},"class_type":"CLIPTextEncode"},
  "3":  {"inputs":{"text":"","clip":["15",1]},"class_type":"CLIPTextEncode"},
  "4":  {"inputs":{"seed":0,"steps":20,"cfg":7,"sampler_name":"euler","scheduler":"normal","denoise":0.7,"model":["15",0],"positive":["2",0],"negative":["3",0],"latent_image":["14",0]},"class_type":"KSampler"},
  "7":  {"inputs":{"filename_prefix":"ComfyUI","images":["8


=== lora局部重繪.py ===
import os
import time
import uuid
import json
import base64
import shutil
import urllib.request
import websocket

from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS

app = Flask(__name__)
CORS(app)

# =============================
# ComfyUI 伺服器與資料夾設定
# =============================
server_address       = "127.0.0.1:8188"  # ComfyUI 伺服器位址
comfyui_output_dir   = r"D:\comfyui\ComfyUI_windows_portable\ComfyUI\output"
temp_input_dir       = r"D:\大模型局部重繪\temp_input"
os.makedirs(temp_input_dir, exist_ok=True)

target_dir_redraw    = r"D:\大模型局部重繪"
target_dir_reverse   = r"D:\大模型局部重繪反轉"
os.makedirs(target_dir_redraw, exist_ok=True)
os.makedirs(target_dir_reverse, exist_ok=True)

pure_painting_dir    = r"D:\大模型局部重繪\pure_painting"
os.makedirs(pure_painting_dir, exist_ok=True)

# 外網域名
EXTERNAL_URL         = "https://inpant-lora.picturesmagician.com"

# =============================
# 工作流程模板（保持原樣）
# =============================
workflow_redraw_template = r"""
{
  "1": {
    "inputs": {
      "ckpt_name": "meinamix_v12Final.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {"title": "Checkpoint加载器（简易）"}
  },
  "2": {
    "inputs": {
      "text": "default",
      "clip": ["1", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {"title": "正向提示词"}
  },
  "3": {
    "inputs": {
      "text": "negative prompt",
      "clip": ["1", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {"title": "反向提示词"}
  },
  "4": {
    "inputs": {
      "seed": 0,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "euler",
      "scheduler": "karras",
      "denoise": 1,
      "model": ["1", 0],
      "positive": ["2", 0],
      "negative": ["3", 0],
      "latent_image": ["14", 0]
    },
    "class_type": "KSampler",
    "_meta": {"title": "K采样器"}
  },
  "7": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": ["8", 0]
    },
    "class_type": "SaveImage",
    "_meta": {"title": "保存图像"}
  },
  "8": {
    "inputs": {
      "samples": ["4", 0],
      "vae": ["9", 0]
    },
    "class_type": "VAEDecode",
    "_meta": {"title": "VAE解码"}
  },
  "9": {
    "inputs": {"vae_name": "kl-f8-anime2.safetensors"},
    "class_type": "VAELoader",
    "_meta": {"title": "加载VAE"}
  },
  "13": {
    "inputs": {
      "pixels": ["28", 0],
      "vae": ["9", 0]
    },
    "class_type": "VAEEncode",
    "_meta": {"title": "VAE编码"}
  },
  "14": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "width": 512,
      "height": 512,
      "crop": "disabled",
      "samples": ["15", 0]
    },
    "class_type": "LatentUpscale",
    "_meta": {"title": "缩放Latent"}
  },
  "15": {
    "inputs": {
      "samples": ["21", 0],
      "mask": ["19", 0]
    },
    "class_type": "SetLatentNoiseMask",
    "_meta": {"title": "设置Latent噪声遮罩"}
  },
  "19": {
    "inputs": {
      "channel": "red",
      "image": ["29", 0]
    },
    "class_type": "ImageToMask",
    "_meta": {"title": "图像到遮罩"}
  },
  "21": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "width": 512,
      "height": 512,
      "crop": "disabled",
      "samples": ["13", 0]
    },
    "class_type": "LatentUpscale",
    "_meta": {"title": "缩放Latent"}
  },
  "22": {
    "inputs": {
      "lora_name": "asuna_(stacia)-v1.5.safetensors",
      "strength_model": 1,
      "strength_clip": 1,
      "model": ["1", 0],
      "clip": ["1", 1]
    },
    "class_type": "LoraLoader",
    "_meta": {"title": "LoRA载入器"}
  },
  "23": {
    "inputs": {
      "image_path": "\"./input/example.png\""
    },
    "class_type": "ZwngLoadImagePathOrURL",
    "_meta": {"title": "Load Image Path or URL"}
  },
  "24": {
    "inputs": {
      "image_path": "\"./input/example.png\""
    },
    "class_type": "ZwngLoadImagePathOrURL",
    "_meta": {"title": "Load Image Path or URL"}
  },
  "25": {
    "inputs": {"image_path": ""},
    "class_type": "ZwngLoadImagePathOrURL",
    "_meta": {"title": "Load Image Path or URL"}
  },
  "26": {
    "inputs": {"image_path": ""},
    "class_type": "ZwngLoadImagePathOrURL",
    "_meta": {"title": "Load Image Path or URL"}
  }
}
""".strip()

workflow_reverse_template = r"""
# （反轉模板省略，與上方結構相同，僅節點編號不同）
""".strip()

# =============================
# 儲存 Base64 圖片
# =============================
def save_base64_image(data_url, folder, prefix):
    header, encoded = data_url.split(",", 1)
    ext = "png" if "png" in header else "jpg"
    filename = f"{prefix}_{uuid.uuid4().hex[:8]}.{ext}"
    path = os.path.join(folder, filename)
    with open(path, "wb") as f:
        f.write(base64.b64decode(encoded))
    return path, None

# =============================
# 發送 ComfyUI 任務、等待完成、搬移檔案
# =============================
def queue_prompt(prompt):
    client_id = str(uuid.uuid4())
    payload = {"prompt": prompt, "client_id": client_id}
    data = json.dumps(payload).encode("utf-8")
    url = f"http://{server_address}/prompt"
    try:
        req = urllib.request.Request(url, data=data)
        with urllib.request.urlopen(req) as resp:
            result = json.loads(resp.read())
            result["client_id"] = client_id
            return result
    except Exception as e:
        print(f"❌ 無法連線至 ComfyUI API: {e}")
        return None

def wait_for_completion(prompt_id, client_id):
    ws_url = f"ws://{server_address}/ws?clientId={client_id}"
    try:
        ws = websocket.create_connection(ws_url)
        while True:
            out = ws.recv()
            if isinstance(out, str):
                msg = json.loads(out)
                if msg.get("type")=="executing" and msg.get("data",{}).get("node") is None \
                   and msg["data"].get("prompt_id")==prompt_id:
                    break
        ws.close()
    except Exception as e:
        print(f"❌ WebSocket 錯誤: {e}")

def move_output_files(prompt_id, target_dir):
    # 同原本的檔案搬移
    ...

@app.route("/image_to_image", methods=["POST"])
def image_to_image():
    data = request.get_json()
    # —— 讀取與轉型參數 ——  
    orig_img = data.get("originalImage")
    mask_img = data.get("maskImage")
    pure_img = data.get("purePainting")

    prompt_text      = data.get("prompt", "").strip()
    vae_name         = data.get("vaeName", "kl-f8-anime2.safetensors")
    ckpt_name        = data.get("checkpointName", "meinamix_v12Final.safetensors")
    try:
        cfg_scale     = int(data.get("cfgScale", 7))
    except:
        cfg_scale     = 7
    sampler_name     = data.get("samplerName", "euler")
    scheduler        = data.get("scheduler", "karras")
    try:
        denoise_strength = float(data.get("denoiseStrength", 1.0))
    except:
        denoise_strength = 1.0
    seed_val         = data.get("seed", "")
    try:
        seed          = int(seed_val) if seed_val!="" else int(uuid.uuid4().int % 1000000)
    except:
        seed          = int(uuid.uuid4().int % 1000000)

    # —— 新增 LoRA 參數讀取 ——  
    lora_name        = data.get("loraName", "super-vanilla-newlora-ver1-p.safetensors")
    try:
        strength_model = float(data.get("loraStrengthModel", 0))
    except:
        strength_model = 0.0
    try:
        strength_clip  = float(data.get("loraStrengthClip", 1))
    except:
        strength_clip  = 1.0

    # —— 印出所有參數 ——  
    print("🔹 收到參數：")
    print(f"  originalImage   : {bool(orig_img)}")
    print(f"  maskImage       : {bool(mask_img)}")
    print(f"  purePainting    : {bool(pure_img)}")
    print(f"  prompt          : {prompt_text}")
    print(f"  vaeName         : {vae_name}")
    print(f"  checkpointName  : {ckpt_name}")
    print(f"  cfgScale        : {cfg_scale}")
    print(f"  samplerName     : {sampler_name}")
    print(f"  scheduler       : {scheduler}")
    print(f"  denoiseStrength : {denoise_strength}")
    print(f"  seed            : {seed}")
    print(f"  loraName        : {lora_name}")
    print(f"  loraStrengthModel: {strength_model}")
    print(f"  loraStrengthClip: {strength_clip}")

    if not orig_img or not mask_img:
        return jsonify({"error": "未提供原始圖片或遮罩圖片"}), 400

    # —— 存圖檔至暫存 ——  
    orig_path, _ = save_base64_image(orig_img, temp_input_dir, "orig")
    mask_path, _ = save_base64_image(mask_img, temp_input_dir, "mask")
    pure_path = None
    if pure_img:
        pure_path, _ = save_base64_image(pure_img, temp_input_dir, "pure")

    mode = data.get("mode","redraw").strip()
    if mode=="reverse":
        workflow_template = workflow_reverse_template
        target_dir        = target_dir_reverse
    else:
        workflow_template = workflow_redraw_template
        target_dir        = target_dir_redraw

    workflow = json.loads(workflow_template)

    # —— 注入基本參數 ——  
    workflow["1"]["inputs"]["ckpt_name"]    = ckpt_name
    workflow["9"]["inputs"]["vae_name"]     = vae_name
    workflow["2"]["inputs"]["text"]         = prompt_text
    workflow["4"]["inputs"]["cfg"]          = cfg_scale
    workflow["4"]["inputs"]["sampler_name"] = sampler_name
    workflow["4"]["inputs"]["scheduler"]    = scheduler
    workflow["4"]["inputs"]["denoise"]      = denoise_strength
    workflow["4"]["inputs"]["seed"]         = seed

    # —— 注入 LoRA 參數至「22」節點 ——  
    workflow["22"]["inputs"]["lora_name"]        = lora_name
    workflow["22"]["inputs"]["strength_model"]   = strength_model
    workflow["22"]["inputs"]["strength_clip"]    = strength_clip

    # —— 注入圖片路徑 ——  
    if mode=="reverse":
        workflow["25"]["inputs"]["image_path"] = orig_path
        workflow["26"]["inputs"]["image_path"] = mask_path
    else:
        workflow["28"]["inputs"]["image_path"] = orig_path
        workflow["29"]["inputs"]["image_path"] = mask_path

    # —— 發送並等待結果 ——  
    print("🚀 發送工作流程至 ComfyUI：")
    print(json.dumps(workflow, indent=4, ensure_ascii=False))
    resp      = queue_prompt(workflow)
    prompt_id = resp["prompt_id"]
    client_id = resp["client_id"]
    wait_for_completion(prompt_id, client_id)

    time.sleep(5)  # 確保圖片生成完成
    output_fn = move_output_files(prompt_id, target_dir)
    image_url  = EXTERNAL_URL + "/get_image/" + output_fn + f"?t={int(time.time())}"
    pure_url   = None
    if pure_path:
        fn = os.path.basename(pure_path)
        shutil.copy(pure_path, os.path.join(pure_painting_dir, fn))
        pure_url = EXTERNAL_URL + "/get_pure/" + fn + f"?t={int(time.time())}"

    return jsonify({"image_url": image_url, "pure_painting_url": pure_url})

@app.route("/get_image/<filename>")
def get_image(filename):
    return send_from_directory(target_dir_redraw if os.path.exists(os.path.join(target_dir_redraw, filename)) else target_dir_reverse, filename)

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5013)


=== lora文生圖.py ===
import json
import os
import shutil
import time
import uuid
import urllib.request
import websocket  # 請先安裝：pip install websocket-client
from flask import Flask, request, jsonify, send_from_directory, Response
from flask_cors import CORS
from collections import OrderedDict
from werkzeug.middleware.proxy_fix import ProxyFix

app = Flask(__name__)

# -------------------------------------------------------------------
# CORS 設定：開發階段允許所有網域；正式上線時請改為限制特定網域
# -------------------------------------------------------------------
CORS(
    app,
    resources={r"/*": {"origins": "*"}},
    supports_credentials=True,
    allow_headers=["Content-Type", "Authorization", "X-Requested-With", "Accept", "Origin"],
    methods=["GET", "POST", "OPTIONS", "DELETE"]
)

# -------------------------------------------------------------------
# ProxyFix：確保 Flask 能正確讀取 Cloudflare Tunnel 傳來的標頭
# -------------------------------------------------------------------
app.wsgi_app = ProxyFix(app.wsgi_app, x_for=1, x_proto=1, x_host=1, x_port=1)

# -------------------------------------------------------------------
# 內網後端服務地址：翻譯服務及生圖服務（請根據實際環境調整）
# -------------------------------------------------------------------
TRANSLATE_SERVER = "http://172.24.11.4:5000"
BACKEND_SERVER   = "http://172.24.11.7:5011"

# -------------------------------------------------------------------
# Cloudflare Tunnel 對外提供的 HTTPS 網域（必須設定為 HTTPS）
# -------------------------------------------------------------------
IMAGE_BASE_URL = "https://api-lora.picturesmagician.com"

# -------------------------------------------------------------------
# ComfyUI 輸出資料夾及目標資料夾（搬移檔案到此目標資料夾後供 /get_image 讀取）
# -------------------------------------------------------------------
comfyui_output_dir = r"D:\comfyui\ComfyUI_windows_portable\ComfyUI\output"
target_dir = r"D:\大模型文生圖"
os.makedirs(target_dir, exist_ok=True)

# -------------------------------------------------------------------
# 用來追蹤翻譯請求狀態的 OrderedDict
# -------------------------------------------------------------------
processing_requests = OrderedDict()


# =============================
# 與 ComfyUI 溝通的函式
# =============================

def queue_prompt(prompt):
    """
    發送工作流程 JSON 到 ComfyUI 的 /prompt API，並回傳 prompt_id 與 client_id
    """
    client_id = str(uuid.uuid4())
    payload = {"prompt": prompt, "client_id": client_id}
    data = json.dumps(payload).encode("utf-8")
    url = "http://127.0.0.1:8188/prompt"
    try:
        req = urllib.request.Request(url, data=data, headers={"Content-Type": "application/json"})
        with urllib.request.urlopen(req) as resp:
            result = json.loads(resp.read())
            result["client_id"] = client_id
            return result
    except Exception as e:
        print(f"❌ 無法連線至 ComfyUI API: {e}")
        return None

def wait_for_completion(prompt_id, client_id):
    """
    建立 WebSocket 連線等待指定 prompt_id 任務完成
    """
    ws_url = f"ws://127.0.0.1:8188/ws?clientId={client_id}"
    print("🕐 等待 ComfyUI 任務完成...")
    try:
        ws = websocket.create_connection(ws_url)
        while True:
            out = ws.recv()
            if isinstance(out, str):
                message = json.loads(out)
                if message.get("type") == "executing":
                    data = message.get("data", {})
                    if data.get("node") is None and data.get("prompt_id") == prompt_id:
                        print("✅ 任務已完成！")
                        break
        ws.close()
    except Exception as e:
        print(f"❌ WebSocket 連線錯誤: {e}")

def get_history(prompt_id):
    """
    透過 /history/<prompt_id> API 取得 ComfyUI 任務輸出紀錄
    """
    url = f"http://127.0.0.1:8188/history/{prompt_id}"
    try:
        with urllib.request.urlopen(url) as resp:
            history_data = json.loads(resp.read())
        print(f"📜 history API 回應: {json.dumps(history_data, indent=4, ensure_ascii=False)}")
        return history_data.get(prompt_id, {})
    except Exception as e:
        print(f"❌ 無法取得歷史紀錄: {e}")
        return {}

def find_latest_png():
    """
    若 /history API 沒有提供檔名，則在 comfyui_output_dir 搜尋最新的 .png 檔案
    """
    png_files = [f for f in os.listdir(comfyui_output_dir) if f.lower().endswith(".png")]
    if not png_files:
        print("🚫 找不到任何 .png 檔案！")
        return None
    latest_png = max(png_files, key=lambda f: os.path.getctime(os.path.join(comfyui_output_dir, f)))
    print(f"🎞 找到最新的 .png 檔案: {latest_png}")
    return latest_png

def get_final_image_filename(prompt_id):
    """
    從 /history/<prompt_id> 中找出最終輸出的圖片檔名，
    如未找到則使用 find_latest_png()
    """
    history = get_history(prompt_id)
    if not history:
        print("⚠️ history API 回應為空，改用檔案搜尋。")
        return find_latest_png()

    outputs = history.get("outputs", {})
    image_node = outputs.get("7", {})
    if "images" in image_node:
        for info in image_node["images"]:
            filename = info.get("filename")
            if filename and filename.lower().endswith(".png"):
                print(f"🎞 從 API 取得圖片檔名: {filename}")
                return filename

    print("⚠️ history API 未提供圖片檔名，改用檔案搜尋。")
    return find_latest_png()

def move_output_files(prompt_id):
    """
    將 comfyui_output_dir 中的圖片檔搬移到 target_dir，
    並在檔名中加入時間戳作為唯一標識
    """
    image_filename = get_final_image_filename(prompt_id)
    if not image_filename:
        print("🚫 無法取得圖片檔案名稱！")
        return None

    name, ext = os.path.splitext(image_filename)
    unique_filename = f"{name}_{int(time.time())}{ext}"
    source_path = os.path.join(comfyui_output_dir, image_filename)
    target_path = os.path.join(target_dir, unique_filename)

    if not os.path.exists(source_path):
        print(f"⚠️ 找不到來源檔案: {source_path}")
        return None

    try:
        shutil.move(source_path, target_path)
        print(f"✅ 搬移成功: {source_path} → {target_path}")
        return unique_filename
    except Exception as e:
        print(f"❌ 搬移失敗: {e}")
        return None


# =============================
# Flask 路由
# =============================

@app.route("/generate_image", methods=["POST"])
def generate_image_endpoint():
    """
    接收前端描述與參數，轉發給 ComfyUI，等待完成，搬移檔案並回傳 HTTPS 圖片連結
    """
    data = request.json
    description = data.get("text", "").strip()
    if not description:
        return jsonify({"error": "請提供有效的描述文字"}), 400

    # ——— 1. 解析基本參數 ———
    # Checkpoint 名稱映射
    checkpoint_map = {
        "anythingelseV4_v45.safetensors":               "anythingelseV4_v45.safetensors",
        "flux1-dev.safetensors":                        "flux1-dev.safetensors",
        "meanimax_v12Final.safetensors":                "meinamix_v12Final.safetensors",        
        "realisticVisionV51_v51VAE.safetensors":        "realisticVisionV51_v51VAE.safetensors",
        "sdxlUnstableDiffusers_nihilanth.safetensors":  "sdxlUnstableDiffusers_nihilmania.safetensors",
        "sdxlYamersRealistic5_v9RunDiffusion.safetensors":"sdxlYamersRealistic5_v5Rundiffusion.safetensors"
    }
    raw_ckpt       = data.get("checkpoint", "meanimax_v12Final.safetensors")
    checkpoint     = checkpoint_map.get(raw_ckpt, raw_ckpt)
    vae            = data.get("vae", "kl-f8-anime2.safetensors")
    try:
        cfg_scale      = int(data.get("cfg_scale", 7))
    except ValueError:
        cfg_scale      = 7
    sampler        = data.get("sampler", "euler")
    scheduler      = data.get("scheduler", "normal")
    try:
        seed           = int(data.get("seed", 103))
    except ValueError:
        seed           = 103

    # ——— 2. 解析 LoRA 參數 ———
    lora_name      = data.get("lora_name", "").strip()
    try:
        strength_model = float(data.get("strength_model", 0.0))
    except (TypeError, ValueError):
        strength_model = 0.0
    try:
        strength_clip  = float(data.get("strength_clip", 1.0))
    except (TypeError, ValueError):
        strength_clip  = 1.0

    # ——— 3. 列印所有參數，方便除錯 ———
    print("🔹 收到前端參數:", data)
    print(f"   -> checkpoint:      {checkpoint}")
    print(f"   -> vae:             {vae}")
    print(f"   -> cfg_scale:       {cfg_scale}")
    print(f"   -> sampler:         {sampler}")
    print(f"   -> scheduler:       {scheduler}")
    print(f"   -> seed:            {seed}")
    print(f"   -> lora_name:       {lora_name}")
    print(f"   -> strength_model:  {strength_model}")
    print(f"   -> strength_clip:   {strength_clip}")

    # ——— 4. 建立 ComfyUI workflow JSON ———
    prompt_text = """
{
  "1":  {"class_type":"CheckpointLoaderSimple", "inputs":{"ckpt_name":"meinamix_v12Final.safetensors"}},
  "2":  {"class_type":"CLIPTextEncode",      "inputs":{"text":"", "clip":["1",1]}},
  "3":  {"class_type":"CLIPTextEncode",      "inputs":{"text":"(low quality, worst quality...)", "clip":["1",1]}},
  "4":  {"class_type":"KSampler",            "inputs":{"seed":440871023236812,"steps":20,"cfg":8,"sampler_name":"euler","scheduler":"normal","denoise":1,"model":["1",0],"positive":["2",0],"negative":["3",0],"latent_image":["15",0]}},
  "7":  {"class_type":"SaveImage",           "inputs":{"filename_prefix":"ComfyUI","images":["8",0]}},
  "8":  {"class_type":"VAEDecode",           "inputs":{"samples":["4",0],"vae":["9",0]}},
  "9":  {"class_type":"VAELoader",           "inputs":{"vae_name":"kl-f8-anime2.safetensors"}},
  "15": {"class_type":"EmptyLatentImage",    "inputs":{"width":512,"height":512,"batch_size":1}}
}
"""
    try:
        prompt = json.loads(prompt_text)
    except json.JSONDecodeError as e:
        return jsonify({"error": "工作流程 JSON 格式錯誤", "details": str(e)}), 500

    # ——— 5. 填入使用者參數 ———
    prompt["1"]["inputs"]["ckpt_name"]      = checkpoint
    prompt["9"]["inputs"]["vae_name"]       = vae
    prompt["2"]["inputs"]["text"]           = description
    prompt["4"]["inputs"]["cfg"]            = cfg_scale
    prompt["4"]["inputs"]["sampler_name"]   = sampler
    prompt["4"]["inputs"]["scheduler"]      = scheduler
    prompt["4"]["inputs"]["seed"]           = seed

    # ——— 6. 插入 LoRA 節點（若有指定） ———
    if lora_name:
        prompt["10"] = {
            "class_type":"LoraLoader",
            "inputs":{
                "lora_name":      lora_name,
                "strength_model": strength_model,
                "strength_clip":  strength_clip,
                "model":          ["1",0],
                "clip":           ["1",1]
            }
        }
        # 把 KSampler 的 model 由 ["1",0] 改成 ["10",0]
        prompt["4"]["inputs"]["model"] = ["10",0]

    # ——— 7. 送到 ComfyUI 並等待完成 ———
    resp_data = queue_prompt(prompt)
    if not resp_data or "prompt_id" not in resp_data:
        return jsonify({"error": "ComfyUI API 回應錯誤"}), 500

    prompt_id = resp_data["prompt_id"]
    client_id = resp_data["client_id"]
    print(f"🔹 prompt_id={prompt_id}, client_id={client_id}")

    wait_for_completion(prompt_id, client_id)
    time.sleep(5)

    # ——— 8. 搬移輸出檔案 → HTTPS 連結回傳 ———
    unique_fn = move_output_files(prompt_id)
    if not unique_fn:
        return jsonify({"error": "搬移圖片失敗"}), 500

    image_url = f"{IMAGE_BASE_URL}/get_image/{unique_fn}?t={int(time.time())}"
    print(f"🔹 回傳圖片 URL: {image_url}")
    return jsonify({"image_url": image_url})


@app.route("/get_image/<path:filename>", methods=["GET"])
def get_image(filename):
    """
    提供搬移後的圖片檔案下載或顯示。如果檔案不存在，回傳 404
    """
    file_path = os.path.join(target_dir, filename)
    if not os.path.exists(file_path):
        print(f"⚠️ 找不到檔案: {file_path}")
        return jsonify({"error": "檔案不存在"}), 404
    return send_from_directory(target_dir, filename)


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5011, debug=False)


=== lora線稿上色.py ===
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import shutil
import time
import uuid
import base64
import urllib.request
import websocket  # pip install websocket-client
from flask import Flask, request, jsonify, send_from_directory, make_response
from flask_cors import CORS

app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}})

# ----------------------------
# 檢查點到 ControlNet 的對應表
# ----------------------------
CHECKPOINT_TO_CONTROLNET = {
    "anythingelseV4_v45.safetensors":                "sd1.5_lineart.safetensors",
    "meinamix_v12Final.safetensors":                 "sd1.5_lineart.safetensors",
    "sdxlUnstableDiffusers_nihilmania.safetensors":  "sdxl_canny.safetensors",
    "sdxlYamersRealistic5_v5Rundiffusion.safetensor": "sdxl_canny.safetensors",
}
DEFAULT_CONTROLNET = "control_sd15_canny.pth"

# ----------------------------
# 文生模式 Workflow JSON (含 LoRA 節點)
# ----------------------------
text_workflow_json = r"""
{
  "1": {
    "inputs": { "ckpt_name": "meinamix_v12Final.safetensors" },
    "class_type": "CheckpointLoaderSimple",
    "_meta": { "title": "Checkpoint載入器(簡易)" }
  },
  "2": {
    "inputs": {
      "text": "example positive prompt",
      "clip": ["52", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": { "title": "CLIP文本編碼器" }
  },
  "3": {
    "inputs": {
      "text": "example negative prompt",
      "clip": ["52", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": { "title": "CLIP文本編碼器" }
  },
  "18": {
    "inputs": {
      "strength": 1.5,
      "start_percent": 0,
      "end_percent": 1,
      "positive": ["2", 0],
      "negative": ["3", 0],
      "control_net": ["19", 0],
      "image": ["47", 0],
      "vae": ["9", 0]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": { "title": "ControlNet應用(進階)" }
  },
  "19": {
    "inputs": { "control_net_name": "control_sd15_canny.pth" },
    "class_type": "ControlNetLoader",
    "_meta": { "title": "ControlNet載入器" }
  },
  "47": {
    "inputs": {
      "low_threshold": 100,
      "high_threshold": 200,
      "resolution": 512,
      "image": ["49", 0]
    },
    "class_type": "CannyEdgePreprocessor",
    "_meta": { "title": "Canny線條預處理器" }
  },
  "48": {
    "inputs": {
      "width": 512,
      "height": 512,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": { "title": "空Latent" }
  },
  "49": {
    "inputs": { "image_path": "" },
    "class_type": "ZwngLoadImagePathOrURL",
    "_meta": { "title": "Load 線稿圖(文生)" }
  },
  "50": {
    "inputs": { "images": ["49", 0] },
    "class_type": "PreviewImage",
    "_meta": { "title": "預覽線稿" }
  },
  "52": {
    "inputs": {
      "lora_name":        "asuna_(stacia)-v1.5.safetensors",
      "strength_model":   1,
      "strength_clip":    1,
      "model":            ["1", 0],
      "clip":             ["1", 1]
    },
    "class_type": "LoraLoader",
    "_meta": { "title": "LoRA載入器" }
  },
  "4": {
    "inputs": {
      "seed":        0,
      "steps":       20,
      "cfg":         7,
      "sampler_name":"euler",
      "scheduler":   "normal",
      "denoise":     1,
      "model":       ["52", 0],
      "positive":    ["18", 0],
      "negative":    ["18", 1],
      "latent_image":["48", 0]
    },
    "class_type": "KSampler",
    "_meta": { "title": "K採樣器" }
  },
  "8": {
    "inputs": {
      "samples": ["4", 0],
      "vae":     ["9", 0]
    },
    "class_type": "VAEDecode",
    "_meta": { "title": "VAE解碼" }
  },
  "7": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images":          ["8", 0]
    },
    "class_type": "SaveImage",
    "_meta": { "title": "儲存圖像" }
  },
  "9": {
    "inputs": { "vae_name": "kl-f8-anime2.safetensors" },
    "class_type": "VAELoader",
    "_meta": { "title": "VAE載入器" }
  }
}
"""

# ----------------------------
# 圖生模式 Workflow JSON (含 LoRA 節點)
# ----------------------------
image_workflow_json = r"""
{
  "1": {
    "inputs": { "ckpt_name": "meinamix_v12Final.safetensors" },
    "class_type": "CheckpointLoaderSimple",
    "_meta": { "title": "Checkpoint載入器(簡易)" }
  },
  "2": {
    "inputs": {
      "text": "example positive prompt",
      "clip": ["52", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": { "title": "CLIP文本編碼器" }
  },
  "3": {
    "inputs": {
      "text": "example negative prompt",
      "clip": ["52", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": { "title": "CLIP文本編碼器" }
  },
  "18": {
    "inputs": {
      "strength":      1.5,
      "start_percent": 0,
      "end_percent":   1,
      "positive":      ["2", 0],
      "negative":      ["3", 0],
      "control_net":   ["19", 0],
      "image":         ["47", 0],
      "vae":           ["9", 0]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": { "title": "ControlNet應用(進階)" }
  },
  "19": {
    "inputs": { "control_net_name": "control_sd15_canny.pth" },
    "class_type": "ControlNetLoader",
    "_meta": { "title": "ControlNet載入器" }
  },
  "47": {
    "inputs": {
      "low_threshold": 100,
      "high_threshold":200,
      "resolution":    512,
      "image":         ["49", 0]
    },
    "class_type": "CannyEdgePreprocessor",
    "_meta": { "title": "Canny線條預處理器" }
  },
  "48": {
    "inputs": { "image_path": "" },
    "class_type": "ZwngLoadImagePathOrURL",
    "_meta": { "title": "Load 輔助線稿圖(圖生)" }
  },
  "51": {
    "inputs": { "image_path": "" },
    "class_type": "ZwngLoadImagePathOrURL",
    "_meta": { "title": "Load 主線稿圖(圖生)" }
  },
  "52": {
    "inputs": {
      "lora_name":        "asuna_(stacia)-v1.5.safetensors",
      "strength_model":   1,
      "strength_clip":    1,
      "model":            ["1", 0],
      "clip":             ["1", 1]
    },
    "class_type": "LoraLoader",
    "_meta": { "title": "LoRA載入器" }
  },
  "4": {
    "inputs": {
      "seed":        0,
      "steps":       20,
      "cfg":         7,
      "sampler_name":"euler",
      "scheduler":   "normal",
      "denoise":     1,
      "model":       ["52", 0],
      "positive":    ["18", 0],
      "negative":    ["18", 1],
      "latent_image":["48", 0]
    },
    "class_type": "KSampler",
    "_meta": { "title": "K採樣器" }
  },
  "8": {
    "inputs": {
      "samples": ["4", 0],
      "vae":     ["9", 0]
    },
    "class_type": "VAEDecode",
    "_meta": { "title": "VAE解碼" }
  },
  "7": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images":          ["8", 0]
    },
    "class_type": "SaveImage",
    "_meta": { "title": "儲存圖像" }
  },
  "9": {
    "inputs": { "vae_name": "kl-f8-anime2.safetensors" },
    "class_type": "VAELoader",
    "_meta": { "title": "VAE載入器" }
  }
}
"""

# ----------------------------
# ComfyUI 伺服器與資料夾設定
# ----------------------------
server_address     = "127.0.0.1:8188"
comfyui_output_dir = r"D:\comfyui\ComfyUI_windows_portable\ComfyUI\output"
target_dir_text    = r"D:\大模型文生線稿上色圖"
target_dir_image   = r"D:\大模型圖生線稿上色圖"
TEMP_IMAGE_DIR     = r"D:\comfyui\temp_images"
EXTERNAL_API_URL   = "https://linecolor-lora.picturesmagician.com"

for d in (target_dir_text, target_dir_image, TEMP_IMAGE_DIR):
    os.makedirs(d, exist_ok=True)

# ----------------------------
# 輔助函式
# ----------------------------
def queue_prompt(workflow_dict):
    client_id = str(uuid.uuid4())
    payload   = {"prompt": workflow_dict, "client_id": client_id}
    data      = json.dumps(payload).encode("utf-8")
    req = urllib.request.Request(
        f"http://{server_address}/prompt",
        data=data,
        headers={"Content-Type":"application/json"}
    )
    with urllib.request.urlopen(req, timeout=60) as resp:
        result = json.loads(resp.read().decode("utf-8"))
        result["client_id"] = client_id
        return result

def wait_for_completion(prompt_id, client_id):
    ws = websocket.create_connection(f"ws://{server_address}/ws?clientId={client_id}", timeout=60)
    while True:
        msg = ws.recv()
        m = json.loads(msg) if isinstance(msg, str) else {}
        if m.get("type") == "executing":
            d = m.get("data", {})
            if d.get("prompt_id") == prompt_id and d.get("node") is None:
                break
    ws.close()

def find_latest_png(directory):
    pngs = [f for f in os.listdir(directory) if f.lower().endswith(".png")]
    return max(pngs, key=lambda fn: os.path.getctime(os.path.join(directory, fn))) if pngs else None

def get_final_image_filename(prompt_id):
    url = f"http://{server_address}/history/{prompt_id}"
    with urllib.request.urlopen(url, timeout=30) as resp:
        hist = json.loads(resp.read().decode("utf-8")).get(prompt_id, {})
    for nid in ("7",):
        for info in hist.get("outputs", {}).get(nid, {}).get("images", []):
            fn = info.get("filename")
            if fn and fn.lower().endswith(".png"):
                return fn
    return find_latest_png(comfyui_output_dir)

def move_output_files(prompt_id, target_folder):
    fn = get_final_image_filename(prompt_id)
    if not fn:
        return None
    src = os.path.join(comfyui_output_dir, fn)
    suffix = prompt_id.replace("-", "")[:8]
    new_fn = f"{suffix}_{fn}"
    dst = os.path.join(target_folder, new_fn)
    shutil.move(src, dst)
    return new_fn

def apply_cn(workflow, cn):
    if "18" in workflow:
        inp = workflow["18"]["inputs"]
        inp["strength"]      = float(cn.get("strength", 1.5))
        inp["start_percent"] = float(cn.get("start_percent", 0.0))
        inp["end_percent"]   = float(cn.get("end_percent", 1.0))
    return workflow

# ----------------------------
# 文生模式路由
# ----------------------------
@app.route("/lineart_color_text", methods=["POST"])
def lineart_color_text():
    data = request.get_json()
    print("Received /lineart_color_text parameters:")
    for k, v in data.items():
        print(f"  {k}: {v}")

    # 驗證
    if not data or "prompt" not in data:
        return jsonify({"error":"缺少提示詞"}), 400

    # 解碼並存檔線稿圖
    try:
        b64 = data["line_art_image"].split(",", 1)[1]
        img = base64.b64decode(b64)
        fn  = f"lineart_{uuid.uuid4().hex}.png"
        path= os.path.join(TEMP_IMAGE_DIR, fn)
        with open(path, "wb") as f:
            f.write(img)
        data["line_art_image"] = path
    except Exception as e:
        return jsonify({"error":f"線稿圖解碼失敗: {e}"}), 400

    # 準備 workflow
    wf = json.loads(text_workflow_json)

    # apply checkpoint / vae
    if data.get("ckpt_name"):
        wf["1"]["inputs"]["ckpt_name"] = data["ckpt_name"]
    if data.get("vae_name"):
        wf["9"]["inputs"]["vae_name"] = data["vae_name"]

    # apply LoRA
    if data.get("lora_name"):
        wf["52"]["inputs"]["lora_name"]      = data["lora_name"]
        wf["52"]["inputs"]["strength_model"] = float(data.get("strength_model", 1.0))
        wf["52"]["inputs"]["strength_clip"]  = float(data.get("strength_clip", 1.0))

    # 文字與採樣參數
    wf["2"]["inputs"]["text"]            = data["prompt"]
    wf["4"]["inputs"]["cfg"]             = int(data.get("cfg_scale", 7))
    wf["4"]["inputs"]["sampler_name"]    = data.get("sampler", "euler")
    wf["4"]["inputs"]["scheduler"]       = data.get("scheduler", "normal")
    wf["4"]["inputs"]["seed"]            = int(data.get("seed", 0))
    wf["4"]["inputs"]["denoise"]         = float(data.get("denoise_strength", 1.0))
    wf["47"]["inputs"]["low_threshold"]  = int(data.get("low_threshold", 100))
    wf["47"]["inputs"]["high_threshold"] = int(data.get("high_threshold", 200))
    wf["49"]["inputs"]["image_path"]     = data["line_art_image"]

    # ControlNet 參數
    if data.get("control_net_params"):
        wf = apply_cn(wf, data["control_net_params"])

    # 自動對應 ControlNet 檔名
    selected_ckpt = data.get("ckpt_name", "")
    cn_name = CHECKPOINT_TO_CONTROLNET.get(selected_ckpt, DEFAULT_CONTROLNET)
    wf["19"]["inputs"]["control_net_name"] = cn_name

    print("🚀 文生模式發送中…")
    resp = queue_prompt(wf)
    if not resp or "prompt_id" not in resp:
        return jsonify({"error":"ComfyUI 回應異常"}), 500

    pid, cid = resp["prompt_id"], resp["client_id"]
    wait_for_completion(pid, cid)
    fn = move_output_files(pid, target_dir_text)
    if not fn:
        return jsonify({"error":"搬檔失敗"}), 500

    url = f"{EXTERNAL_API_URL}/get_image/{fn}?t={int(time.time())}"
    return jsonify({"image_url": url})

# ----------------------------
# 圖生模式路由
# ----------------------------
@app.route("/lineart_color_image", methods=["POST"])
def lineart_color_image():
    data = request.get_json()
    print("Received /lineart_color_image parameters:")
    for k, v in data.items():
        print(f"  {k}: {v}")

    # 驗證
    if not data or "prompt" not in data or "image" not in data:
        return jsonify({"error":"缺少提示詞或主圖"}), 400

    # 解碼並存檔主圖
    try:
        b64 = data["image"].split(",", 1)[1]
        img = base64.b64decode(b64)
        fn  = f"main_{uuid.uuid4().hex}.png"
        path= os.path.join(TEMP_IMAGE_DIR, fn)
        with open(path, "wb") as f:
            f.write(img)
        data["image"] = path
    except Exception as e:
        return jsonify({"error":f"主圖解碼失敗: {e}"}), 400

    # 解碼並存檔輔助線稿（可空）
    if data.get("line_art_image"):
        try:
            b64 = data["line_art_image"].split(",", 1)[1]
            img = base64.b64decode(b64)
            fn  = f"aux_{uuid.uuid4().hex}.png"
            ap  = os.path.join(TEMP_IMAGE_DIR, fn)
            with open(ap, "wb") as f:
                f.write(img)
            data["line_art_image"] = ap
        except Exception as e:
            return jsonify({"error":f"輔助線稿解碼失敗: {e}"}), 400
    else:
        data["line_art_image"] = data["image"]

    # 準備 workflow
    wf = json.loads(image_workflow_json)

    # apply checkpoint / vae
    if data.get("ckpt_name"):
        wf["1"]["inputs"]["ckpt_name"] = data["ckpt_name"]
    if data.get("vae_name"):
        wf["9"]["inputs"]["vae_name"]  = data["vae_name"]

    # apply LoRA
    if data.get("lora_name"):
        wf["52"]["inputs"]["lora_name"]      = data["lora_name"]
        wf["52"]["inputs"]["strength_model"] = float(data.get("strength_model", 1.0))
        wf["52"]["inputs"]["strength_clip"]  = float(data.get("strength_clip", 1.0))

    # 文字與採樣參數
    wf["2"]["inputs"]["text"]            = data["prompt"]
    wf["4"]["inputs"]["cfg"]             = int(data.get("cfg_scale", 7))
    wf["4"]["inputs"]["sampler_name"]    = data.get("sampler", "euler")
    wf["4"]["inputs"]["scheduler"]       = data.get("scheduler", "normal")
    wf["4"]["inputs"]["seed"]            = int(data.get("seed", 0))
    wf["4"]["inputs"]["denoise"]         = float(data.get("denoise_strength", 1.0))
    wf["47"]["inputs"]["low_threshold"]  = int(data.get("low_threshold", 100))
    wf["47"]["inputs"]["high_threshold"] = int(data.get("high_threshold", 200))
    wf["49"]["inputs"]["image_path"]     = data["line_art_image"]
    wf["51"]["inputs"]["image_path"]     = data["image"]

    # ControlNet 參數
    if data.get("control_net_params"):
        wf = apply_cn(wf, data["control_net_params"])

    # 自動對應 ControlNet 檔名
    selected_ckpt = data.get("ckpt_name", "")
    cn_name = CHECKPOINT_TO_CONTROLNET.get(selected_ckpt, DEFAULT_CONTROLNET)
    wf["19"]["inputs"]["control_net_name"] = cn_name

    print("🚀 圖生模式發送中…")
    resp = queue_prompt(wf)
    if not resp or "prompt_id" not in resp:
        return jsonify({"error":"ComfyUI 回應異常"}), 500

    pid, cid = resp["prompt_id"], resp["client_id"]
    wait_for_completion(pid, cid)
    fn = move_output_files(pid, target_dir_image)
    if not fn:
        return jsonify({"error":"搬檔失敗"}), 500

    url = f"{EXTERNAL_API_URL}/get_image/{fn}?t={int(time.time())}"
    return jsonify({"image_url": url})

# ----------------------------
# 圖片代理 API & 啟動服務
# ----------------------------
@app.route("/get_image/<path:filename>", methods=["GET"])
def get_image(filename):
    t = os.path.join(target_dir_text, filename)
    i = os.path.join(target_dir_image, filename)
    if os.path.exists(t):
        resp = make_response(send_from_directory(target_dir_text, filename))
    elif os.path.exists(i):
        resp = make_response(send_from_directory(target_dir_image, filename))
    else:
        return jsonify({"error":"檔案不存在"}), 404
    resp.headers.update({
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache"
    })
    return resp

if __name__ == "__main__":
    # 開發測試用，正式部署請改用 gunicorn/uwsgi
    app.run(host="0.0.0.0", port=5017, debug=False)


=== 人物姿勢控制.py ===
# image_generation_flask.py
import os
import json
import shutil
import time
import uuid
import base64
import urllib.request
import websocket  # pip install websocket-client
from flask import Flask, request, jsonify, send_from_directory, make_response
from flask_cors import CORS

app = Flask(__name__)
CORS(app)

# -----------------------------------
# ComfyUI 位置 & 資料夾設定 (保持原樣)
# -----------------------------------
server_address = "127.0.0.1:8188"  # ComfyUI 伺服器地址
comfyui_output_dir = r"D:\comfyui\ComfyUI_windows_portable\ComfyUI\output"

# 生成結果存放（文生與圖生分開）
target_dir_text  = r"D:\大模型文生圖姿勢控制"
target_dir_image = r"D:\大模型圖生圖姿勢控制"
os.makedirs(target_dir_text, exist_ok=True)
os.makedirs(target_dir_image, exist_ok=True)

# 暫存上傳檔案（主圖 / 姿勢圖）
temp_dir = r"D:\大模型姿勢控制\temp_input"
os.makedirs(temp_dir, exist_ok=True)

# 外部對應的域名（組合給前端）
EXTERNAL_API_URL = "https://pose.picturesmagician.com"

# -----------------------------------
# 工作流程 JSON（文生模式）
# 分為：無 ControlNet (BASE) 與 有 ControlNet (CN)
# -----------------------------------
WORKFLOW_TEXT_BASE = r"""
{
  "1": { "class_type": "CheckpointLoaderSimple",
         "inputs": {"ckpt_name": "meinamix_v12Final.safetensors"} },
  "2": { "class_type": "CLIPTextEncode",
         "inputs": {"text": "example prompt", "clip": ["1", 1]} },
  "3": { "class_type": "CLIPTextEncode",
         "inputs": {"text": "bad hands...", "clip": ["1", 1]} },
  "4": {
    "class_type": "KSampler",
    "inputs": {
      "seed": 87,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "dpmpp_2m_sde",
      "scheduler": "karras",
      "denoise": 1,
      "model": ["1", 0],
      "positive": ["2", 0],
      "negative": ["3", 0],
      "latent_image": ["47", 0]
    }
  },
  "7": {
    "class_type": "SaveImage",
    "inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}
  },
  "8": {
    "class_type": "VAEDecode",
    "inputs": {"samples": ["4", 0], "vae": ["9", 0]}
  },
  "9": {
    "class_type": "VAELoader",
    "inputs": {"vae_name": "kl-f8-anime2.safetensors"}
  },
  "47": {
    "class_type": "EmptyLatentImage",
    "inputs": {"width": 512, "height": 512, "batch_size": 1}
  }
}
""".strip()

WORKFLOW_TEXT_CN = r"""
{
  "1": { "class_type": "CheckpointLoaderSimple",
         "inputs": {"ckpt_name": "meinamix_v12Final.safetensors"} },
  "2": { "class_type": "CLIPTextEncode",
         "inputs": {"text": "example prompt", "clip": ["1", 1]} },
  "3": { "class_type": "CLIPTextEncode",
         "inputs": {"text": "bad hands...", "clip": ["1", 1]} },
  "4": {
    "class_type": "KSampler",
    "inputs": {
      "seed": 87,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "dpmpp_2m_sde",
      "scheduler": "karras",
      "denoise": 1,
      "model": ["1", 0],
      "positive": ["23", 0],
      "negative": ["23", 1],
      "latent_image": ["47", 0]
    }
  },
  "7": {
    "class_type": "SaveImage",
    "inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}
  },
  "8": {
    "class_type": "VAEDecode",
    "inputs": {"samples": ["4", 0], "vae": ["9", 0]}
  },
  "9": {
    "class_type": "VAELoader",
    "inputs": {"vae_name": "kl-f8-anime2.safetensors"}
  },
  "17": {
    "class_type": "OpenposePreprocessor",
    "inputs": {
      "detect_hand": "enable",
      "detect_body": "enable",
      "detect_face": "disable",
      "resolution": 512,
      "scale_stick_for_xinsr_cn": "disable",
      "image": ["48", 0]
    }
  },
  "18": {
    "class_type": "ControlNetApplyAdvanced",
    "inputs": {
      "strength": 1.2,
      "start_percent": 0,
      "end_percent": 1,
      "positive": ["2", 0],
      "negative": ["3", 0],
      "control_net": ["19", 0],
      "image": ["17", 0],
      "vae": ["9", 0]
    }
  },
  "19": {
    "class_type": "ControlNetLoader",
    "inputs": {"control_net_name": "control_sd15_openpose.pth"}
  },
  "23": {
    "class_type": "ControlNetApplyAdvanced",
    "inputs": {
      "strength": 1.0,
      "start_percent": 0,
      "end_percent": 1,
      "positive": ["18", 0],
      "negative": ["18", 1],
      "control_net": ["24", 0],
      "image": ["28", 0],
      "vae": ["9", 0]
    }
  },
  "24": {
    "class_type": "ControlNetLoader",
    "inputs": {"control_net_name": "control_sd15_depth.pth"}
  },
  "28": {
    "class_type": "MiDaS-DepthMapPreprocessor",
    "inputs": {
      "a": 0,
      "bg_threshold": 0.1,
      "resolution": 512,
      "image": ["50", 0]
    }
  },
  "47": {
    "class_type": "EmptyLatentImage",
    "inputs": {"width": 512, "height": 512, "batch_size": 1}
  },
  "48": {
    "class_type": "ZwngLoadImagePathOrURL",
    "inputs": {"image_path": "C:\\dummy_pose.png"}
  },
  "50": {
    "class_type": "ZwngLoadImagePathOrURL",
    "inputs": {"image_path": "C:\\dummy_pose.png"}
  }
}
""".strip()

# -----------------------------------
# 工作流程 JSON（圖生模式）
# 分為：無 ControlNet (BASE) 與 有 ControlNet (CN)
# -----------------------------------
WORKFLOW_IMAGE_BASE = r"""
{
  "1": { "class_type": "CheckpointLoaderSimple",
         "inputs": {"ckpt_name": "meinamix_v12Final.safetensors"} },
  "2": { "class_type": "CLIPTextEncode",
         "inputs": {"text": "example prompt", "clip": ["1", 1]} },
  "3": { "class_type": "CLIPTextEncode",
         "inputs": {"text": "bad hands...", "clip": ["1", 1]} },
  "4": {
    "class_type": "KSampler",
    "inputs": {
      "seed": 87,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "dpmpp_2m_sde",
      "scheduler": "karras",
      "denoise": 1,
      "model": ["1", 0],
      "positive": ["2", 0],
      "negative": ["3", 0],
      "latent_image": ["37", 0]
    }
  },
  "7": {
    "class_type": "SaveImage",
    "inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}
  },
  "8": {
    "class_type": "VAEDecode",
    "inputs": {"samples": ["4", 0], "vae": ["9", 0]}
  },
  "9": {
    "class_type": "VAELoader",
    "inputs": {"vae_name": "kl-f8-anime2.safetensors"}
  },
  "37": {
    "class_type": "VAEEncode",
    "inputs": {"pixels": ["47", 0], "vae": ["9", 0]}
  },
  "47": {
    "class_type": "ZwngLoadImagePathOrURL",
    "inputs": {"image_path": "C:\\dummy_main.png"}
  }
}
""".strip()

WORKFLOW_IMAGE_CN = r"""
{
  "1": { "class_type": "CheckpointLoaderSimple",
         "inputs": {"ckpt_name": "meinamix_v12Final.safetensors"} },
  "2": { "class_type": "CLIPTextEncode",
         "inputs": {"text": "example prompt", "clip": ["1", 1]} },
  "3": { "class_type": "CLIPTextEncode",
         "inputs": {"text": "bad hands...", "clip": ["1", 1]} },
  "4": {
    "class_type": "KSampler",
    "inputs": {
      "seed": 87,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "dpmpp_2m_sde",
      "scheduler": "karras",
      "denoise": 1,
      "model": ["1", 0],
      "positive": ["23", 0],
      "negative": ["23", 1],
      "latent_image": ["37", 0]
    }
  },
  "7": {
    "class_type": "SaveImage",
    "inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}
  },
  "8": {
    "class_type": "VAEDecode",
    "inputs": {"samples": ["4", 0], "vae": ["9", 0]}
  },
  "9": {
    "class_type": "VAELoader",
    "inputs": {"vae_name": "kl-f8-anime2.safetensors"}
  },
  "17": {
    "class_type": "OpenposePreprocessor",
    "inputs": {
      "detect_hand": "enable",
      "detect_body": "enable",
      "detect_face": "disable",
      "resolution": 512,
      "scale_stick_for_xinsr_cn": "disable",
      "image": ["49", 0]
    }
  },
  "18": {
    "class_type": "ControlNetApplyAdvanced",
    "inputs": {
      "strength": 1.2,
      "start_percent": 0,
      "end_percent": 1,
      "positive": ["2", 0],
      "negative": ["3", 0],
      "control_net": ["19", 0],
      "image": ["17", 0],
      "vae": ["9", 0]
    }
  },
  "19": {
    "class_type": "ControlNetLoader",
    "inputs": {"control_net_name": "control_sd15_openpose.pth"}
  },
  "23": {
    "class_type": "ControlNetApplyAdvanced",
    "inputs": {
      "strength": 1.0,
      "start_percent": 0,
      "end_percent": 1,
      "positive": ["18", 0],
      "negative": ["18", 1],
      "control_net": ["24", 0],
      "image": ["28", 0],
      "vae": ["9", 0]
    }
  },
  "24": {
    "class_type": "ControlNetLoader",
    "inputs": {"control_net_name": "control_sd15_depth.pth"}
  },
  "28": {
    "class_type": "MiDaS-DepthMapPreprocessor",
    "inputs": {
      "a": 0,
      "bg_threshold": 0.1,
      "resolution": 512,
      "image": ["50", 0]
    }
  },
  "37": {
    "class_type": "VAEEncode",
    "inputs": {"pixels": ["47", 0], "vae": ["9", 0]}
  },
  "47": {
    "class_type": "ZwngLoadImagePathOrURL",
    "inputs": {"image_path": "C:\\dummy_main.png"}
  },
  "49": {
    "class_type": "ZwngLoadImagePathOrURL",
    "inputs": {"image_path": "C:\\dummy_pose.png"}
  },
  "50": {
    "class_type": "ZwngLoadImagePathOrURL",
    "inputs": {"image_path": "C:\\dummy_pose.png"}
  }
}
""".strip()

# -----------------------------------
# 小工具：queue_prompt, wait_for_completion, get_history, find_latest_png,
#           get_final_image_filename, move_output_files,
#           apply_controlnet_params_to_workflow_text_cn,
#           apply_controlnet_params_to_workflow_image_cn
# -----------------------------------
def queue_prompt(prompt):
    client_id = str(uuid.uuid4())
    payload = {"prompt": prompt, "client_id": client_id}
    data = json.dumps(payload).encode("utf-8")
    url = f"http://{server_address}/prompt"
    try:
        req = urllib.request.Request(url, data=data, headers={"Content-Type": "application/json"})
        with urllib.request.urlopen(req) as resp:
            result = json.loads(resp.read())
            result["client_id"] = client_id
            return result
    except Exception as e:
        print(f"❌ 無法連線至 ComfyUI: {e}")
        return None

def wait_for_completion(prompt_id, client_id):
    ws_url = f"ws://{server_address}/ws?clientId={client_id}"
    try:
        ws = websocket.create_connection(ws_url)
        while True:
            out = ws.recv()
            if isinstance(out, str):
                msg = json.loads(out)
                if msg.get("type") == "executing":
                    data = msg.get("data", {})
                    if data.get("node") is None and data.get("prompt_id") == prompt_id:
                        break
        ws.close()
    except Exception as e:
        print(f"❌ WebSocket 錯誤: {e}")

def find_latest_png(directory):
    png_list = [f for f in os.listdir(directory) if f.lower().endswith(".png")]
    if not png_list:
        return None
    return max(png_list, key=lambda x: os.path.getctime(os.path.join(directory, x)))

def get_history(prompt_id):
    url = f"http://{server_address}/history/{prompt_id}"
    try:
        with urllib.request.urlopen(url) as resp:
            all_data = json.loads(resp.read())
        return all_data.get(prompt_id, {})
    except:
        return {}

def get_final_image_filename(prompt_id):
    history = get_history(prompt_id)
    if history and "outputs" in history and "7" in history["outputs"]:
        for info in history["outputs"]["7"]["images"]:
            fn = info.get("filename")
            if fn and fn.lower().endswith(".png"):
                return fn
    return find_latest_png(comfyui_output_dir)

def move_output_files(prompt_id, target_folder):
    fn = get_final_image_filename(prompt_id)
    if not fn:
        return None
    src = os.path.join(comfyui_output_dir, fn)
    dst = os.path.join(target_folder, fn)
    try:
        shutil.move(src, dst)
        return fn
    except:
        return None

def apply_controlnet_params_to_workflow_text_cn(workflow, cn_params):
    # 保持原樣
    if "17" in workflow and "inputs" in workflow["17"]:
        workflow["17"]["inputs"]["detect_hand"] = cn_params.get("detect_hand", "enable")
        workflow["17"]["inputs"]["detect_body"] = cn_params.get("detect_body", "enable")
        workflow["17"]["inputs"]["detect_face"] = cn_params.get("detect_face", "disable")
    strength = float(cn_params.get("strength", 1.0))
    s_start = float(cn_params.get("start_percent", 0.0))
    s_end = float(cn_params.get("end_percent", 1.0))
    if "18" in workflow:
        for node in ["18", "23"]:
            if node in workflow and "inputs" in workflow[node]:
                workflow[node]["inputs"]["strength"] = strength
                workflow[node]["inputs"]["start_percent"] = s_start
                workflow[node]["inputs"]["end_percent"] = s_end

def apply_controlnet_params_to_workflow_image_cn(workflow, cn_params):
    # 保持原樣
    if "17" in workflow and "inputs" in workflow["17"]:
        workflow["17"]["inputs"]["detect_hand"] = cn_params.get("detect_hand", "enable")
        workflow["17"]["inputs"]["detect_body"] = cn_params.get("detect_body", "enable")
        workflow["17"]["inputs"]["detect_face"] = cn_params.get("detect_face", "disable")
    strength = float(cn_params.get("strength", 1.0))
    s_start = float(cn_params.get("start_percent", 0.0))
    s_end = float(cn_params.get("end_percent", 1.0))
    if "18" in workflow:
        for node in ["18", "23"]:
            if node in workflow and "inputs" in workflow[node]:
                workflow[node]["inputs"]["strength"] = strength
                workflow[node]["inputs"]["start_percent"] = s_start
                workflow[node]["inputs"]["end_percent"] = s_end

# -----------------------------------
# 文生模式 Endpoint（已微調）
# -----------------------------------
@app.route("/pose_control_text", methods=["POST"])
def pose_control_text():
    data = request.get_json()
    if not data or "prompt" not in data:
        return jsonify({"error": "缺少 prompt 參數"}), 400

    # 列出接收到的參數
    expected_keys = [
        "prompt", "vae_name", "checkpoint_name",
        "cfg_scale", "sampler", "scheduler",
        "denoise_strength", "seed",
        "pose_image", "control_net_params"
    ]
    received_params = {k: data.get(k) for k in expected_keys if k in data}
    print("=== Received Params (Text Mode) ===")
    for k, v in received_params.items():
        print(f"{k}: {v}")
    print("===================================")

    # 原有邏輯
    prompt_text    = data["prompt"].strip()
    cfg_scale      = int(data.get("cfg_scale", 7))
    sampler        = data.get("sampler", "dpmpp_2m_sde")
    scheduler      = data.get("scheduler", "karras")
    seed           = int(data.get("seed", 87))
    pose_image_b64 = data.get("pose_image", "").strip()
    cn_params      = data.get("control_net_params", {})

    workflow_str = WORKFLOW_TEXT_CN if pose_image_b64 else WORKFLOW_TEXT_BASE
    workflow     = json.loads(workflow_str)

    workflow["2"]["inputs"]["text"]       = prompt_text
    workflow["4"]["inputs"]["cfg"]        = cfg_scale
    workflow["4"]["inputs"]["sampler_name"] = sampler
    workflow["4"]["inputs"]["scheduler"]    = scheduler
    workflow["4"]["inputs"]["seed"]         = seed

    if pose_image_b64:
        _, enc = pose_image_b64.split(",", 1)
        pose_fn   = f"pose_{uuid.uuid4().hex}.png"
        pose_path = os.path.join(temp_dir, pose_fn)
        with open(pose_path, "wb") as f:
            f.write(base64.b64decode(enc))
        workflow["48"]["inputs"]["image_path"] = pose_path
        workflow["50"]["inputs"]["image_path"] = pose_path
        apply_controlnet_params_to_workflow_text_cn(workflow, cn_params)

    resp = queue_prompt(workflow)
    if not resp or "prompt_id" not in resp:
        return jsonify({"error": "ComfyUI 無回應"}), 500
    wait_for_completion(resp["prompt_id"], resp["client_id"])

    fn = move_output_files(resp["prompt_id"], target_dir_text)
    if not fn:
        return jsonify({"error": "搬移檔案失敗"}), 500
    image_url = f"{EXTERNAL_API_URL}/get_image/{fn}?t={int(time.time())}"

    return jsonify({
        "image_url":       image_url,
        "receivedParams":  received_params,
        "paramDescriptions": {
            "prompt":             "提示詞文字內容",
            "vae_name":           "VAE 名稱 (可選)",
            "checkpoint_name":    "Checkpoint 名稱 (可選)",
            "cfg_scale":          "CFG 強度 (數值)",
            "sampler":            "採樣器名稱",
            "scheduler":          "調度器名稱",
            "denoise_strength":   "去噪幅度 (0~1)",
            "seed":               "隨機種子數值",
            "pose_image":         "姿勢圖 Base64 (可選)",
            "control_net_params": "ControlNet 參數物件"
        }
    })

# -----------------------------------
# 圖生模式 Endpoint（已微調）
# -----------------------------------
@app.route("/pose_control_image", methods=["POST"])
def pose_control_image():
    data = request.get_json()
    if not data or "prompt" not in data or "image" not in data:
        return jsonify({"error": "缺少 prompt 或 image 參數"}), 400

    # 列出接收到的參數
    expected_keys = [
        "prompt", "vae_name", "checkpoint_name",
        "cfg_scale", "sampler", "scheduler",
        "denoise_strength", "seed",
        "image", "pose_image", "control_net_params"
    ]
    received_params = {k: data.get(k) for k in expected_keys if k in data}
    print("=== Received Params (Image Mode) ===")
    for k, v in received_params.items():
        print(f"{k}: {v}")
    print("====================================")

    # 原有邏輯
    prompt_text = data["prompt"].strip()
    main_b64    = data["image"].strip()
    cfg_scale   = int(data.get("cfg_scale", 7))
    sampler     = data.get("sampler", "dpmpp_2m_sde")
    scheduler   = data.get("scheduler", "karras")
    seed        = int(data.get("seed", 87))
    pose_b64    = data.get("pose_image", "").strip()
    cn_params   = data.get("control_net_params", {})

    workflow_str = WORKFLOW_IMAGE_CN if pose_b64 else WORKFLOW_IMAGE_BASE
    workflow     = json.loads(workflow_str)

    workflow["2"]["inputs"]["text"]         = prompt_text
    workflow["4"]["inputs"]["cfg"]          = cfg_scale
    workflow["4"]["inputs"]["sampler_name"] = sampler
    workflow["4"]["inputs"]["scheduler"]    = scheduler
    workflow["4"]["inputs"]["seed"]         = seed

    # 解碼主圖
    _, main_enc = main_b64.split(",", 1)
    main_fn     = f"main_{uuid.uuid4().hex}.png"
    main_path   = os.path.join(temp_dir, main_fn)
    with open(main_path, "wb") as f:
        f.write(base64.b64decode(main_enc))
    workflow["47"]["inputs"]["image_path"] = main_path

    # 解碼姿勢圖並套用 ControlNet
    if pose_b64:
        _, pose_enc = pose_b64.split(",", 1)
        pose_fn     = f"pose_{uuid.uuid4().hex}.png"
        pose_path   = os.path.join(temp_dir, pose_fn)
        with open(pose_path, "wb") as f:
            f.write(base64.b64decode(pose_enc))
        workflow["49"]["inputs"]["image_path"] = pose_path
        workflow["50"]["inputs"]["image_path"] = pose_path
        apply_controlnet_params_to_workflow_image_cn(workflow, cn_params)

    resp = queue_prompt(workflow)
    if not resp or "prompt_id" not in resp:
        return jsonify({"error": "ComfyUI 無回應"}), 500
    wait_for_completion(resp["prompt_id"], resp["client_id"])

    fn = move_output_files(resp["prompt_id"], target_dir_image)
    if not fn:
        return jsonify({"error": "搬移檔案失敗"}), 500
    image_url = f"{EXTERNAL_API_URL}/get_image/{fn}?t={int(time.time())}"

    return jsonify({
        "image_url":       image_url,
        "receivedParams":  received_params,
        "paramDescriptions": {
            "prompt":             "提示詞文字內容",
            "vae_name":           "VAE 名稱 (可選)",
            "checkpoint_name":    "Checkpoint 名稱 (可選)",
            "cfg_scale":          "CFG 強度 (數值)",
            "sampler":            "採樣器名稱",
            "scheduler":          "調度器名稱",
            "denoise_strength":   "去噪幅度 (0~1)",
            "seed":               "隨機種子數值",
            "image":              "主圖 Base64 編碼",
            "pose_image":         "姿勢圖 Base64 (可選)",
            "control_net_params": "ControlNet 參數物件"
        }
    })

# -----------------------------------
# 圖片代理 & 啟動 (保持原樣)
# -----------------------------------
@app.route("/get_image/<path:filename>", methods=["GET"])
def get_image(filename):
    t_path = os.path.join(target_dir_text, filename)
    i_path = os.path.join(target_dir_image, filename)
    if os.path.exists(t_path):
        resp = make_response(send_from_directory(target_dir_text, filename))
    elif os.path.exists(i_path):
        resp = make_response(send_from_directory(target_dir_image, filename))
    else:
        return jsonify({"error": "檔案不存在"}), 404
    resp.headers["Cache-Control"] = "no-store, no-cache, must-revalidate, max-age=0"
    resp.headers["Pragma"]        = "no-cache"
    return resp

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5005, debug=False)


=== 創意QRcode.py ===
import os
import json
import shutil
import time
import uuid
import base64
import urllib.request
import urllib.error
import websocket
import qrcode

from io import BytesIO
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS

app = Flask(__name__)
CORS(app)

# =============================
# 基本設定
# =============================

# ComfyUI 伺服器位址（請確認此位址與埠號正確）
SERVER_ADDRESS = "127.0.0.1:8188"

# 定義全域 CLIENT_ID，用於識別本服務發送的請求（生成一次即可）
CLIENT_ID = str(uuid.uuid4())

# ComfyUI 的輸出目錄（儲存生成圖片的目錄）
COMFYUI_OUTPUT_DIR = r"D:\comfyui\ComfyUI_windows_portable\ComfyUI\output"

# 目標目錄，用來儲存最終搬移過來的圖片
TARGET_DIR = r"D:\大模型qcode"
os.makedirs(TARGET_DIR, exist_ok=True)

# 用於暫存生成或上傳的 QR Code 圖片的資料夾
TEMP_FOLDER = r"D:\大模型qcode\temp"
os.makedirs(TEMP_FOLDER, exist_ok=True)

# 前端不使用預設 QR Code 網址，由前端傳入
DEFAULT_QR_CODE_URL = ""

# =============================
# 外網域名（用於回傳圖片 URL）
# =============================
EXTERNAL_URL = "https://qrcode.picturesmagician.com"

# =============================
# A. 生成 QR Code 的函式
# =============================
def generate_qr_code(url, output_file):
    qr = qrcode.QRCode(
        version=3,
        error_correction=qrcode.constants.ERROR_CORRECT_H,
        box_size=10,
        border=2
    )
    qr.add_data(url, optimize=True)
    qr.make(fit=True)
    img = qr.make_image(fill_color="black", back_color="white")
    img.save(output_file)
    print(f"✅ QR Code 已儲存: {output_file}")

# =============================
# B. 與 ComfyUI 互動的相關函式
# =============================
def queue_prompt(prompt):
    payload = {"prompt": prompt, "client_id": CLIENT_ID}
    data = json.dumps(payload).encode("utf-8")
    url = f"http://{SERVER_ADDRESS}/prompt"
    try:
        req = urllib.request.Request(url, data=data, headers={"Content-Type": "application/json"})
        with urllib.request.urlopen(req) as resp:
            result = json.loads(resp.read())
            result["client_id"] = CLIENT_ID
            return result
    except Exception as e:
        print(f"❌ 無法連線至 ComfyUI API: {e}")
        return None

def wait_for_completion(prompt_id):
    ws_url = f"ws://{SERVER_ADDRESS}/ws?clientId={CLIENT_ID}"
    print("🕐 等待 ComfyUI 任務完成...")
    try:
        ws = websocket.create_connection(ws_url)
        while True:
            out = ws.recv()
            if isinstance(out, str):
                message = json.loads(out)
                if message.get("type") == "executing":
                    data = message.get("data", {})
                    if data.get("node") is None and data.get("prompt_id") == prompt_id:
                        print("✅ 任務已完成！")
                        break
        ws.close()
    except Exception as e:
        print(f"❌ WebSocket 連線錯誤: {e}")

def get_history(prompt_id):
    url = f"http://{SERVER_ADDRESS}/history/{prompt_id}"
    try:
        with urllib.request.urlopen(url) as resp:
            history_data = json.loads(resp.read())
        print(f"📜 Debug: history API 回應 = {json.dumps(history_data, indent=4, ensure_ascii=False)}")
        return history_data.get(prompt_id, {})
    except Exception as e:
        print(f"❌ 無法取得歷史紀錄: {e}")
        return {}

def find_latest_png():
    png_files = [f for f in os.listdir(COMFYUI_OUTPUT_DIR) if f.lower().endswith(".png")]
    if not png_files:
        print("🚫 找不到任何 .png 檔案！")
        return None
    latest_png = max(png_files, key=lambda f: os.path.getctime(os.path.join(COMFYUI_OUTPUT_DIR, f)))
    print(f"🎞 找到最新的 .png 檔案: {latest_png}")
    return latest_png

def get_final_image_filename(prompt_id):
    history = get_history(prompt_id)
    if not history:
        print("⚠️ /history API 回應為空，改用檔案搜尋。")
        return find_latest_png()
    outputs = history.get("outputs", {})
    image_node = outputs.get("31", {})
    if "images" in image_node:
        for info in image_node["images"]:
            filename = info.get("filename")
            if filename and filename.lower().endswith(".png"):
                print(f"🎞 從 API 取得圖片檔名: {filename}")
                return filename
    print("⚠️ /history API 未提供圖片檔名，改用檔案搜尋。")
    return find_latest_png()

def move_output_files(prompt_id):
    image_filename = get_final_image_filename(prompt_id)
    if not image_filename:
        print("🚫 無法取得圖片檔案名稱！")
        return None
    source_path = os.path.join(COMFYUI_OUTPUT_DIR, image_filename)
    target_path = os.path.join(TARGET_DIR, image_filename)
    if not os.path.exists(source_path):
        print(f"⚠️ 找不到 {source_path}，無法搬移！")
        return None
    try:
        shutil.move(source_path, target_path)
        print(f"✅ 已搬移: {source_path} → {target_path}")
        return image_filename
    except Exception as e:
        print(f"❌ 搬移失敗: {e}")
        return None

# =============================
# C. Flask API Endpoint：/convert-image
# =============================
@app.route("/convert-image", methods=["POST"])
def convert_image_endpoint():
    data = request.get_json(force=True)
    if not data or "prompt" not in data:
        return jsonify({"error": "缺少必要的參數"}), 400

    # 1. 先讀 conversionType 並處理 QR 圖片來源
    conversionType = data.get("conversionType", "text").strip()
    if conversionType == "text":
        qrUrl = data.get("qrUrl", "").strip()
        if not qrUrl:
            return jsonify({"error": "請提供 QR Code 網址！"}), 400
        qr_output_file = os.path.join(TEMP_FOLDER, f"qr_{uuid.uuid4().hex}.png")
        try:
            generate_qr_code(qrUrl, qr_output_file)
        except Exception as e:
            return jsonify({"error": f"QR Code 生成失敗: {e}"}), 500
        qr_image_path = qr_output_file
    elif conversionType == "image":
        qr_image_b64 = data.get("qrImage", "").strip()
        if not qr_image_b64:
            return jsonify({"error": "圖生模式下未提供圖片"}), 400
        try:
            header, encoded = qr_image_b64.split(",", 1)
        except Exception as e:
            return jsonify({"error": f"無效的圖片資料: {e}"}), 400
        file_ext = "jpg" if ("jpeg" in header or "jpg" in header) else "png"
        qr_output_file = os.path.join(TEMP_FOLDER, f"qr_{uuid.uuid4().hex}.{file_ext}")
        try:
            with open(qr_output_file, "wb") as f:
                f.write(base64.b64decode(encoded))
        except Exception as e:
            return jsonify({"error": f"圖片儲存失敗: {e}"}), 500
        qr_image_path = qr_output_file
    else:
        return jsonify({"error": "無效的 conversionType"}), 400

    # 2. 讀取其餘參數
    prompt_text      = data.get("prompt", "").strip()
    cfg_scale        = int(data.get("cfgScale", 7)) if str(data.get("cfgScale", "")).isdigit() else 7
    sampler_name     = data.get("samplerName", "euler")
    scheduler        = data.get("scheduler", "karras")
    seed_val         = data.get("seed", "").strip()
    try:
        seed = int(seed_val) if seed_val else int(uuid.uuid4().int % 1000000)
    except:
        seed = int(uuid.uuid4().int % 1000000)

    # 新增：讀取 ControlNet 參數與新版欄位
    qrcode_strength   = float(data.get("qrcodeStrength", 1.3))
    qrcode_start      = float(data.get("qrcodeStart", 0.1))
    qrcode_end        = float(data.get("qrcodeEnd", 0.9))
    vae_name          = data.get("vaeName", "").strip()
    checkpoint_name   = data.get("checkpointName", "").strip()

    # 3. 列印所有參數，方便除錯
    print("=== 收到參數設定 ===")
    print(f"conversionType: {conversionType}")
    if conversionType == "text":
        print(f"qrUrl: {qrUrl}")
    else:
        print(f"qrImage: <base64 length {len(data.get('qrImage',''))}>")
    print(f"prompt: {prompt_text}")
    print(f"CFG 強度: {cfg_scale}")
    print(f"採樣器: {sampler_name}")
    print(f"調度器: {scheduler}")
    print(f"種子: {seed}")
    print(f"qrcodeStrength: {qrcode_strength}")
    print(f"qrcodeStart: {qrcode_start}")
    print(f"qrcodeEnd: {qrcode_end}")
    print(f"vaeName: {vae_name}")
    print(f"checkpointName: {checkpoint_name}")
    print("====================")

    # 4. 載入既有 workflow 模板
    workflow = json.loads(r"""
{
  "2": {
    "inputs": {
      "strength": 1.3,
      "start_percent": 0.1,
      "end_percent": 0.9,
      "positive": ["10", 0],
      "negative": ["11", 0],
      "control_net": ["3", 0],
      "image": ["30", 0]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {"title": "ControlNet應用(進階)"}
  },
  "3": {
    "inputs": {"control_net_name": "sd1.5_qrcode.safetensors"},
    "class_type": "ControlNetLoader",
    "_meta": {"title": "ControlNet載入器"}
  },
  "8": {
    "inputs": {
      "b1": 1.3,
      "b2": 1.4,
      "s1": 0.9,
      "s2": 0.2,
      "model": ["26", 0]
    },
    "class_type": "FreeU_V2",
    "_meta": {"title": "FreeU_V2"}
  },
  "9": {
    "inputs": {
      "seed": 249753754870844,
      "steps": 50,
      "cfg": 6,
      "sampler_name": "dpmpp_2m_sde",
      "scheduler": "karras",
      "denoise": 1,
      "model": ["8", 0],
      "positive": ["2", 0],
      "negative": ["2", 1],
      "latent_image": ["12", 0]
    },
    "class_type": "KSampler",
    "_meta": {"title": "K採樣器"}
  },
  "10": {
    "inputs": {"text": "house", "clip": ["26", 1]},
    "class_type": "CLIPTextEncode",
    "_meta": {"title": "CLIP文本編碼器"}
  },
  "11": {
    "inputs": {
      "text": "embedding:EasyNegative, embedding:bad_prompt_version2-neg, embedding:verybadimagenegative_v1.3, ",
      "clip": ["26", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {"title": "CLIP文本編碼器"}
  },
  "12": {
    "inputs": {"width": ["25", 0], "height": ["25", 0], "batch_size": 1},
    "class_type": "EmptyLatentImage",
    "_meta": {"title": "空Latent"}
  },
  "13": {
    "inputs": {"image": ["30", 0]},
    "class_type": "GetImageSize+",
    "_meta": {"title": "🔧 Get Image Size"}
  },
  "15": {
    "inputs": {"samples": ["9", 0], "vae": ["17", 0]},
    "class_type": "VAEDecode",
    "_meta": {"title": "VAE解碼"}
  },
  "16": {
    "inputs": {"images": ["15", 0]},
    "class_type": "PreviewImage",
    "_meta": {"title": "預覽圖像"}
  },
  "17": {
    "inputs": {"vae_name": "kl-f8-anime2.safetensors"},
    "class_type": "VAELoader",
    "_meta": {"title": "VAE載入器"}
  },
  "25": {
    "inputs": {"value": 860},
    "class_type": "INTConstant",
    "_meta": {"title": "INT Constant"}
  },
  "26": {
    "inputs": {"ckpt_name": "meinamix_v12Final.safetensors"},
    "class_type": "CheckpointLoaderSimple",
    "_meta": {"title": "Checkpoint載入器(簡易)"}
  },
  "30": {
    "inputs": {
      "image": "E:/sd_qr_output/optimized_qr_code.png",
      "force_size": "Disabled",
      "custom_width": 512,
      "custom_height": 512
    },
    "class_type": "VHS_LoadImagePath",
    "_meta": {"title": "Load Image (Path)"}
  },
  "31": {
    "inputs": {"filename_prefix": "qrcode", "images": ["15", 0]},
    "class_type": "SaveImage",
    "_meta": {"title": "儲存圖像"}
  }
}
""")

    # 5. 注入動態參數到 workflow
    workflow["10"]["inputs"]["text"]      = prompt_text
    workflow["9"]["inputs"]["cfg"]        = cfg_scale
    workflow["9"]["inputs"]["sampler_name"] = sampler_name
    workflow["9"]["inputs"]["scheduler"] = scheduler
    workflow["9"]["inputs"]["seed"]      = seed

    # 注入 ControlNet 參數
    workflow["2"]["inputs"]["strength"]      = qrcode_strength
    workflow["2"]["inputs"]["start_percent"] = qrcode_start
    workflow["2"]["inputs"]["end_percent"]   = qrcode_end

    # 注入 VAE 與 Checkpoint
    workflow["17"]["inputs"]["vae_name"]    = vae_name
    workflow["26"]["inputs"]["ckpt_name"]   = checkpoint_name

    # 更新節點 "30" 的 image 路徑
    workflow["30"]["inputs"]["image"] = qr_image_path.replace("\\", "/")

    print("🚀 發送工作流程到 ComfyUI：")
    print(json.dumps(workflow, indent=4, ensure_ascii=False))

    response = queue_prompt(workflow)
    if not response or "prompt_id" not in response:
        return jsonify({"error": "API 回應錯誤，請檢查 ComfyUI 是否在運行"}), 500

    prompt_id = response["prompt_id"]
    print(f"🆔 取得 prompt_id: {prompt_id}")

    wait_for_completion(prompt_id)

    print("✅ 任務已完成，開始搬移輸出圖片。")
    output_filename = move_output_files(prompt_id)
    if not output_filename:
        return jsonify({"error": "搬移圖片失敗"}), 500

    image_url = EXTERNAL_URL + "/get_image/" + output_filename + f"?t={int(time.time())}"
    return jsonify({"image_url": image_url})

@app.route("/get_image/<filename>", methods=["GET"])
def get_image(filename):
    return send_from_directory(TARGET_DIR, filename)

# 新增 /image_to_image 路由，供 ComfyUI 在工作流程中讀取圖片檔案
@app.route("/image_to_image", methods=["POST"])
def load_image():
    data = request.get_json(force=True)
    image_path = data.get("image")
    if not image_path or not os.path.exists(image_path):
        return jsonify({"error": "圖像路徑不存在"}), 404
    ext = os.path.splitext(image_path)[1].lower()
    mimetype = "image/png" if ext == ".png" else "image/jpeg"
    with open(image_path, "rb") as f:
        content = f.read()
    return content, 200, {"Content-Type": mimetype}

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5004, debug=False)


=== 創意繪畫.py ===
import json
import os
import shutil
import time
import uuid
import websocket  # pip install websocket-client
import urllib.request
import urllib.error
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from werkzeug.utils import secure_filename
import base64

app = Flask(__name__)
CORS(app)

# =============================
# ComfyUI 伺服器與資料夾設定
# =============================
server_address   = "127.0.0.1:8188"  # ComfyUI 伺服器位址（假設在本機）
comfyui_output_dir = r"D:\comfyui\ComfyUI_windows_portable\ComfyUI\output"
target_dir       = r"D:\大模型圖生圖"
temp_input_dir   = r"D:\大模型圖生圖\temp_input"  # 用於暫存前端繪製圖像
os.makedirs(target_dir, exist_ok=True)
os.makedirs(temp_input_dir, exist_ok=True)

# 外網對外提供的域名（例如 Cloudflare Tunnel 提供的 HTTPS 網域）
EXTERNAL_URL     = "https://draw.picturesmagician.com"

# =============================
# 工具函數：Queue、等待、歷史紀錄、文件搬移等
# =============================
def queue_prompt(prompt):
    client_id = str(uuid.uuid4())
    payload   = {"prompt": prompt, "client_id": client_id}
    data      = json.dumps(payload).encode("utf-8")
    url       = f"http://{server_address}/prompt"
    try:
        req = urllib.request.Request(url, data=data, headers={"Content-Type": "application/json"})
        with urllib.request.urlopen(req) as resp:
            result = json.loads(resp.read())
            result["client_id"] = client_id
            return result
    except urllib.error.HTTPError as e:
        error_body = e.read().decode()
        print(f"❌ HTTPError: {e.code} {error_body}")
        return None
    except Exception as e:
        print(f"❌ 無法連線至 ComfyUI API: {e}")
        return None

def wait_for_completion(prompt_id, client_id):
    ws_url = f"ws://{server_address}/ws?clientId={client_id}"
    print("🕐 等待 ComfyUI 任務完成...")
    try:
        ws = websocket.create_connection(ws_url)
        while True:
            out = ws.recv()
            if isinstance(out, str):
                message = json.loads(out)
                if message.get("type") == "executing":
                    data = message.get("data", {})
                    if data.get("node") is None and data.get("prompt_id") == prompt_id:
                        print("✅ 任務已完成！")
                        break
        ws.close()
    except Exception as e:
        print(f"❌ WebSocket 連線錯誤: {e}")

def get_history(prompt_id):
    url = f"http://{server_address}/history/{prompt_id}"
    try:
        with urllib.request.urlopen(url) as resp:
            history_data = json.loads(resp.read())
        print(f"📜 history API 回應:\n{json.dumps(history_data, indent=4, ensure_ascii=False)}")
        return history_data.get(prompt_id, {})
    except Exception as e:
        print(f"❌ 無法取得歷史紀錄: {e}")
        return {}

def find_latest_png():
    png_files = [f for f in os.listdir(comfyui_output_dir) if f.lower().endswith(".png")]
    if not png_files:
        print("🚫 找不到任何 .png 檔案！")
        return None
    latest_png = max(png_files, key=lambda f: os.path.getctime(os.path.join(comfyui_output_dir, f)))
    print(f"🎞 找到最新的 .png 檔案: {latest_png}")
    return latest_png

def get_final_image_filename(prompt_id):
    history = get_history(prompt_id)
    if not history:
        print("⚠️ history API 回應为空，改用檔案搜尋。")
        return find_latest_png()
    outputs    = history.get("outputs", {})
    image_node = outputs.get("7", {})
    if "images" in image_node:
        for info in image_node["images"]:
            filename = info.get("filename")
            if filename and filename.lower().endswith(".png"):
                print(f"🎞 從 API 取得圖片檔名: {filename}")
                return filename
    print("⚠️ API 未提供圖片檔名，改用檔案搜尋。")
    return find_latest_png()

def move_output_files(prompt_id):
    image_filename = get_final_image_filename(prompt_id)
    if not image_filename:
        print("🚫 無法取得圖片檔案名稱！")
        return None
    source_path = os.path.join(comfyui_output_dir, image_filename)
    target_path = os.path.join(target_dir, image_filename)
    if not os.path.exists(source_path):
        print(f"⚠️ 找不到 {source_path}，無法搬移！")
        return None
    try:
        shutil.move(source_path, target_path)
        print(f"✅ 已搬移: {source_path} → {target_path}")
        return image_filename
    except Exception as e:
        print(f"❌ 搬移失敗: {e}")
        return None

# =============================
# 創意繪畫 API Endpoint
# =============================
@app.route("/convert-image", methods=["POST"])
def convert_image_endpoint():
    # force=True 確保解析 JSON
    data = request.get_json(force=True)

    # —— 修改處：列印完整 payload ——  
    print("▶ Received payload:", json.dumps(data, ensure_ascii=False))

    if not data or "image" not in data:
        return jsonify({"error": "未提供圖像資料"}), 400

    image_base64 = data["image"]
    try:
        header, encoded = image_base64.split(",", 1)
    except Exception as e:
        return jsonify({"error": "圖像資料格式錯誤", "details": str(e)}), 400

    file_ext = "png"
    if "jpeg" in header or "jpg" in header:
        file_ext = "jpg"
    try:
        file_bytes = base64.b64decode(encoded)
    except Exception as e:
        return jsonify({"error": "Base64 解碼錯誤", "details": str(e)}), 400

    filename = f"upload_{uuid.uuid4().hex}.{file_ext}"
    input_image_path = os.path.join(temp_input_dir, filename)
    with open(input_image_path, "wb") as f:
        f.write(file_bytes)
    print(f"✅ 已儲存繪製圖像：{input_image_path}")

    # —— 修改處：完整讀取前端所有參數 ——  
    cfg_scale        = data.get("cfgScale", "7")
    sampler_name     = data.get("samplerName", "euler")
    scheduler        = data.get("scheduler", "karras")
    denoise_strength = data.get("denoiseStrength", "0.7")
    vae_name         = data.get("vaeName", "kl-f8-anime2.safetensors")
    ckpt_name        = data.get("checkpointName", "meinamix_v12Final.safetensors")
    seed             = data.get("seed", "")
    prompt_text      = data.get("prompt", "").strip()

    # 型別轉換
    try:
        cfg_scale = int(cfg_scale)
    except:
        cfg_scale = 7
    try:
        denoise_strength = float(denoise_strength)
    except:
        denoise_strength = 0.7
    try:
        seed = int(seed) if seed != "" else int(uuid.uuid4().int % 1000000)
    except:
        seed = int(uuid.uuid4().int % 1000000)

    # —— 修改處：列印所有參數 ——  
    print("✅ 收到參數設定：")
    print(f"  • VAE 名稱         : {vae_name}")
    print(f"  • Checkpoint 名稱 : {ckpt_name}")
    print(f"  • CFG 強度        : {cfg_scale}")
    print(f"  • 採樣器           : {sampler_name}")
    print(f"  • 調度器           : {scheduler}")
    print(f"  • 去躁幅度         : {denoise_strength}")
    print(f"  • 隨機種子         : {seed}")
    print(f"  • 提示詞           : {prompt_text}")
    # — 修改處結束 —

    # 工作流程 JSON 模板
    workflow_template = r"""
{
  "1": {
    "inputs": {
      "ckpt_name": "meinamix_v12Final.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {"title": "Checkpoint加载器（简易）"}
  },
  "2": {
    "inputs": {
      "text": "a girl",
      "clip": ["1", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {"title": "正向提示詞"}
  },
  "3": {
    "inputs": {
      "text": "(low quality, worst quality, text, letterboxed:1.4), (deformed, distorted, disfigured:1.3), easynegative, hands, bad-hands-5, blurry, ugly, embedding:easynegative",
      "clip": ["1", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {"title": "反向提示詞"}
  },
  "4": {
    "inputs": {
      "seed": 0,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "dpmpp_2m_sde",
      "scheduler": "karras",
      "denoise": 0.7,
      "model": ["1", 0],
      "positive": ["2", 0],
      "negative": ["3", 0],
      "latent_image": ["14", 0]
    },
    "class_type": "KSampler",
    "_meta": {"title": "K采样器"}
  },
  "7": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": ["8", 0]
    },
    "class_type": "SaveImage",
    "_meta": {"title": "保存图像"}
  },
  "8": {
    "inputs": {
      "samples": ["4", 0],
      "vae": ["9", 0]
    },
    "class_type": "VAEDecode",
    "_meta": {"title": "VAE解码"}
  },
  "9": {
    "inputs": {"vae_name": "kl-f8-anime2.safetensors"},
    "class_type": "VAELoader",
    "_meta": {"title": "加载VAE"}
  },
  "14": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "width": 512,
      "height": 512,
      "crop": "disabled",
      "samples": ["13", 0]
    },
    "class_type": "LatentUpscale",
    "_meta": {"title": "缩放Latent"}
  },
  "13": {
    "inputs": {
      "pixels": ["17", 0],
      "vae": ["9", 0]
    },
    "class_type": "VAEEncode",
    "_meta": {"title": "VAE编码"}
  },
  "17": {
    "inputs": {
      "image": "",
      "force_size": "Disabled",
      "custom_width": 512,
      "custom_height": 512
    },
    "class_type": "LoadImage",
    "_meta": {"title": "Load Image (Path)"}
  }
}
""".strip()
    try:
        workflow = json.loads(workflow_template)
    except Exception as e:
        return jsonify({"error": "工作流程 JSON 格式錯誤", "details": str(e)}), 500

    # —— 修改處：套用所有參數到工作流程 ——  
    workflow["1"]["inputs"]["ckpt_name"]     = ckpt_name
    workflow["9"]["inputs"]["vae_name"]      = vae_name
    workflow["4"]["inputs"]["cfg"]           = cfg_scale
    workflow["4"]["inputs"]["sampler_name"]  = sampler_name
    workflow["4"]["inputs"]["scheduler"]     = scheduler
    workflow["4"]["inputs"]["denoise"]       = denoise_strength
    workflow["4"]["inputs"]["seed"]          = seed
    workflow["17"]["inputs"]["image"]        = input_image_path
    if prompt_text:
        workflow["2"]["inputs"]["text"]      = prompt_text
    # — 修改處結束 —

    print("🚀 發送工作流程至 ComfyUI：")
    print(json.dumps(workflow, indent=4, ensure_ascii=False))

    response = queue_prompt(workflow)
    if not response or "prompt_id" not in response:
        return jsonify({"error": "API 回應錯誤，請檢查 ComfyUI 是否在運行"}), 500

    prompt_id = response["prompt_id"]
    client_id = response["client_id"]
    print(f"🆔 取得 prompt_id: {prompt_id}")

    wait_for_completion(prompt_id, client_id)

    print("✅ 任務完成，開始搬移輸出圖片。")
    output_filename = move_output_files(prompt_id)
    if not output_filename:
        return jsonify({"error": "搬移圖片失敗"}), 500

    # 使用外網域名組成圖片 URL
    image_url = EXTERNAL_URL + "/get_image/" + output_filename + f"?t={int(time.time())}"
    return jsonify({"image_url": image_url})

@app.route("/get_image/<filename>", methods=["GET"])
def get_image(filename):
    return send_from_directory(target_dir, filename)

# 新增 /image_to_image 路由，供 ComfyUI 讀取圖片檔案（若工作流程中 LoadImage 觸發）
@app.route("/image_to_image", methods=["POST"])
def load_image():
    data = request.get_json(force=True)
    image_path = data.get("image")
    if not image_path or not os.path.exists(image_path):
        return jsonify({"error": "圖像路徑不存在"}), 404
    ext = os.path.splitext(image_path)[1].lower()
    mimetype = "image/png" if ext == ".png" else "image/jpeg"
    with open(image_path, "rb") as f:
        content = f.read()
    return content, 200, {"Content-Type": mimetype}

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5003, debug=False)


=== 反推提示詞.py ===
import json
import os
import shutil
import time
import websocket  # 請確保已安裝 websocket-client (pip install websocket-client)
import urllib.request
import uuid
import base64  # 新增 base64 模組
from flask import Flask, request, jsonify, send_from_directory, make_response
from flask_cors import CORS
from PIL import Image, PngImagePlugin  # 用來嵌入 dummy metadata

app = Flask(__name__)
CORS(app)

# =============================
# 設定區 (可考慮改用環境變數)
# =============================
# ComfyUI 伺服器與資料夾設定
SERVER_ADDRESS = "127.0.0.1:8188"  # ComfyUI 伺服器位址
COMFYUI_OUTPUT_DIR = r"D:\comfyui\ComfyUI_windows_portable\ComfyUI\output"  # ComfyUI 輸出資料夾路徑
TARGET_DIR = r"D:\圖像反推"  # 目標資料夾路徑，將搬移 txt 文檔到此處
os.makedirs(TARGET_DIR, exist_ok=True)

# 上傳圖片暫存資料夾 (若需要，可新增)
TEMP_DIR = r"D:\大模型\temp_input"
os.makedirs(TEMP_DIR, exist_ok=True)

# 外部對應域名 (供前端存取圖片用)
EXTERNAL_API_URL = "https://reverseprompt.picturesmagician.com"

# WebSocket 等待超時秒數
WS_TIMEOUT = 180

# =============================
# 輔助函式
# =============================

def queue_prompt(prompt):
    """
    將工作流程 (Workflow) JSON 送往 ComfyUI 的 /prompt API，
    並回傳包含 prompt_id 與任務專用 client_id 的結果。
    """
    client_id = str(uuid.uuid4())
    payload = {
        "prompt": prompt,
        "client_id": client_id
    }
    data = json.dumps(payload).encode("utf-8")
    url = f"http://{SERVER_ADDRESS}/prompt"
    try:
        req = urllib.request.Request(url, data=data, headers={"Content-Type": "application/json"})
        with urllib.request.urlopen(req, timeout=60) as resp:
            result = json.loads(resp.read())
            result["client_id"] = client_id
            return result
    except Exception as e:
        print(f"❌ 無法連線至 ComfyUI API: {e}")
        return None

def wait_for_completion(prompt_id, client_id):
    """
    建立 WebSocket 連線以監聽指定 prompt_id 的執行狀態，
    當收到 'executing' 訊息，且其中的 node 為 None 且 prompt_id 相符時，
    表示該流程已完成。
    加入超時處理避免無限等待。
    """
    ws_url = f"ws://{SERVER_ADDRESS}/ws?clientId={client_id}"
    print("🕐 等待 ComfyUI 任務完成...")
    start_time = time.time()
    try:
        ws = websocket.create_connection(ws_url, timeout=30)
        while True:
            if time.time() - start_time > WS_TIMEOUT:
                print("⚠️ 等待任務超時")
                break
            out = ws.recv()
            if isinstance(out, str):
                try:
                    message = json.loads(out)
                except Exception as e:
                    print(f"❌ JSON 解碼錯誤: {e}")
                    continue
                if message.get("type") == "executing":
                    data = message.get("data", {})
                    if data.get("node") is None and data.get("prompt_id") == prompt_id:
                        print("✅ 任務已完成！")
                        break
        ws.close()
    except Exception as e:
        print(f"❌ WebSocket 連線錯誤: {e}")

def get_history(prompt_id):
    """
    透過 /history/<prompt_id> API 取得該任務的輸出紀錄，
    並回傳相對應的 JSON 資料。
    """
    url = f"http://{SERVER_ADDRESS}/history/{prompt_id}"
    try:
        with urllib.request.urlopen(url, timeout=30) as resp:
            history_data = json.loads(resp.read())
        print(f"📜 Debug: history API 回應 = {json.dumps(history_data, indent=4, ensure_ascii=False)}")
        return history_data.get(prompt_id, {})
    except Exception as e:
        print(f"❌ 無法取得歷史紀錄: {e}")
        return {}

def find_latest_txt():
    """
    若 /history API 未提供有效檔名，則於 ComfyUI 輸出資料夾中搜尋最新建立的 .txt 檔案。
    """
    try:
        txt_files = [f for f in os.listdir(COMFYUI_OUTPUT_DIR) if f.lower().endswith(".txt")]
    except Exception as e:
        print(f"❌ 無法讀取輸出目錄: {e}")
        return None
    if not txt_files:
        print("🚫 找不到任何 .txt 檔案！")
        return None
    latest_txt = max(txt_files, key=lambda f: os.path.getctime(os.path.join(COMFYUI_OUTPUT_DIR, f)))
    print(f"🎞 找到最新的 .txt 檔案: {latest_txt}")
    return latest_txt

def get_final_text_filename(prompt_id):
    """
    嘗試從 /history/<prompt_id> 的回應中取得最終儲存的文本檔案名稱，
    若無法取得，則改用檔案搜尋方式取得最新 .txt 檔案。
    """
    history = get_history(prompt_id)
    if not history:
        print("⚠️ /history API 回應為空，改用檔案搜尋。")
        return find_latest_txt()
    outputs = history.get("outputs", {})
    text_node = outputs.get("4", {})
    if "images" in text_node:
        for info in text_node["images"]:
            filename = info.get("filename")
            if filename and filename.lower().endswith(".txt"):
                print(f"🎞 從 API 取得文本檔名: {filename}")
                return filename
    print("⚠️ /history API 未提供文本檔名，改用檔案搜尋。")
    return find_latest_txt()

def move_output_files(prompt_id):
    """
    取得最終儲存的文本檔名後，將該 .txt 檔從 ComfyUI 輸出資料夾搬移至指定目標資料夾中。
    """
    text_filename = get_final_text_filename(prompt_id)
    if not text_filename:
        print("🚫 無法取得文本檔案名稱！")
        return None
    source_path = os.path.join(COMFYUI_OUTPUT_DIR, text_filename)
    target_path = os.path.join(TARGET_DIR, text_filename)
    if not os.path.exists(source_path):
        print(f"⚠️ 找不到 {source_path}，無法搬移！")
        return None
    try:
        shutil.move(source_path, target_path)
        print(f"✅ 已搬移: {source_path} → {target_path}")
        return text_filename
    except Exception as e:
        print(f"❌ 搬移失敗: {e}")
        return None

# =============================
# 定義 API 工作流程 (Workflow) JSON
# =============================
prompt_text = r"""
{
  "2": {
    "inputs": {
      "model": "wd-v1-4-moat-tagger-v2",
      "threshold": 0.35,
      "character_threshold": 0.85,
      "replace_underscore": false,
      "trailing_comma": false,
      "exclude_tags": "",
      "tags": "outdoors, sky, day, tree, no_humans, grass, plant, building, scenery, fence, road, bush, house",
      "image": [
        "5",
        0
      ]
    },
    "class_type": "WD14Tagger|pysssss",
    "_meta": {
      "title": "WD14圖像反推提詞"
    }
  },
  "3": {
    "inputs": {
      "text": [
        "2",
        0
      ],
      "text2": "outdoors, sky, day, tree, no_humans, grass, plant, building, scenery, fence, road, bush, house"
    },
    "class_type": "ShowText|pysssss",
    "_meta": {
      "title": "顯示文本"
    }
  },
  "4": {
    "inputs": {
      "text": [
        "3",
        0
      ],
      "path": "./ComfyUI/output",
      "filename_prefix": "ComfyUI",
      "filename_delimiter": "_",
      "filename_number_padding": 4,
      "file_extension": ".txt",
      "encoding": "utf-8",
      "filename_suffix": ""
    },
    "class_type": "Save Text File",
    "_meta": {
      "title": "儲存文本"
    }
  },
  "5": {
    "inputs": {
      "image_path": "C:\\Users\\User\\Desktop\\00001-2890787883.png"
    },
    "class_type": "ZwngLoadImagePathOrURL",
    "_meta": {
      "title": "Load Image Path or URL"
    }
  },
  "6": {
    "inputs": {
      "images": [
        "5",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "預覽圖像"
    }
  }
}
"""

try:
    workflow = json.loads(prompt_text)
except json.decoder.JSONDecodeError as e:
    print(f"❌ JSON 格式錯誤: {e}")
    exit()

# =============================
# 修改工作流程中的參數
# =============================
workflow["2"]["inputs"]["threshold"] = 0.35
workflow["2"]["inputs"]["character_threshold"] = 0.85

# =============================
# Flask 路由
# =============================

@app.route("/reverse_prompt", methods=["POST"])
def reverse_prompt():
    """
    接收前端傳來的圖像（base64 格式，JSON key 為 "image"），
    將圖像存至暫存目錄，更新工作流程中節點 "5" 的 image_path，
    呼叫 ComfyUI 產生反推文本，
    搬移生成的文本檔至目標資料夾，
    並回傳對外的 HTTPS 連結。
    """
    data = request.get_json()
    if not data or "image" not in data:
        return jsonify({"error": "缺少 image 參數"}), 400

    # 前端上傳圖像 (base64 格式) 解碼後存檔
    try:
        image_data = data["image"]
        # 輸出除錯用：檢查是否包含 base64 前綴
        print("🔹 收到圖片資料:", image_data[:30])
        if "," in image_data:
            header, encoded = image_data.split(",", 1)
        else:
            encoded = image_data
        filename = f"reverse_{uuid.uuid4().hex}.png"
        image_path = os.path.join(TEMP_DIR, filename)
        with open(image_path, "wb") as f:
            f.write(base64.b64decode(encoded))
        print(f"✅ 上傳圖像存檔：{image_path}")

        # 利用 Pillow 嵌入 dummy workflow metadata 避免 ComfyUI 檢查 extra_pnginfo 時出錯
        try:
            with Image.open(image_path) as im:
                metadata = PngImagePlugin.PngInfo()
                metadata.add_text("workflow", "{}")
                im.save(image_path, pnginfo=metadata)
            print("✅ 嵌入 dummy workflow metadata 成功")
        except Exception as e:
            print(f"❌ 嵌入 metadata 失敗: {e}")
    except Exception as e:
        return jsonify({"error": "圖像解碼失敗", "details": str(e)}), 400

    # 更新工作流程中節點 "5" 的 image_path
    workflow["5"]["inputs"]["image_path"] = image_path

    # 若前端有其他參數 (例如 threshold)，可在此更新
    workflow["2"]["inputs"]["threshold"] = float(data.get("threshold", 0.35))
    workflow["2"]["inputs"]["character_threshold"] = float(data.get("character_threshold", 0.85))

    # 呼叫 ComfyUI
    print("🚀 發送工作流程到 ComfyUI...")
    resp = queue_prompt(workflow)
    if not resp or "prompt_id" not in resp:
        return jsonify({"error": "ComfyUI API 回應錯誤"}), 500

    prompt_id = resp["prompt_id"]
    client_id = resp["client_id"]
    print(f"🆔 取得 prompt_id: {prompt_id}")

    # 等待工作流程完成
    wait_for_completion(prompt_id, client_id)
    time.sleep(2)  # 可根據情況微調等待時間

    # 取得並搬移生成的文本檔案
    final_filename = move_output_files(prompt_id)
    if not final_filename:
        return jsonify({"error": "搬移檔案失敗，未取得文本檔名"}), 500

    # 組合對外網址 (加入時間戳避免快取問題)
    text_url = f"{EXTERNAL_API_URL}/get_image/{final_filename}?t={int(time.time())}"
    print("🔹 回傳文本 URL:", text_url)
    return jsonify({"text_url": text_url})

@app.route("/get_image/<path:filename>", methods=["GET"])
def get_image(filename):
    """
    提供搬移後的檔案下載或顯示 (通常為 .txt)。
    """
    file_path = os.path.join(TARGET_DIR, filename)
    if not os.path.exists(file_path):
        return jsonify({"error": "檔案不存在"}), 404
    response = make_response(send_from_directory(TARGET_DIR, filename))
    response.headers["Cache-Control"] = "no-store, no-cache, must-revalidate, max-age=0"
    response.headers["Pragma"] = "no-cache"
    return response

# =============================
# 啟動 Flask 服務
# =============================
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5007, debug=False)


=== 圖生圖.py ===
import json
import os
import shutil
import time
import uuid
import websocket  # pip install websocket-client
import urllib.request
import urllib.error
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from werkzeug.utils import secure_filename

app = Flask(__name__)
CORS(app)

# ================================
# 參數列表與說明
# ================================
# image           : 上傳的原始圖片（文件流）
# cfgScale        : CFG 強度（提示詞嚴格度，通常 7～10）
# samplerName     : 採樣器（如 euler, dpmpp_2m_sde…）
# scheduler       : 調度器（如 karras, linear_quadratic…）
# denoiseStrength : 去躁幅度（0.0～1.0）
# vaeName         : VAE 名稱（如 kl-f8-anime2.safetensors）
# checkpointName  : Checkpoint 名稱（如 meinamix_v12Final.safetensors）
# seed            : 隨機種子（整數，可留空自動隨機）
# prompt          : 正向提示詞（翻譯後文字）

# ================================
# ComfyUI 伺服器與資料夾設定
# ================================
server_address    = "127.0.0.1:8188"  
comfyui_output_dir = r"D:\comfyui\ComfyUI_windows_portable\ComfyUI\output"
target_dir         = r"D:\大模型圖生圖"
temp_input_dir     = r"D:\大模型圖生圖\temp_input"

os.makedirs(target_dir, exist_ok=True)
os.makedirs(temp_input_dir, exist_ok=True)

EXTERNAL_URL = "https://image.picturesmagician.com"

def queue_prompt(prompt):
    client_id = str(uuid.uuid4())
    payload = {"prompt": prompt, "client_id": client_id}
    data = json.dumps(payload).encode("utf-8")
    url = f"http://{server_address}/prompt"
    try:
        req = urllib.request.Request(url, data=data, headers={"Content-Type":"application/json"})
        with urllib.request.urlopen(req) as resp:
            result = json.loads(resp.read())
            result["client_id"] = client_id
            return result
    except Exception as e:
        print(f"❌ 無法連線至 ComfyUI API: {e}")
        return None

def wait_for_completion(prompt_id, client_id):
    ws_url = f"ws://{server_address}/ws?clientId={client_id}"
    print("🕐 等待 ComfyUI 任務完成...")
    try:
        ws = websocket.create_connection(ws_url)
        while True:
            out = ws.recv()
            if isinstance(out, str):
                msg = json.loads(out)
                if msg.get("type") == "executing":
                    data = msg.get("data", {})
                    if data.get("node") is None and data.get("prompt_id") == prompt_id:
                        print("✅ 任務已完成！")
                        break
        ws.close()
    except Exception as e:
        print(f"❌ WebSocket 錯誤: {e}")

def get_history(prompt_id):
    url = f"http://{server_address}/history/{prompt_id}"
    try:
        with urllib.request.urlopen(url) as resp:
            history_data = json.loads(resp.read())
        return history_data.get(prompt_id, {})
    except Exception as e:
        print(f"❌ 取得 history 錯誤: {e}")
        return {}

def find_latest_png():
    pngs = [f for f in os.listdir(comfyui_output_dir) if f.lower().endswith(".png")]
    if not pngs:
        print("🚫 沒有找到 PNG 檔")
        return None
    latest = max(pngs, key=lambda f: os.path.getctime(os.path.join(comfyui_output_dir, f)))
    return latest

def get_final_image_filename(prompt_id):
    history = get_history(prompt_id)
    outputs = history.get("outputs", {})
    node7 = outputs.get("7", {})
    if "images" in node7:
        for info in node7["images"]:
            fn = info.get("filename")
            if fn and fn.lower().endswith(".png"):
                return fn
    return find_latest_png()

def move_output_files(prompt_id):
    fn = get_final_image_filename(prompt_id)
    if not fn:
        return None
    src = os.path.join(comfyui_output_dir, fn)
    dst = os.path.join(target_dir, fn)
    if os.path.exists(src):
        shutil.move(src, dst)
        return fn
    return None

@app.route("/image_to_image", methods=["POST"])
def image_to_image():
    # 圖片檢查與儲存
    if "image" not in request.files:
        return jsonify({"error": "未上傳圖片"}), 400
    f = request.files["image"]
    if f.filename == "":
        return jsonify({"error": "無檔名"}), 400
    filename = secure_filename(f.filename)
    input_path = os.path.join(temp_input_dir, filename)
    f.save(input_path)
    print(f"✅ 已保存上傳: {input_path}")

    # 讀取所有參數
    cfg_scale        = request.form.get("cfgScale", "7")
    sampler_name     = request.form.get("samplerName", "euler")
    scheduler        = request.form.get("scheduler", "karras")
    denoise_strength = request.form.get("denoiseStrength", "0.7")
    vae_name         = request.form.get("vaeName", "kl-f8-anime2.safetensors")
    ckpt_name        = request.form.get("checkpointName", "meinamix_v12Final.safetensors")
    seed_str         = request.form.get("seed", "")
    prompt_text      = request.form.get("prompt", "").strip()

    # 參數型別轉換
    try:
        cfg_scale = int(cfg_scale)
    except:
        cfg_scale = 7
    try:
        denoise_strength = float(denoise_strength)
    except:
        denoise_strength = 0.7
    try:
        seed = int(seed_str) if seed_str else int(uuid.uuid4().int % 1000000)
    except:
        seed = int(uuid.uuid4().int % 1000000)

    # 日誌列印
    print("收到參數：")
    print(f"  CFG 強度       : {cfg_scale}")
    print(f"  採樣器         : {sampler_name}")
    print(f"  調度器         : {scheduler}")
    print(f"  去躁幅度       : {denoise_strength}")
    print(f"  VAE 名稱       : {vae_name}")
    print(f"  Checkpoint 名稱: {ckpt_name}")
    print(f"  隨機種子       : {seed}")
    print(f"  提示詞         : {prompt_text}")

    # 載入工作流程模板
    workflow_template = r"""
{
  "1": {"inputs":{"ckpt_name":"meinamix_v12Final.safetensors"},"class_type":"CheckpointLoaderSimple"},
  "2": {"inputs":{"text":"a girl","clip":["1",1]},"class_type":"CLIPTextEncode"},
  "3": {"inputs":{"text":"(low quality...)","clip":["1",1]},"class_type":"CLIPTextEncode"},
  "4": {"inputs":{"seed":0,"steps":20,"cfg":7,"sampler_name":"dpmpp_2m_sde","scheduler":"karras","denoise":0.7,"model":["1",0],"positive":["2",0],"negative":["3",0],"latent_image":["14",0]},"class_type":"KSampler"},
  "7": {"inputs":{"filename_prefix":"ComfyUI","images":["8",0]},"class_type":"SaveImage"},
  "8": {"inputs":{"samples":["4",0],"vae":["9",0]},"class_type":"VAEDecode"},
  "9": {"inputs":{"vae_name":"kl-f8-anime2.safetensors"},"class_type":"VAELoader"},
  "13":{"inputs":{"pixels":["17",0],"vae":["9",0]},"class_type":"VAEEncode"},
  "14":{"inputs":{"upscale_method":"nearest-exact","width":512,"height":512,"crop":"disabled","samples":["13",0]},"class_type":"LatentUpscale"},
  "17":{"inputs":{"image":"","force_size":"Disabled","custom_width":512,"custom_height":512},"class_type":"VHS_LoadImagePath"}
}
""".strip()

    workflow = json.loads(workflow_template)

    # 套用使用者參數
    workflow["1"]["inputs"]["ckpt_name"]     = ckpt_name
    workflow["9"]["inputs"]["vae_name"]      = vae_name
    workflow["2"]["inputs"]["text"]          = prompt_text or workflow["2"]["inputs"]["text"]
    workflow["4"]["inputs"]["cfg"]           = cfg_scale
    workflow["4"]["inputs"]["sampler_name"]  = sampler_name
    workflow["4"]["inputs"]["scheduler"]     = scheduler
    workflow["4"]["inputs"]["denoise"]       = denoise_strength
    workflow["4"]["inputs"]["seed"]          = seed
    workflow["17"]["inputs"]["image"]        = input_path.replace("\\", "/")

    print("🚀 發送 workflow 至 ComfyUI：")
    print(json.dumps(workflow, indent=2, ensure_ascii=False))

    resp = queue_prompt(workflow)
    if not resp or "prompt_id" not in resp:
        return jsonify({"error": "ComfyUI 無法回應"}), 500

    prompt_id = resp["prompt_id"]
    client_id = resp["client_id"]

    wait_for_completion(prompt_id, client_id)

    fn = move_output_files(prompt_id)
    if not fn:
        return jsonify({"error": "圖片搬移失敗"}), 500

    image_url = f"{EXTERNAL_URL}/get_image/{fn}?t={int(time.time())}"
    return jsonify({"image_url": image_url})

@app.route("/get_image/<filename>", methods=["GET"])
def get_image(filename):
    return send_from_directory(target_dir, filename)

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001, debug=False)


=== 圖生影片.py ===
import json
import os
import shutil
import time
import uuid
import urllib.request
import urllib.error
import websocket  # 請確保 pip install websocket-client
from flask import Flask, request, jsonify, send_from_directory, Response
from flask_cors import CORS
from werkzeug.middleware.proxy_fix import ProxyFix
from werkzeug.utils import secure_filename
import threading
from collections import OrderedDict

app = Flask(__name__)
CORS(
    app,
    resources={r"/*": {"origins": "*"}},
    supports_credentials=True,
    allow_headers=["Content-Type", "Authorization", "X-Requested-With", "Accept", "Origin"],
    methods=["GET", "POST", "OPTIONS", "DELETE"]
)
app.wsgi_app = ProxyFix(app.wsgi_app, x_for=1, x_proto=1, x_host=1, x_port=1)

# ------------------------------------------------------
# ComfyUI 伺服器位址（本機）
# ------------------------------------------------------
server_address = "127.0.0.1:8188"
client_id = str(uuid.uuid4())

# ------------------------------------------------------
# 資料夾設定
# ------------------------------------------------------
comfyui_output_dir = r"D:\comfyui\ComfyUI_windows_portable\ComfyUI\output"
target_dir = r"D:\sd1.5_animediff_img2video_dataset"
os.makedirs(target_dir, exist_ok=True)

# ------------------------------------------------------
# 輔助函式
# ------------------------------------------------------
def queue_prompt(prompt):
    """
    發送 ComfyUI API 請求 (/prompt)，回傳 JSON 結果
    """
    p = {"prompt": prompt, "client_id": client_id}
    data = json.dumps(p).encode("utf-8")
    req = urllib.request.Request(f"http://{server_address}/prompt", data=data,
                                 headers={"Content-Type": "application/json"})
    with urllib.request.urlopen(req) as resp:
        return json.loads(resp.read())

def wait_for_completion(prompt_id):
    """
    透過 WebSocket 監聽 ComfyUI 任務進度，直到完成
    """
    ws_url = f"ws://{server_address}/ws?clientId={client_id}"
    print("等待 ComfyUI 任務完成...")
    try:
        ws = websocket.create_connection(ws_url)
        while True:
            out = ws.recv()
            if isinstance(out, str):
                msg = json.loads(out)
                if msg.get("type") == "executing":
                    data = msg.get("data", {})
                    # 當 node 為 None，且 prompt_id 相符，表示任務完成
                    if data.get("node") is None and data.get("prompt_id") == prompt_id:
                        print("任務已完成！")
                        break
        ws.close()
    except Exception as e:
        print(f"WebSocket 連線錯誤: {e}")

def get_history(prompt_id):
    """
    從 ComfyUI /history/{prompt_id} 取得輸出紀錄
    """
    url = f"http://{server_address}/history/{prompt_id}"
    try:
        with urllib.request.urlopen(url) as resp:
            history_data = json.loads(resp.read())
        print("[Debug] history API 回應:", json.dumps(history_data, indent=4))
        return history_data.get(prompt_id, {})
    except Exception as e:
        print("無法取得歷史紀錄:", e)
        return {}

def find_latest_mp4():
    """
    在 comfyui_output_dir 中尋找最新的 MP4 檔案
    """
    mp4_files = [f for f in os.listdir(comfyui_output_dir) if f.endswith(".mp4")]
    if not mp4_files:
        print("找不到 MP4 檔案！")
        return None
    latest_mp4 = max(mp4_files, key=lambda f: os.path.getctime(os.path.join(comfyui_output_dir, f)))
    print("找到最新 MP4:", latest_mp4)
    return latest_mp4

def get_final_video_filename(prompt_id):
    """
    解析 /history 或 fallback 到檔案搜尋，找出最終生成的 MP4 檔名
    """
    history = get_history(prompt_id)
    if not history:
        print("history API 回應為空，改用檔案搜尋。")
        return find_latest_mp4()

    # 依照工作流程中 "video combine" 節點 ID 做調整，這裡假設是 "261"
    node_261 = history.get("outputs", {}).get("261", {})
    if "gifs" in node_261:
        for video_item in node_261["gifs"]:
            filename = video_item.get("filename", "")
            if filename.endswith(".mp4"):
                print("API 回傳 MP4 檔案:", filename)
                return filename

    print("API 未找到 MP4，改用檔案搜尋。")
    return find_latest_mp4()

def move_output_files(prompt_id):
    """
    搬移最終 MP4 檔案到 target_dir
    """
    mp4_filename = get_final_video_filename(prompt_id)
    if not mp4_filename:
        print("無法獲取 MP4 檔案名稱！")
        return None
    source_path = os.path.join(comfyui_output_dir, mp4_filename)
    target_path = os.path.join(target_dir, mp4_filename)
    if not os.path.exists(source_path):
        print(f"找不到 {source_path}，無法搬移！")
        return None
    try:
        shutil.move(source_path, target_path)
        print(f"已搬移: {source_path} → {target_path}")
        return mp4_filename
    except Exception as e:
        print("搬移失敗:", e)
        return None

# ------------------------------------------------------
# 範例工作流程 (請根據實際需求修改 animediff+LoRA 內容)
# ------------------------------------------------------
prompt_text ="""
{
  "61": {
    "inputs": {
      "text": "a white hair girl walking",
      "clip": [
        "199",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP文本編碼器"
    }
  },
  "183": {
    "inputs": {
      "multiply_by": 64,
      "latents": [
        "270",
        0
      ]
    },
    "class_type": "VHS_DuplicateLatents",
    "_meta": {
      "title": "Repeat Latents 🎥🅥🅗🅢"
    }
  },
  "186": {
    "inputs": {
      "model_name": "mm_sd_v15.ckpt",
      "beta_schedule": "sqrt_linear (AnimateDiff)",
      "motion_scale": 1,
      "apply_v2_models_properly": true,
      "model": [
        "314",
        0
      ],
      "context_options": [
        "197",
        0
      ]
    },
    "class_type": "ADE_AnimateDiffLoaderWithContext",
    "_meta": {
      "title": "AnimateDiff Loader [Legacy] 🎭🅐🅓①"
    }
  },
  "197": {
    "inputs": {
      "context_length": 16,
      "context_stride": 2,
      "context_overlap": 4,
      "context_schedule": "uniform",
      "closed_loop": false,
      "fuse_method": "flat",
      "use_on_equal_length": false,
      "start_percent": 0,
      "guarantee_steps": 1
    },
    "class_type": "ADE_AnimateDiffUniformContextOptions",
    "_meta": {
      "title": "Context Options◆Looped Uniform 🎭🅐🅓"
    }
  },
  "199": {
    "inputs": {
      "ckpt_name": "meinamix_v12Final.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Checkpoint載入器(簡易)"
    }
  },
  "261": {
    "inputs": {
      "frame_rate": 8,
      "loop_count": 0,
      "filename_prefix": "AnimateDiff",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": true,
      "trim_to_audio": false,
      "pingpong": false,
      "save_output": true,
      "images": [
        "281",
        5
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine 🎥🅥🅗🅢"
    }
  },
  "267": {
    "inputs": {
      "stop_at_clip_layer": -14,
      "clip": [
        "199",
        1
      ]
    },
    "class_type": "CLIPSetLastLayer",
    "_meta": {
      "title": "CLIP設定停止層"
    }
  },
  "269": {
    "inputs": {
      "pixels": [
        "340",
        0
      ],
      "vae": [
        "338",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE編碼"
    }
  },
  "270": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "width": 512,
      "height": 768,
      "crop": "disabled",
      "samples": [
        "269",
        0
      ]
    },
    "class_type": "LatentUpscale",
    "_meta": {
      "title": "Latent縮放"
    }
  },
  "271": {
    "inputs": {
      "model_name": "mm_sd_v15.ckpt",
      "beta_schedule": "sqrt_linear (AnimateDiff)",
      "motion_scale": 1,
      "apply_v2_models_properly": true,
      "model": [
        "314",
        0
      ],
      "context_options": [
        "197",
        0
      ]
    },
    "class_type": "ADE_AnimateDiffLoaderWithContext",
    "_meta": {
      "title": "AnimateDiff Loader [Legacy] 🎭🅐🅓①"
    }
  },
  "277": {
    "inputs": {
      "seed": 217460870924708,
      "steps": 20,
      "cfg": 12,
      "sampler_name": "euler",
      "scheduler": "karras",
      "denoise": 1,
      "preview_method": "auto",
      "vae_decode": "true",
      "model": [
        "271",
        0
      ],
      "positive": [
        "279",
        1
      ],
      "negative": [
        "279",
        2
      ],
      "latent_image": [
        "279",
        3
      ],
      "optional_vae": [
        "279",
        4
      ]
    },
    "class_type": "KSampler (Efficient)",
    "_meta": {
      "title": "K採樣器(效率)"
    }
  },
  "278": {
    "inputs": {
      "seed": 453587441579143,
      "steps": 20,
      "cfg": 12,
      "sampler_name": "euler",
      "scheduler": "karras",
      "denoise": 1,
      "preview_method": "auto",
      "vae_decode": "true",
      "model": [
        "277",
        0
      ],
      "positive": [
        "277",
        1
      ],
      "negative": [
        "277",
        2
      ],
      "latent_image": [
        "277",
        3
      ],
      "optional_vae": [
        "277",
        4
      ]
    },
    "class_type": "KSampler (Efficient)",
    "_meta": {
      "title": "K採樣器(效率)"
    }
  },
  "279": {
    "inputs": {
      "seed": 689898909542969,
      "steps": 20,
      "cfg": 25,
      "sampler_name": "euler",
      "scheduler": "karras",
      "denoise": 1,
      "preview_method": "auto",
      "vae_decode": "true",
      "model": [
        "186",
        0
      ],
      "positive": [
        "61",
        0
      ],
      "negative": [
        "336",
        0
      ],
      "latent_image": [
        "289",
        0
      ],
      "optional_vae": [
        "338",
        0
      ]
    },
    "class_type": "KSampler (Efficient)",
    "_meta": {
      "title": "K採樣器(效率)"
    }
  },
  "281": {
    "inputs": {
      "seed": 744353399792849,
      "steps": 20,
      "cfg": 12,
      "sampler_name": "euler",
      "scheduler": "karras",
      "denoise": 1,
      "preview_method": "auto",
      "vae_decode": "true",
      "model": [
        "278",
        0
      ],
      "positive": [
        "278",
        1
      ],
      "negative": [
        "278",
        2
      ],
      "latent_image": [
        "334",
        0
      ],
      "optional_vae": [
        "278",
        4
      ]
    },
    "class_type": "KSampler (Efficient)",
    "_meta": {
      "title": "K採樣器(效率)"
    }
  },
  "289": {
    "inputs": {
      "boolean": false,
      "latent_a": [
        "183",
        0
      ],
      "latent_b": [
        "291",
        0
      ]
    },
    "class_type": "Latent Input Switch",
    "_meta": {
      "title": "Latent切換"
    }
  },
  "291": {
    "inputs": {
      "width": 512,
      "height": 768,
      "batch_size": 64
    },
    "class_type": "ADE_EmptyLatentImageLarge",
    "_meta": {
      "title": "Empty Latent Image (Big Batch) 🎭🅐🅓"
    }
  },
  "314": {
    "inputs": {
      "lora_name": "sj.safetensors",
      "strength_model": 0.55,
      "strength_clip": 1,
      "model": [
        "199",
        0
      ],
      "clip": [
        "199",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "LoRA載入器"
    }
  },
  "333": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": 1.25,
      "image": [
        "278",
        5
      ]
    },
    "class_type": "ImageScaleBy",
    "_meta": {
      "title": "圖像按係數縮放"
    }
  },
  "334": {
    "inputs": {
      "tile_size": 512,
      "overlap": 64,
      "temporal_size": 64,
      "temporal_overlap": 8,
      "pixels": [
        "333",
        0
      ],
      "vae": [
        "278",
        4
      ]
    },
    "class_type": "VAEEncodeTiled",
    "_meta": {
      "title": "VAE分塊編碼"
    }
  },
  "336": {
    "inputs": {
      "text": "(low quality, nsfw, worst quality, text, letterboxed:1.4), (deformed, distorted, disfigured:1.3), easynegative, hands, bad-hands-5, blurry, ugly, embedding:easynegative",
      "clip": [
        "267",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP文本編碼器"
    }
  },
  "338": {
    "inputs": {
      "vae_name": "kl-f8-anime2.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "VAE載入器"
    }
  },
  "340": {
    "inputs": {
      "image_path": "./ComfyUI/input/example.png",
      "RGBA": "false",
      "filename_text_extension": "true"
    },
    "class_type": "Image Load",
    "_meta": {
      "title": "圖像載入"
    }
  }
}
"""

# ------------------------------------------------------
# /generate_img2video：接收前端的 multipart/form-data
# ------------------------------------------------------
@app.route("/generate_img2video", methods=["POST"])
def generate_img2video():
    """
    前端會帶 text, duration, frame_rate, seed, image
    傳到這裡，由本後端呼叫 ComfyUI 生成影片後搬移檔案，
    最後回傳 JSON。
    """
    # 解析表單參數
    text = request.form.get("text", "").strip()
    if not text:
        return jsonify({"error": "請提供有效的提示詞"}), 400

    try:
        duration = int(request.form.get("duration", 4))
    except ValueError:
        duration = 4

    try:
        frame_rate = int(request.form.get("frame_rate", 8))
    except ValueError:
        frame_rate = 8

    try:
        seed = int(request.form.get("seed", 0))
    except ValueError:
        seed = 0
    if seed == 0:
        # 若種子=0，則自動生成一個
        seed = int(time.time() * 1000) % 1000000

    image = request.files.get("image")
    if image is None:
        return jsonify({"error": "請上傳圖片"}), 400

    # 儲存上傳圖片
    filename = secure_filename(f"{uuid.uuid4().hex}_{image.filename}")
    temp_upload_dir = r"D:\sd1.5_img2video_temp_uploads"
    os.makedirs(temp_upload_dir, exist_ok=True)
    file_path = os.path.join(temp_upload_dir, filename)
    image.save(file_path)
    print("上傳圖片儲存於:", file_path)

    result = {}

    def call_comfyui():
        """
        生成核心邏輯：更新 workflow → queue_prompt → wait_for_completion → 搬移 → 回傳結果
        """
        try:
            # 1) 載入基礎工作流程
            workflow = json.loads(prompt_text)

            # 2) 更新工作流程
            if "61" in workflow and "text" in workflow["61"]["inputs"]:
                workflow["61"]["inputs"]["text"] = text
            # 假設 "183" 是控制 multiply_by (這裡依照你的實際 workflow 做修改)
            if "183" in workflow and "multiply_by" in workflow["183"]["inputs"]:
                workflow["183"]["inputs"]["multiply_by"] = duration * 16
            if "261" in workflow and "frame_rate" in workflow["261"]["inputs"]:
                workflow["261"]["inputs"]["frame_rate"] = frame_rate
            # 假設 "277" 是 KSampler seed (依你的 workflow ID 修正)
            if "277" in workflow and "seed" in workflow["277"]["inputs"]:
                workflow["277"]["inputs"]["seed"] = seed

            print("最終 workflow =", json.dumps(workflow, indent=2, ensure_ascii=False))

            # 3) 呼叫 ComfyUI
            resp_json = queue_prompt(workflow)
            if not resp_json or "prompt_id" not in resp_json:
                print("ComfyUI API 回應錯誤")
                result["error"] = "ComfyUI API 回應錯誤"
                return
            prompt_id = resp_json["prompt_id"]
            print("取得 prompt_id:", prompt_id)

            # 4) 等待完成
            wait_for_completion(prompt_id)
            time.sleep(2)  # 給系統一點時間寫檔案

            # 5) 搬移 MP4 檔案
            mp4_filename = move_output_files(prompt_id)
            if not mp4_filename:
                result["error"] = "搬移影片失敗"
            else:
                # 回傳對外影片 URL
                video_url = f"https://imagevideo.picturesmagician.com/get_video/{mp4_filename}?t={int(time.time())}"
                print("影片生成成功，URL =", video_url)
                result["video_url"] = video_url

        except Exception as e:
            print("例外錯誤：", e)
            result["error"] = str(e)
        finally:
            # 刪除暫存檔
            try:
                os.remove(file_path)
            except Exception as e2:
                print("刪除暫存檔失敗：", e2)

    # 啟動後台執行緒
    thread = threading.Thread(target=call_comfyui)
    thread.start()

    # 以 SSE 回傳生成進度
    def sse_stream():
        progress = 0
        while thread.is_alive():
            msg = {"progress": progress, "message": "影片生成中..."}
            yield f"data: {json.dumps(msg)}\n\n"
            time.sleep(5)
            progress = min(progress + 10, 90)

        thread.join()
        if "video_url" in result:
            ok = {"progress": 100, "video_url": result["video_url"], "message": "影片生成完成！"}
            yield f"data: {json.dumps(ok)}\n\n"
        else:
            err = result.get("error", "未知錯誤")
            fail = {"progress": 100, "error": err, "message": "影片生成失敗"}
            yield f"data: {json.dumps(fail)}\n\n"
        # 移除原先多餘的 yield "\n"

    # 加入 SSE 回傳所需的標頭，參考文生影片做法
    headers = {
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
        "X-Accel-Buffering": "no"
    }
    return Response(sse_stream(), headers=headers, mimetype="text/event-stream")

# ------------------------------------------------------
# 取回影片檔案
# ------------------------------------------------------
@app.route("/get_video/<path:filename>", methods=["GET"])
def get_video(filename):
    """
    提供最終影片檔下載/播放
    """
    file_path = os.path.join(target_dir, filename)
    if not os.path.exists(file_path):
        return jsonify({"error": "檔案不存在"}), 404
    return send_from_directory(target_dir, filename)

if __name__ == "__main__":
    # 後端 Flask 監聽 0.0.0.0:5000
    app.run(host="0.0.0.0", port=5009, debug=False)


=== 局部重繪.py ===
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import time
import uuid
import json
import base64
import shutil
import io
import urllib.request
import websocket  # pip install websocket-client
from PIL import Image
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS

app = Flask(__name__)
CORS(app)

# =============================
# ComfyUI 伺服器與資料夾設定
# =============================
server_address     = "127.0.0.1:8188"
comfyui_output_dir = r"D:\comfyui\ComfyUI_windows_portable\ComfyUI\output"
temp_input_dir     = r"D:\大模型局部重繪\temp_input"
target_dir_redraw  = r"D:\大模型局部重繪"
EXTERNAL_URL       = "https://inpant.picturesmagician.com"

for d in (temp_input_dir, target_dir_redraw):
    os.makedirs(d, exist_ok=True)

# =============================
# 重繪專用 ComfyUI Workflow JSON
# =============================
workflow_redraw_template = r"""
{
  "1": {
    "inputs": {
      "ckpt_name": "meinamix_v12Final.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {"title": "Checkpoint加载器（简易）"}
  },
  "2": {
    "inputs": {
      "text": "",
      "clip": ["1", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {"title": "CLIP 文本编码器"}
  },
  "3": {
    "inputs": {
      "text": "",
      "clip": ["1", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {"title": "CLIP 文本编码器（负向）"}
  },
  "4": {
    "inputs": {
      "seed": 0,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 1.0,
      "model": ["1", 0],
      "positive": ["2", 0],
      "negative": ["3", 0],
      "latent_image": ["13", 0]
    },
    "class_type": "KSampler",
    "_meta": {"title": "K 取样器"}
  },
  "7": {
    "inputs": {
      "filename_prefix": "Redraw",
      "images": ["8", 0]
    },
    "class_type": "SaveImage",
    "_meta": {"title": "保存图像"}
  },
  "8": {
    "inputs": {
      "samples": ["4", 0],
      "vae": ["9", 0]
    },
    "class_type": "VAEDecode",
    "_meta": {"title": "VAE 解码"}
  },
  "9": {
    "inputs": {
      "vae_name": "kl-f8-anime2.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {"title": "VAE 加载器"}
  },
  "13": {
    "inputs": {
      "pixels": ["28", 0],
      "vae": ["9", 0]
    },
    "class_type": "VAEEncode",
    "_meta": {"title": "VAE 编码（空/原图）"}
  },
  "19": {
    "inputs": {
      "control_net_name": "control_sd15_canny.pth"
    },
    "class_type": "ControlNetLoader",
    "_meta": {"title": "ControlNet 加载器"}
  },
  "20": {
    "inputs": {
      "low_threshold": 100,
      "high_threshold": 200,
      "resolution": 512,
      "image": ["29", 0]
    },
    "class_type": "CannyEdgePreprocessor",
    "_meta": {"title": "Canny 预处理"}
  },
  "21": {
    "inputs": {
      "strength": 1.0,
      "start_percent": 0,
      "end_percent": 1,
      "positive": ["2", 0],
      "negative": ["3", 0],
      "control_net": ["19", 0],
      "image": ["20", 0],
      "vae": ["9", 0]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {"title": "ControlNet 应用(进阶)"}
  },
  "26": {
    "inputs": {
      "images": ["29", 0]
    },
    "class_type": "PreviewImage",
    "_meta": {"title": "预览遮罩"}
  },
  "27": {
    "inputs": {
      "images": ["28", 0]
    },
    "class_type": "PreviewImage",
    "_meta": {"title": "预览原图"}
  },
  "28": {
    "inputs": {
      "image_path": ""
    },
    "class_type": "ZwngLoadImagePathOrURL",
    "_meta": {"title": "Load 原图"}
  },
  "29": {
    "inputs": {
      "image_path": ""
    },
    "class_type": "ZwngLoadImagePathOrURL",
    "_meta": {"title": "Load 遮罩图"}
  }
}
"""

# =============================
# 保存並縮放前端傳來的 Base64 圖片
# =============================
def save_base64_image(data_url, folder, prefix):
    try:
        header, encoded = data_url.split(",", 1)
    except Exception:
        return None, "無效的圖片資料"
    ext = "png" if "png" in header else "jpg"
    raw = base64.b64decode(encoded)
    img = Image.open(io.BytesIO(raw))
    if img.mode != "RGBA":
        img = img.convert("RGBA")
    img = img.resize((512, 512), Image.LANCZOS)
    filename = f"{prefix}_{uuid.uuid4().hex}.{ext}"
    path = os.path.join(folder, filename)
    img.save(path)
    return path, None

# =============================
# 排隊到 ComfyUI
# =============================
def queue_prompt(workflow):
    client_id = str(uuid.uuid4())
    payload   = {"prompt": workflow, "client_id": client_id}
    data      = json.dumps(payload).encode("utf-8")
    req = urllib.request.Request(
        f"http://{server_address}/prompt",
        data=data,
        headers={"Content-Type": "application/json"}
    )
    with urllib.request.urlopen(req) as resp:
        result = json.loads(resp.read().decode("utf-8"))
    result["client_id"] = client_id
    return result

# =============================
# 等待 ComfyUI 完成
# =============================
def wait_for_completion(prompt_id, client_id):
    ws = websocket.create_connection(f"ws://{server_address}/ws?clientId={client_id}")
    while True:
        out = ws.recv()
        if isinstance(out, (bytes, bytearray)):
            try:
                out = out.decode("utf-8")
            except Exception:
                out = out.decode("latin-1", "ignore")
        try:
            msg = json.loads(out)
        except Exception:
            # 非 JSON 訊息（如 ping/pong）忽略
            continue
        if msg.get("type") == "executing":
            data = msg.get("data", {})
            if data.get("prompt_id") == prompt_id and data.get("node") is None:
                break
    ws.close()

# =============================
# 取得 & 搬移結果檔案
# =============================
def find_latest_png(directory):
    pngs = []
    for root, _, files in os.walk(directory):
        for fn in files:
            if fn.lower().endswith(".png"):
                pngs.append((os.path.getctime(os.path.join(root, fn)), fn))
    return max(pngs, key=lambda x: x[0])[1] if pngs else None

def get_final_image_filename(prompt_id):
    url = f"http://{server_address}/history/{prompt_id}"
    with urllib.request.urlopen(url) as resp:
        hist = json.loads(resp.read().decode("utf-8")).get(prompt_id, {})
    for nid in ("7",):
        for info in hist.get("outputs", {}).get(nid, {}).get("images", []):
            fn = info.get("filename")
            if fn and fn.lower().endswith(".png"):
                return fn
    return find_latest_png(comfyui_output_dir)

def move_output_files(prompt_id, target_dir):
    fn = get_final_image_filename(prompt_id)
    if not fn:
        raise FileNotFoundError("找不到輸出檔案")
    src = os.path.join(comfyui_output_dir, fn)
    if not os.path.exists(src):
        for root, _, files in os.walk(comfyui_output_dir):
            if fn in files:
                src = os.path.join(root, fn)
                break
    dst = os.path.join(target_dir, fn)
    shutil.move(src, dst)
    return fn

# =============================
# API Endpoint：/convert-image
# =============================
@app.route("/convert-image", methods=["POST"])
def convert_image_endpoint():
    data = request.get_json(force=True)
    print("▶ 收到參數：")
    for k in ("originalImage","maskImage","prompt","vaeName","checkpointName",
              "cfgScale","samplerName","scheduler","denoiseStrength","seed"):
        print(f"  {k}: {data.get(k)}")

    if not data.get("originalImage") or not data.get("maskImage"):
        return jsonify({"error":"缺少原圖或遮罩圖"}), 400

    orig_path, err = save_base64_image(data["originalImage"], temp_input_dir, "orig")
    if err: return jsonify({"error": err}), 400
    mask_path, err = save_base64_image(data["maskImage"],   temp_input_dir, "mask")
    if err: return jsonify({"error": err}), 400

    prompt_text  = data.get("prompt","").strip()
    vae_name     = data.get("vaeName","kl-f8-anime2.safetensors")
    ckpt_name    = data.get("checkpointName","meinamix_v12Final.safetensors")
    try:    cfg_scale = int(data.get("cfgScale",7))
    except: cfg_scale = 7
    sampler_name = data.get("samplerName","euler")
    scheduler    = data.get("scheduler","normal")
    try:    denoise = float(data.get("denoiseStrength",1.0))
    except: denoise = 1.0
    sv = data.get("seed","")
    try:    seed = int(sv) if sv else int(uuid.uuid4().int % 1000000)
    except: seed = int(uuid.uuid4().int % 1000000)

    if not prompt_text:
        return jsonify({"error":"提示詞為空"}), 400

    wf = json.loads(workflow_redraw_template)
    wf["1"]["inputs"]["ckpt_name"]    = ckpt_name
    wf["9"]["inputs"]["vae_name"]     = vae_name
    wf["2"]["inputs"]["text"]         = prompt_text
    wf["4"]["inputs"]["cfg"]          = cfg_scale
    wf["4"]["inputs"]["sampler_name"] = sampler_name
    wf["4"]["inputs"]["scheduler"]    = scheduler
    wf["4"]["inputs"]["denoise"]      = denoise
    wf["4"]["inputs"]["seed"]         = seed
    wf["28"]["inputs"]["image_path"]  = orig_path
    wf["29"]["inputs"]["image_path"]  = mask_path

    print("🚀 發送工作流程至 ComfyUI：")
    print(json.dumps(wf, indent=2, ensure_ascii=False))

    resp = queue_prompt(wf)
    pid, cid = resp["prompt_id"], resp["client_id"]
    wait_for_completion(pid, cid)
    time.sleep(2)
    fn = move_output_files(pid, target_dir_redraw)

    url = f"{EXTERNAL_URL}/get_image/{fn}?t={int(time.time())}"
    return jsonify({"image_url": url})

# =============================
# 圖片代理 Endpoint
# =============================
@app.route("/get_image/<filename>", methods=["GET"])
def get_image(filename):
    p = os.path.join(target_dir_redraw, filename)
    if os.path.exists(p):
        return send_from_directory(target_dir_redraw, filename)
    return "檔案不存在", 404

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5002, debug=False)


=== 局部重繪測試.py ===
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import time
import uuid
import json
import base64
import shutil
import io
import urllib.request
import websocket  # pip install websocket-client
from PIL import Image
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS

app = Flask(__name__)
CORS(app)

# =============================
# ComfyUI 伺服器與資料夾設定
# =============================
server_address     = "127.0.0.1:8188"
comfyui_output_dir = r"D:\comfyui\ComfyUI_windows_portable\ComfyUI\output"
temp_input_dir     = r"D:\大模型局部重繪\temp_input"
target_dir_redraw  = r"D:\大模型局部重繪"
EXTERNAL_URL       = "https://inpant.picturesmagician.com"

for d in (temp_input_dir, target_dir_redraw):
    os.makedirs(d, exist_ok=True)

# =============================
# 重繪專用 ComfyUI Workflow JSON
# =============================
workflow_redraw_template = r"""
{
  "1": {
    "inputs": {
      "ckpt_name": "meinamix_v12Final.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {"title": "Checkpoint加载器（简易）"}
  },
  "2": {
    "inputs": {
      "text": "",
      "clip": ["1", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {"title": "CLIP 文本编码器"}
  },
  "3": {
    "inputs": {
      "text": "",
      "clip": ["1", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {"title": "CLIP 文本编码器（负向）"}
  },
  "4": {
    "inputs": {
      "seed": 0,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 1.0,
      "model": ["1", 0],
      "positive": ["2", 0],
      "negative": ["3", 0],
      "latent_image": ["13", 0]
    },
    "class_type": "KSampler",
    "_meta": {"title": "K 取样器"}
  },
  "7": {
    "inputs": {
      "filename_prefix": "Redraw",
      "images": ["8", 0]
    },
    "class_type": "SaveImage",
    "_meta": {"title": "保存图像"}
  },
  "8": {
    "inputs": {
      "samples": ["4", 0],
      "vae": ["9", 0]
    },
    "class_type": "VAEDecode",
    "_meta": {"title": "VAE 解码"}
  },
  "9": {
    "inputs": {
      "vae_name": "kl-f8-anime2.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {"title": "VAE 加载器"}
  },
  "13": {
    "inputs": {
      "pixels": ["28", 0],
      "vae": ["9", 0]
    },
    "class_type": "VAEEncode",
    "_meta": {"title": "VAE 编码（空/原图）"}
  },
  "19": {
    "inputs": {
      "control_net_name": "control_sd15_canny.pth"
    },
    "class_type": "ControlNetLoader",
    "_meta": {"title": "ControlNet 加载器"}
  },
  "20": {
    "inputs": {
      "low_threshold": 100,
      "high_threshold": 200,
      "resolution": 512,
      "image": ["29", 0]
    },
    "class_type": "CannyEdgePreprocessor",
    "_meta": {"title": "Canny 预处理"}
  },
  "21": {
    "inputs": {
      "strength": 1.0,
      "start_percent": 0,
      "end_percent": 1,
      "positive": ["2", 0],
      "negative": ["3", 0],
      "control_net": ["19", 0],
      "image": ["20", 0],
      "vae": ["9", 0]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {"title": "ControlNet 应用(进阶)"}
  },
  "26": {
    "inputs": {
      "images": ["29", 0]
    },
    "class_type": "PreviewImage",
    "_meta": {"title": "预览遮罩"}
  },
  "27": {
    "inputs": {
      "images": ["28", 0]
    },
    "class_type": "PreviewImage",
    "_meta": {"title": "预览原图"}
  },
  "28": {
    "inputs": {
      "image_path": ""
    },
    "class_type": "ZwngLoadImagePathOrURL",
    "_meta": {"title": "Load 原图"}
  },
  "29": {
    "inputs": {
      "image_path": ""
    },
    "class_type": "ZwngLoadImagePathOrURL",
    "_meta": {"title": "Load 遮罩图"}
  }
}
"""

# =============================
# 保存並縮放前端傳來的 Base64 圖片
# =============================
def save_base64_image(data_url, folder, prefix):
    try:
        header, encoded = data_url.split(",", 1)
    except Exception:
        return None, "無效的圖片資料"
    ext = "png" if "png" in header else "jpg"
    raw = base64.b64decode(encoded)
    img = Image.open(io.BytesIO(raw))
    if img.mode != "RGBA":
        img = img.convert("RGBA")
    img = img.resize((512, 512), Image.LANCZOS)
    filename = f"{prefix}_{uuid.uuid4().hex}.{ext}"
    path = os.path.join(folder, filename)
    img.save(path)
    return path, None

# =============================
# 排隊到 ComfyUI
# =============================
def queue_prompt(workflow):
    client_id = str(uuid.uuid4())
    payload   = {"prompt": workflow, "client_id": client_id}
    data      = json.dumps(payload).encode("utf-8")
    req = urllib.request.Request(
        f"http://{server_address}/prompt",
        data=data,
        headers={"Content-Type": "application/json"}
    )
    with urllib.request.urlopen(req) as resp:
        result = json.loads(resp.read().decode("utf-8"))
    result["client_id"] = client_id
    return result

# =============================
# 等待 ComfyUI 完成
# =============================
def wait_for_completion(prompt_id, client_id):
    ws = websocket.create_connection(f"ws://{server_address}/ws?clientId={client_id}")
    while True:
        out = ws.recv()
        if isinstance(out, (bytes, bytearray)):
            try:
                out = out.decode("utf-8")
            except Exception:
                out = out.decode("latin-1", "ignore")
        try:
            msg = json.loads(out)
        except Exception:
            # 非 JSON 訊息（如 ping/pong）忽略
            continue
        if msg.get("type") == "executing":
            data = msg.get("data", {})
            if data.get("prompt_id") == prompt_id and data.get("node") is None:
                break
    ws.close()

# =============================
# 取得 & 搬移結果檔案
# =============================
def find_latest_png(directory):
    pngs = []
    for root, _, files in os.walk(directory):
        for fn in files:
            if fn.lower().endswith(".png"):
                pngs.append((os.path.getctime(os.path.join(root, fn)), fn))
    return max(pngs, key=lambda x: x[0])[1] if pngs else None

def get_final_image_filename(prompt_id):
    url = f"http://{server_address}/history/{prompt_id}"
    with urllib.request.urlopen(url) as resp:
        hist = json.loads(resp.read().decode("utf-8")).get(prompt_id, {})
    for nid in ("7",):
        for info in hist.get("outputs", {}).get(nid, {}).get("images", []):
            fn = info.get("filename")
            if fn and fn.lower().endswith(".png"):
                return fn
    return find_latest_png(comfyui_output_dir)

def move_output_files(prompt_id, target_dir):
    fn = get_final_image_filename(prompt_id)
    if not fn:
        raise FileNotFoundError("找不到輸出檔案")
    src = os.path.join(comfyui_output_dir, fn)
    if not os.path.exists(src):
        for root, _, files in os.walk(comfyui_output_dir):
            if fn in files:
                src = os.path.join(root, fn)
                break
    dst = os.path.join(target_dir, fn)
    shutil.move(src, dst)
    return fn

# =============================
# API Endpoint：/convert-image
# =============================
@app.route("/convert-image", methods=["POST"])
def convert_image_endpoint():
    data = request.get_json(force=True)
    print("▶ 收到參數：")
    for k in ("originalImage","maskImage","prompt","vaeName","checkpointName",
              "cfgScale","samplerName","scheduler","denoiseStrength","seed"):
        print(f"  {k}: {data.get(k)}")

    if not data.get("originalImage") or not data.get("maskImage"):
        return jsonify({"error":"缺少原圖或遮罩圖"}), 400

    orig_path, err = save_base64_image(data["originalImage"], temp_input_dir, "orig")
    if err: return jsonify({"error": err}), 400
    mask_path, err = save_base64_image(data["maskImage"],   temp_input_dir, "mask")
    if err: return jsonify({"error": err}), 400

    prompt_text  = data.get("prompt","").strip()
    vae_name     = data.get("vaeName","kl-f8-anime2.safetensors")
    ckpt_name    = data.get("checkpointName","meinamix_v12Final.safetensors")
    try:    cfg_scale = int(data.get("cfgScale",7))
    except: cfg_scale = 7
    sampler_name = data.get("samplerName","euler")
    scheduler    = data.get("scheduler","normal")
    try:    denoise = float(data.get("denoiseStrength",1.0))
    except: denoise = 1.0
    sv = data.get("seed","")
    try:    seed = int(sv) if sv else int(uuid.uuid4().int % 1000000)
    except: seed = int(uuid.uuid4().int % 1000000)

    if not prompt_text:
        return jsonify({"error":"提示詞為空"}), 400

    wf = json.loads(workflow_redraw_template)
    wf["1"]["inputs"]["ckpt_name"]    = ckpt_name
    wf["9"]["inputs"]["vae_name"]     = vae_name
    wf["2"]["inputs"]["text"]         = prompt_text
    wf["4"]["inputs"]["cfg"]          = cfg_scale
    wf["4"]["inputs"]["sampler_name"] = sampler_name
    wf["4"]["inputs"]["scheduler"]    = scheduler
    wf["4"]["inputs"]["denoise"]      = denoise
    wf["4"]["inputs"]["seed"]         = seed
    wf["28"]["inputs"]["image_path"]  = orig_path
    wf["29"]["inputs"]["image_path"]  = mask_path

    print("🚀 發送工作流程至 ComfyUI：")
    print(json.dumps(wf, indent=2, ensure_ascii=False))

    resp = queue_prompt(wf)
    pid, cid = resp["prompt_id"], resp["client_id"]
    wait_for_completion(pid, cid)
    time.sleep(2)
    fn = move_output_files(pid, target_dir_redraw)

    url = f"{EXTERNAL_URL}/get_image/{fn}?t={int(time.time())}"
    return jsonify({"image_url": url})

# =============================
# 圖片代理 Endpoint
# =============================
@app.route("/get_image/<filename>", methods=["GET"])
def get_image(filename):
    p = os.path.join(target_dir_redraw, filename)
    if os.path.exists(p):
        return send_from_directory(target_dir_redraw, filename)
    return "檔案不存在", 404

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5002, debug=False)


=== 影片生影片.py ===
import json
import os
import shutil
import websocket  # 確保安裝 `websocket-client` 模組
import urllib.request
import urllib.error
import urllib.parse
import uuid
import random
import time
import requests
import threading

from flask import Flask, request, jsonify, Response, send_from_directory
from flask_cors import CORS
from werkzeug.middleware.proxy_fix import ProxyFix
from werkzeug.utils import secure_filename

# ----------------------------------------------------------------------------
# ComfyUI 伺服器位址與目標資料夾設定
server_address = "127.0.0.1:8188"
client_id = str(uuid.uuid4())  # 產生唯一 client ID

# ComfyUI 輸出與目標資料夾（請確保這些資料夾存在）
comfyui_output_dir = "D:/comfyui/ComfyUI_windows_portable/ComfyUI/output/"
target_dir = "D:/sd1.5_animediff_txt2video_dataset/"
os.makedirs(comfyui_output_dir, exist_ok=True)
os.makedirs(target_dir, exist_ok=True)

app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}},
     supports_credentials=True,
     allow_headers=["Content-Type", "Authorization", "X-Requested-With", "Accept", "Origin"],
     methods=["GET", "POST", "OPTIONS", "DELETE"])

# 讓 Flask 正確處理反向代理（例如 Cloudflare Tunnel）
app.wsgi_app = ProxyFix(app.wsgi_app, x_for=1, x_proto=1, x_host=1, x_port=1)

# ----------------------------------------------------------------------------
# 對外提供的 HTTPS 網域設定（前端用於組合最終影片 URL）
VIDEO_BASE_URL = "https://vid2vid.picturesmagician.com"

# ----------------------------------------------------------------------------
# 以下為原始腳本中的函式定義
# ----------------------------------------------------------------------------

def queue_prompt(prompt):
    """發送請求到 ComfyUI API"""
    p = {
        "prompt": prompt,
        "client_id": client_id,
        "disable_cached_nodes": True  # 強制禁用快取
    }
    data = json.dumps(p).encode("utf-8")
    req = urllib.request.Request(
        f"http://{server_address}/prompt",
        data=data,
        headers={'Content-Type': 'application/json'}
    )
    try:
        with urllib.request.urlopen(req) as response:
            return json.loads(response.read())
    except urllib.error.HTTPError as e:
        print(f"❌ HTTP 錯誤: {e.code} {e.reason}")
        return None
    except urllib.error.URLError as e:
        print(f"❌ URL 錯誤: {e.reason}")
        return None

def wait_for_completion(prompt_id):
    """透過 WebSocket 監聽 ComfyUI，直到任務完成"""
    ws_url = f"ws://{server_address}/ws?clientId={client_id}"
    try:
        ws = websocket.create_connection(ws_url)
        print("🕐 等待 ComfyUI 任務完成...")
        while True:
            out = ws.recv()
            if isinstance(out, str):
                message = json.loads(out)
                if message.get("type") == "executing":
                    data = message.get("data", {})
                    # 當 node=None 且 prompt_id 對應時代表流程已結束
                    if data.get("node") is None and data.get("prompt_id") == prompt_id:
                        print("✅ 任務已完成！")
                        break
        ws.close()
    except Exception as e:
        print(f"❌ WebSocket 連線錯誤: {e}")

def get_history_all():
    """
    獲取 /history 全部資料（回傳一個 Dict: { prompt_id: {...}, ... }）
    """
    url = f"http://{server_address}/history"
    try:
        with urllib.request.urlopen(url) as response:
            return json.loads(response.read())
    except Exception as e:
        print(f"❌ 無法取得完整 /history: {e}")
        return {}

def get_history(prompt_id):
    """從 /history/{prompt_id} 取得特定任務的詳細歷史"""
    url = f"http://{server_address}/history/{prompt_id}"
    try:
        with urllib.request.urlopen(url) as response:
            history_data = json.loads(response.read())
        print(f"📜 Debug: history API 回應 = {json.dumps(history_data, indent=4, ensure_ascii=False)}")
        return history_data.get(prompt_id, {})
    except urllib.error.HTTPError as e:
        print(f"❌ HTTP 錯誤: {e.code} {e.reason}")
        return {}
    except urllib.error.URLError as e:
        print(f"❌ URL 錯誤: {e.reason}")
        return {}
    except Exception as e:
        print(f"❌ 其他錯誤: {e}")
        return {}

def find_latest_mp4():
    """從 ComfyUI 輸出資料夾尋找最新的 MP4 檔案"""
    mp4_files = [f for f in os.listdir(comfyui_output_dir) if f.endswith(".mp4")]
    if not mp4_files:
        print("🚫 找不到 MP4 檔案！")
        return None
    latest_mp4 = max(mp4_files, key=lambda f: os.path.getctime(os.path.join(comfyui_output_dir, f)))
    print(f"🎬 找到最新 MP4: {latest_mp4}")
    return latest_mp4

def get_final_video_filename(prompt_id):
    """取得 VHS_VideoCombine 產出的 MP4 檔案名稱（先查 /history，再用檔案搜尋）"""
    history = get_history(prompt_id)
    if not history:
        print("⚠️ API 沒回傳任何資訊，改用檔案搜尋。")
        return find_latest_mp4()
    video_node = history.get("outputs", {}).get("102", {})
    if "videos" in video_node:
        for vid in video_node["videos"]:
            filename = vid.get("filename", "")
            if filename.endswith(".mp4"):
                return filename
    if "files" in video_node:
        for f in video_node["files"]:
            filename = f.get("filename", "")
            if filename.endswith(".mp4"):
                return filename
    if "gifs" in video_node:
        for g in video_node["gifs"]:
            filename = g.get("filename", "")
            if filename.endswith(".mp4"):
                return filename
    print("⚠️ API 沒找到 MP4，改用檔案搜尋。")
    return find_latest_mp4()

def move_output_files(prompt_id):
    """搬移 get_final_video_filename() 找到的 MP4 檔案"""
    mp4_filename = get_final_video_filename(prompt_id)
    if not mp4_filename:
        print("🚫 無法從 API 或檔案搜尋獲取 MP4 檔案名稱！")
        return None
    source_path = os.path.join(comfyui_output_dir, mp4_filename)
    target_path = os.path.join(target_dir, mp4_filename)
    if not os.path.exists(source_path):
        print(f"⚠️ 找不到 {source_path}，無法搬移！")
        return None
    try:
        shutil.move(source_path, target_path)
        print(f"✅ 已搬移: {source_path} → {target_path}")
        return mp4_filename
    except Exception as e:
        print(f"❌ 搬移失敗: {e}")
        return None

# ----------------------------------------------------------------------------
# 以下為參數設定區塊（請勿隨意修改）
# ----------------------------------------------------------------------------

prompt = {
    "1": {
        "inputs": {
            "ckpt_name": "meinamix_v12Final.safetensors",
            "beta_schedule": "sqrt_linear (AnimateDiff)",
            "use_custom_scale_factor": False,
            "scale_factor": 0.18215
        },
        "class_type": "CheckpointLoaderSimpleWithNoiseSelect",
        "_meta": {
            "title": "Load Checkpoint w/ Noise Select 🎭🅐🅓"
        }
    },
    "2": {
        "inputs": {
            "vae_name": "kl-f8-anime2.safetensors"
        },
        "class_type": "VAELoader",
        "_meta": {
            "title": "VAE載入器"
        }
    },
    "6": {
        "inputs": {
            "text": "(low quality, nsfw, worst quality, text, letterboxed:1.4), (deformed, distorted, disfigured:1.3), easynegative, hands, bad-hands-5, blurry, ugly, embedding:easynegative",
            "clip": ["1", 1]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "CLIP文本編碼器"
        }
    },
    "7": {
        "inputs": {
            "seed": 44444444,
            "steps": 25,
            "cfg": 7,
            "sampler_name": "euler_ancestral",
            "scheduler": "normal",
            "denoise": 1,
            "model": ["93", 0],
            "positive": ["72", 0],
            "negative": ["72", 1],
            "latent_image": ["56", 0]
        },
        "class_type": "KSampler",
        "_meta": {
            "title": "K採樣器"
        }
    },
    "10": {
        "inputs": {
            "samples": ["7", 0],
            "vae": ["2", 0]
        },
        "class_type": "VAEDecode",
        "_meta": {
            "title": "VAE解碼"
        }
    },
    "12": {
        "inputs": {
            "filename_prefix": "Images\\image",
            "images": ["10", 0]
        },
        "class_type": "SaveImage",
        "_meta": {
            "title": "儲存圖像"
        }
    },
    "50": {
        "inputs": {
            "images": ["53", 0]
        },
        "class_type": "PreviewImage",
        "_meta": {
            "title": "預覽圖像"
        }
    },
    "53": {
        "inputs": {
            "upscale_method": "nearest-exact",
            "width": 1024,
            "height": 576,
            "crop": "disabled",
            "image": ["109", 0]
        },
        "class_type": "ImageScale",
        "_meta": {
            "title": "圖像縮放"
        }
    },
    "56": {
        "inputs": {
            "pixels": ["53", 0],
            "vae": ["2", 0]
        },
        "class_type": "VAEEncode",
        "_meta": {
            "title": "VAE編碼"
        }
    },
    "70": {
        "inputs": {
            "control_net_name": "sd1.5_lineart.safetensors"
        },
        "class_type": "ControlNetLoaderAdvanced",
        "_meta": {
            "title": "ControlNet載入器(進階)"
        }
    },
    "71": {
        "inputs": {
            "coarse": "disable",
            "resolution": 512,
            "image": ["53", 0]
        },
        "class_type": "LineArtPreprocessor",
        "_meta": {
            "title": "LineArt線稿預處理"
        }
    },
    "72": {
        "inputs": {
            "strength": 0.5,
            "start_percent": 0.018000000000000002,
            "end_percent": 1,
            "positive": ["96", 0],
            "negative": ["6", 0],
            "control_net": ["70", 0],
            "image": ["71", 0]
        },
        "class_type": "ControlNetApplyAdvanced",
        "_meta": {
            "title": "ControlNet應用(進階)"
        }
    },
    "92": {
        "inputs": {
            "images": ["71", 0]
        },
        "class_type": "PreviewImage",
        "_meta": {
            "title": "預覽圖像"
        }
    },
    "93": {
        "inputs": {
            "model_name": "mm_sd_v15.ckpt",
            "beta_schedule": "sqrt_linear (AnimateDiff)",
            "motion_scale": 1,
            "apply_v2_models_properly": True,
            "model": ["1", 0],
            "context_options": ["94", 0]
        },
        "class_type": "ADE_AnimateDiffLoaderWithContext",
        "_meta": {
            "title": "AnimateDiff Loader [Legacy] 🎭🅐🅓①"
        }
    },
    "94": {
        "inputs": {
            "context_length": 16,
            "context_stride": 1,
            "context_overlap": 4,
            "context_schedule": "uniform",
            "closed_loop": False,
            "fuse_method": "flat",
            "use_on_equal_length": False,
            "start_percent": 0,
            "guarantee_steps": 1
        },
        "class_type": "ADE_AnimateDiffUniformContextOptions",
        "_meta": {
            "title": "Context Options◆Looped Uniform 🎭🅐🅓"
        }
    },
    "96": {
        "inputs": {
            "text": "\"0\" :\"spring day, cherryblossoms\",\n\"8\" :\"summer day, vegetation\",\n\"16\" :\"fall day, leaves blowing in the wind\",\n\"32\" :\"winter, during a snowstorm, earmuffs\"\n",
            "max_frames": 120,
            "print_output": "",
            "pre_text": ["101", 0],
            "app_text": "",
            "start_frame": 0,
            "end_frame": 0,
            "pw_a": 0,
            "pw_b": 0,
            "pw_c": 0,
            "pw_d": 0,
            "clip": ["1", 1]
        },
        "class_type": "BatchPromptSchedule",
        "_meta": {
            "title": "Batch Prompt Schedule 📅🅕🅝"
        }
    },
    "101": {
        "inputs": {
            "text": "(Masterpiece, best quality:1.2), closeup, a guy walking through forest "
        },
        "class_type": "ttN text",
        "_meta": {
            "title": "text"
        }
    },
    "102": {
        "inputs": {
            "frame_rate": 8,
            "loop_count": 0,
            "filename_prefix": "AnimateDiff",
            # 修改這裡：將影片格式從 H265 調整為 H264，並將像素格式改為 yuv420p
            "format": "video/h264-mp4",
            "pix_fmt": "yuv420p",
            "crf": 22,
            "save_metadata": True,
            "pingpong": False,
            "save_output": True,
            "images": ["10", 0]
        },
        "class_type": "VHS_VideoCombine",
        "_meta": {
            "title": "Video Combine 🎥🅥🅗🅢"
        }
    },
    "109": {
        "inputs": {
            "video": "",
            # 修改這裡：將 force_rate 從 0 改為 8，確保輸入影片幀率正確讀取
            "force_rate": 8,
            "force_size": "Disabled",
            "custom_width": 512,
            "custom_height": 512,
            "frame_load_cap": 120,
            "skip_first_frames": 0,
            "select_every_nth": 1
        },
        "class_type": "VHS_LoadVideoPath",
        "_meta": {
            "title": "Load Video (Path) 🎥🅥🅗🅢"
        }
    }
}

# ----------------------------------------------------------------------------
# Flask 路由：/generate_video2video
# ----------------------------------------------------------------------------
@app.route("/generate_video2video", methods=["POST"])
def generate_video2video():
    print("🚀 發送請求到 ComfyUI...")

    # 取得表單參數
    text = request.form.get("text", "").strip()
    if not text:
        return jsonify({"error": "請提供有效的提示詞"}), 400

    try:
        seed = int(request.form.get("seed", 0))
    except ValueError:
        seed = 0
    if seed == 0:
        seed = int(time.time() * 1000) % 1000000

    # 取得上傳的影片檔案
    video_file = request.files.get("video")
    if not video_file:
        return jsonify({"error": "請上傳影片"}), 400

    # 將上傳的影片暫存於 temp_uploads 資料夾
    temp_path = os.path.join(os.getcwd(), "temp_uploads")
    os.makedirs(temp_path, exist_ok=True)
    temp_filename = secure_filename(f"{uuid.uuid4().hex}.mp4")
    file_path = os.path.join(temp_path, temp_filename)
    video_file.save(file_path)
    print(f"✅ [後端] 接收到上傳影片並儲存於 {file_path}")

    # 更新 prompt 的短影片路徑
    prompt["109"]["inputs"]["video"] = file_path

    result = {}

    def call_comfyui():
        try:
            response = queue_prompt(prompt)
            if response is None or "prompt_id" not in response:
                result["error"] = "API 回應錯誤，請檢查 ComfyUI 設定"
                return
            prompt_id = response["prompt_id"]
            print(f"🆔 獲取 prompt_id: {prompt_id}")

            wait_for_completion(prompt_id)
            time.sleep(2)
            move_output_files(prompt_id)
            final_video_url = f"{VIDEO_BASE_URL}/get_video/{get_final_video_filename(prompt_id)}?t={int(time.time())}"
            print("影片生成成功，URL =", final_video_url)
            result["video_url"] = final_video_url
        except Exception as e:
            result["error"] = str(e)
    
    thread = threading.Thread(target=call_comfyui)
    thread.start()

    def sse_stream():
        progress = 0
        while thread.is_alive():
            msg = {"progress": progress, "message": "影片生成中..."}
            yield f"data: {json.dumps(msg)}\n\n"
            time.sleep(5)
            progress = min(progress + 10, 90)
        thread.join()
        if "video_url" in result:
            final_msg = {"progress": 100, "video_url": result["video_url"], "message": "影片生成完成！"}
            yield f"data: {json.dumps(final_msg)}\n\n"
        else:
            err = result.get("error", "未知錯誤")
            fail_msg = {"progress": 100, "error": err, "message": "影片生成失敗"}
            yield f"data: {json.dumps(fail_msg)}\n\n"

    headers = {
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
        "X-Accel-Buffering": "no",
        "Cross-Origin-Resource-Policy": "cross-origin",
        "Access-Control-Allow-Origin": "*"
    }
    return Response(sse_stream(), headers=headers, mimetype="text/event-stream")

# ----------------------------------------------------------------------------
# GET /get_video 路由：提供影片檔案
# ----------------------------------------------------------------------------
@app.route("/get_video/<path:filename>", methods=["GET"])
def get_video(filename):
    upload_dir = os.path.join(os.getcwd(), "uploaded_videos")
    file_path1 = os.path.join(upload_dir, filename)
    file_path2 = os.path.join(target_dir, filename)
    print("檢查檔案路徑：", file_path1, "或", file_path2)
    if os.path.exists(file_path1):
        response = send_from_directory(upload_dir, filename)
    elif os.path.exists(file_path2):
        response = send_from_directory(target_dir, filename)
    else:
        return jsonify({"error": "檔案不存在", "paths": [file_path1, file_path2]}), 404
    response.headers["Cross-Origin-Resource-Policy"] = "cross-origin"
    response.headers["Access-Control-Allow-Origin"] = "*"
    return response

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5010, debug=False)


=== 文生圖.py ===
import json
import os
import shutil
import time
import uuid
import urllib.request
import websocket  # 請先安裝：pip install websocket-client
from flask import Flask, request, jsonify, send_from_directory, Response
from flask_cors import CORS
from collections import OrderedDict
from werkzeug.middleware.proxy_fix import ProxyFix

app = Flask(__name__)

# -------------------------------------------------------------------
# CORS 設定：開發階段允許所有網域；正式上線時請改為限制特定網域
# -------------------------------------------------------------------
CORS(
    app,
    resources={r"/*": {"origins": "*"}},
    supports_credentials=True,
    allow_headers=["Content-Type", "Authorization", "X-Requested-With", "Accept", "Origin"],
    methods=["GET", "POST", "OPTIONS", "DELETE"]
)

# -------------------------------------------------------------------
# ProxyFix：確保 Flask 能正確讀取 Cloudflare Tunnel 傳來的標頭
# -------------------------------------------------------------------
app.wsgi_app = ProxyFix(app.wsgi_app, x_for=1, x_proto=1, x_host=1, x_port=1)

# -------------------------------------------------------------------
# 內網後端服務地址：翻譯服務及生圖服務（請根據實際環境調整）
# -------------------------------------------------------------------
TRANSLATE_SERVER = "http://172.24.11.4:5000"
BACKEND_SERVER   = "http://172.24.11.7:5000"

# -------------------------------------------------------------------
# Cloudflare Tunnel 對外提供的 HTTPS 網域（必須設定為 HTTPS）
# -------------------------------------------------------------------
IMAGE_BASE_URL = "https://api.picturesmagician.com"

# -------------------------------------------------------------------
# ComfyUI 輸出資料夾及目標資料夾（搬移檔案到此目標資料夾後供 /get_image 讀取）
# -------------------------------------------------------------------
comfyui_output_dir = r"D:\comfyui\ComfyUI_windows_portable\ComfyUI\output"
target_dir = r"D:\大模型文生圖"
os.makedirs(target_dir, exist_ok=True)

# -------------------------------------------------------------------
# 用來追蹤翻譯請求狀態的 OrderedDict
# -------------------------------------------------------------------
processing_requests = OrderedDict()


# =============================
# 與 ComfyUI 溝通的函式
# =============================

def queue_prompt(prompt):
    """
    發送工作流程 JSON 到 ComfyUI 的 /prompt API，並回傳 prompt_id 與 client_id
    """
    client_id = str(uuid.uuid4())
    payload = {"prompt": prompt, "client_id": client_id}
    data = json.dumps(payload).encode("utf-8")
    url = "http://127.0.0.1:8188/prompt"
    try:
        req = urllib.request.Request(url, data=data, headers={"Content-Type": "application/json"})
        with urllib.request.urlopen(req) as resp:
            result = json.loads(resp.read())
            result["client_id"] = client_id
            return result
    except Exception as e:
        print(f"❌ 無法連線至 ComfyUI API: {e}")
        return None

def wait_for_completion(prompt_id, client_id):
    """
    建立 WebSocket 連線等待指定 prompt_id 任務完成
    """
    ws_url = f"ws://127.0.0.1:8188/ws?clientId={client_id}"
    print("🕐 等待 ComfyUI 任務完成...")
    try:
        ws = websocket.create_connection(ws_url)
        while True:
            out = ws.recv()
            if isinstance(out, str):
                message = json.loads(out)
                if message.get("type") == "executing":
                    data = message.get("data", {})
                    if data.get("node") is None and data.get("prompt_id") == prompt_id:
                        print("✅ 任務已完成！")
                        break
        ws.close()
    except Exception as e:
        print(f"❌ WebSocket 連線錯誤: {e}")

def get_history(prompt_id):
    """
    透過 /history/<prompt_id> API 取得 ComfyUI 任務輸出紀錄
    """
    url = f"http://127.0.0.1:8188/history/{prompt_id}"
    try:
        with urllib.request.urlopen(url) as resp:
            history_data = json.loads(resp.read())
        print(f"📜 history API 回應: {json.dumps(history_data, indent=4, ensure_ascii=False)}")
        return history_data.get(prompt_id, {})
    except Exception as e:
        print(f"❌ 無法取得歷史紀錄: {e}")
        return {}

def find_latest_png():
    """
    若 /history API 沒有提供檔名，則在 comfyui_output_dir 搜尋最新的 .png 檔案
    """
    png_files = [f for f in os.listdir(comfyui_output_dir) if f.lower().endswith(".png")]
    if not png_files:
        print("🚫 找不到任何 .png 檔案！")
        return None
    latest_png = max(png_files, key=lambda f: os.path.getctime(os.path.join(comfyui_output_dir, f)))
    print(f"🎞 找到最新的 .png 檔案: {latest_png}")
    return latest_png

def get_final_image_filename(prompt_id):
    """
    從 /history/<prompt_id> 中找出最終輸出的圖片檔名，
    如未找到則使用 find_latest_png()
    """
    history = get_history(prompt_id)
    if not history:
        print("⚠️ history API 回應為空，改用檔案搜尋。")
        return find_latest_png()

    outputs = history.get("outputs", {})
    image_node = outputs.get("7", {})
    if "images" in image_node:
        for info in image_node["images"]:
            filename = info.get("filename")
            if filename and filename.lower().endswith(".png"):
                print(f"🎞 從 API 取得圖片檔名: {filename}")
                return filename

    print("⚠️ history API 未提供圖片檔名，改用檔案搜尋。")
    return find_latest_png()

def move_output_files(prompt_id):
    """
    將 comfyui_output_dir 中的圖片檔搬移到 target_dir，
    並在檔名中加入時間戳作為唯一標識
    """
    image_filename = get_final_image_filename(prompt_id)
    if not image_filename:
        print("🚫 無法取得圖片檔案名稱！")
        return None

    name, ext = os.path.splitext(image_filename)
    unique_filename = f"{name}_{int(time.time())}{ext}"
    source_path = os.path.join(comfyui_output_dir, image_filename)
    target_path = os.path.join(target_dir, unique_filename)

    if not os.path.exists(source_path):
        print(f"⚠️ 找不到來源檔案: {source_path}")
        return None

    try:
        shutil.move(source_path, target_path)
        print(f"✅ 搬移成功: {source_path} → {target_path}")
        return unique_filename
    except Exception as e:
        print(f"❌ 搬移失敗: {e}")
        return None


# =============================
# Flask 路由
# =============================

@app.route("/generate_image", methods=["POST"])
def generate_image_endpoint():
    """
    接收前端描述與參數，轉發給內網生圖服務，
    等待任務完成後搬移檔案，並回傳 HTTPS 圖片連結
    """
    data = request.json
    description = data.get("text", "").strip()
    if not description:
        return jsonify({"error": "請提供有效的描述文字"}), 400

    # ——— 新增：Checkpoint 名稱映射 ———
    checkpoint_map = {
        "anythingelseV4_v45.safetensors":               "anythingelseV4_v45.safetensors",
        "flux1-dev.safetensors":                         "flux1-dev.safetensors",
        "meanimax_v12Final.safetensors":                 "meinamix_v12Final.safetensors",        # max → mix
        "realisticVisionV51_v51VAE.safetensors":         "realisticVisionV51_v51VAE.safetensors",
        "sdxlUnstableDiffusers_nihilanth.safetensors":   "sdxlUnstableDiffusers_nihilmania.safetensors",  # anth → mania
        "sdxlYamersRealistic5_v9RunDiffusion.safetensors":"sdxlYamersRealistic5_v5Rundiffusion.safetensors"   # v9 → v5, RunDiffusion → Rundiffusion
    }
    raw_ckpt = data.get("checkpoint", "meanimax_v12Final.safetensors")
    checkpoint_name = checkpoint_map.get(raw_ckpt, raw_ckpt)
    vae_name        = data.get("vae", "kl-f8-anime2.safetensors")
    # ——————————————————————————————

    try:
        cfg_scale = int(data.get("cfg_scale", 7))
    except ValueError:
        cfg_scale = 7
    sampler_name = data.get("sampler", "euler")
    scheduler    = data.get("scheduler", "normal")
    try:
        seed = int(data.get("seed", 103))
    except ValueError:
        seed = 103

    print("🔹 收到前端參數:", data)

    # ComfyUI 工作流程 JSON 範本
    prompt_text = """
{
  "1": {
    "inputs": {"ckpt_name": "meinamix_v12Final.safetensors"},
    "class_type": "CheckpointLoaderSimple"
  },
  "2": {
    "inputs": {"text": "", "clip": ["1", 1]},
    "class_type": "CLIPTextEncode"
  },
  "3": {
    "inputs": {
      "text": "(low quality, worst quality, text, letterboxed:1.4), (deformed, distorted, disfigured:1.3), easynegative, hands, bad-hands-5, blurry, ugly, embedding:easynegative",
      "clip": ["1", 1]
    },
    "class_type": "CLIPTextEncode"
  },
  "4": {
    "inputs": {
      "seed": 440871023236812,
      "steps": 20,
      "cfg": 8,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 1,
      "model": ["1", 0],
      "positive": ["2", 0],
      "negative": ["3", 0],
      "latent_image": ["15", 0]
    },
    "class_type": "KSampler"
  },
  "7": {
    "inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]},
    "class_type": "SaveImage"
  },
  "8": {
    "inputs": {"samples": ["4", 0], "vae": ["9", 0]},
    "class_type": "VAEDecode"
  },
  "9": {
    "inputs": {"vae_name": "kl-f8-anime2.safetensors"},
    "class_type": "VAELoader"
  },
  "15": {
    "inputs": {"width": 512, "height": 512, "batch_size": 1},
    "class_type": "EmptyLatentImage"
  }
}
"""
    try:
        prompt = json.loads(prompt_text)
    except json.JSONDecodeError as e:
        return jsonify({"error": "工作流程 JSON 格式錯誤", "details": str(e)}), 500

    # ——— 把映射後的 checkpoint 與 vae 寫入 workflow JSON ———
    prompt["1"]["inputs"]["ckpt_name"] = checkpoint_name
    prompt["9"]["inputs"]["vae_name"]   = vae_name
    # ——————————————————————————————————————————————

    # 填入其它使用者參數
    prompt["2"]["inputs"]["text"]             = description
    prompt["4"]["inputs"]["cfg"]              = cfg_scale
    prompt["4"]["inputs"]["sampler_name"]     = sampler_name
    prompt["4"]["inputs"]["scheduler"]        = scheduler
    prompt["4"]["inputs"]["seed"]             = seed

    print("🚀 發送工作流程到 ComfyUI...")
    resp_data = queue_prompt(prompt)
    if not resp_data or "prompt_id" not in resp_data:
        return jsonify({"error": "ComfyUI API 回應錯誤"}), 500

    prompt_id = resp_data["prompt_id"]
    client_id = resp_data["client_id"]
    print(f"🔹 取得 prompt_id: {prompt_id}, client_id: {client_id}")

    wait_for_completion(prompt_id, client_id)
    time.sleep(5)

    print("✅ 任務完成，開始搬移圖片檔案...")
    unique_filename = move_output_files(prompt_id)
    if not unique_filename:
        return jsonify({"error": "搬移圖片失敗"}), 500

    # 回傳 HTTPS 圖片 URL
    image_url = f"{IMAGE_BASE_URL}/get_image/{unique_filename}?t={int(time.time())}"
    print("🔹 回傳圖片 URL:", image_url)
    return jsonify({"image_url": image_url})

@app.route("/get_image/<path:filename>", methods=["GET"])
def get_image(filename):
    """
    提供搬移後的圖片檔案下載或顯示。如果檔案不存在，回傳 404
    """
    file_path = os.path.join(target_dir, filename)
    if not os.path.exists(file_path):
        print(f"⚠️ 找不到檔案: {file_path}")
        return jsonify({"error": "檔案不存在"}), 404
    return send_from_directory(target_dir, filename)

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=False)


=== 文生影片.py ===
import json
import os
import shutil
import time
import uuid
import urllib.request
import websocket  # 請先安裝 websocket-client
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from werkzeug.middleware.proxy_fix import ProxyFix

app = Flask(__name__)
CORS(
    app,
    resources={r"/*": {"origins": "*"}},
    supports_credentials=True,
    allow_headers=["Content-Type", "Authorization", "X-Requested-With", "Accept", "Origin"],
    methods=["GET", "POST", "OPTIONS", "DELETE"]
)
app.wsgi_app = ProxyFix(app.wsgi_app, x_for=1, x_proto=1, x_host=1, x_port=1)

# -----------------------------
# ComfyUI 與目標資料夾設定
# -----------------------------
server_address = "127.0.0.1:8188"  # ComfyUI 伺服器位址（本機）
client_id = str(uuid.uuid4())      # 產生唯一 client ID

# ComfyUI 輸出資料夾 (影片將先產出於此)
comfyui_output_dir = "D:/comfyui/ComfyUI_windows_portable/ComfyUI/output/"
# 目標資料夾 (搬移後影片存放處)
target_dir = "D:/sd1.5_animediff_txt2video_dataset/"
os.makedirs(target_dir, exist_ok=True)

# -----------------------------
# 輔助函式
# -----------------------------
def queue_prompt(prompt):
    """發送請求到 ComfyUI /prompt API，並回傳結果"""
    p = {"prompt": prompt, "client_id": client_id}
    data = json.dumps(p).encode("utf-8")
    req = urllib.request.Request(f"http://{server_address}/prompt", data=data, headers={"Content-Type": "application/json"})
    return json.loads(urllib.request.urlopen(req).read())

def wait_for_completion(prompt_id):
    """透過 WebSocket 監聽 ComfyUI 任務進度，直到完成"""
    ws_url = f"ws://{server_address}/ws?clientId={client_id}"
    print("🕐 等待 ComfyUI 任務完成...")
    try:
        ws = websocket.create_connection(ws_url)
        while True:
            out = ws.recv()
            if isinstance(out, str):
                message = json.loads(out)
                # 當收到 "executing" 訊息，且 prompt_id 相符且沒有指定 node 時，視為完成
                if message.get("type") == "executing":
                    data = message.get("data", {})
                    if data.get("node") is None and data.get("prompt_id") == prompt_id:
                        print("✅ 任務已完成！")
                        break
        ws.close()
    except Exception as e:
        print(f"❌ WebSocket 連線錯誤: {e}")

def get_history(prompt_id):
    """從 ComfyUI /history API 取得任務輸出紀錄"""
    url = f"http://{server_address}/history/{prompt_id}"
    try:
        with urllib.request.urlopen(url) as resp:
            history_data = json.loads(resp.read())
        print(f"📜 Debug: history API 回應 = {json.dumps(history_data, indent=4)}")
        return history_data.get(prompt_id, {})
    except Exception as e:
        print(f"❌ 無法取得歷史紀錄: {e}")
        return {}

def find_latest_mp4():
    """在 ComfyUI 輸出資料夾中尋找最新的 MP4 檔案"""
    mp4_files = [f for f in os.listdir(comfyui_output_dir) if f.endswith(".mp4")]
    if not mp4_files:
        print("🚫 找不到 MP4 檔案！")
        return None
    latest_mp4 = max(mp4_files, key=lambda f: os.path.getctime(os.path.join(comfyui_output_dir, f)))
    print(f"🎬 找到最新 MP4: {latest_mp4}")
    return latest_mp4

def get_final_video_filename(prompt_id):
    """從 /history API 或檔案搜尋中取得最終 MP4 檔案名稱"""
    history = get_history(prompt_id)
    if not history:
        print("⚠️ history API 回應為空，改用檔案搜尋。")
        return find_latest_mp4()
    video_node = history.get("outputs", {}).get("52", {})
    if "gifs" in video_node:
        for video in video_node["gifs"]:
            print(f"🎬 Found video from API: {video['filename']}")
            if video["filename"].endswith(".mp4"):
                return video["filename"]
    print("⚠️ API 未找到 MP4，改用檔案搜尋。")
    return find_latest_mp4()

def move_output_files(prompt_id):
    """將生成的 MP4 檔案從 ComfyUI 輸出資料夾搬移到目標資料夾"""
    mp4_filename = get_final_video_filename(prompt_id)
    if not mp4_filename:
        print("🚫 無法獲取 MP4 檔案名稱！")
        return None
    source_path = os.path.join(comfyui_output_dir, mp4_filename)
    target_path = os.path.join(target_dir, mp4_filename)
    if not os.path.exists(source_path):
        print(f"⚠️ 找不到 {source_path}，無法搬移！")
        return None
    try:
        shutil.move(source_path, target_path)
        print(f"✅ 已搬移: {source_path} → {target_path}")
        return mp4_filename
    except Exception as e:
        print(f"❌ 搬移失敗: {e}")
        return None

# -----------------------------
# 工作流程 JSON (影片生成) - 以 animediff_1.5 為基底
# -----------------------------
prompt_text = """
{
  "2": {
    "inputs": {
      "vae_name": "kl-f8-anime2.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "VAE載入器"
    }
  },
  "4": {
    "inputs": {
      "stop_at_clip_layer": -1,
      "clip": [
        "22",
        1
      ]
    },
    "class_type": "CLIPSetLastLayer",
    "_meta": {
      "title": "CLIP設定停止層"
    }
  },
  "7": {
    "inputs": {
      "seed": 1079132525953378,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "euler",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "20",
        0
      ],
      "positive": [
        "88",
        0
      ],
      "negative": [
        "69",
        0
      ],
      "latent_image": [
        "9",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "K採樣器"
    }
  },
  "9": {
    "inputs": {
      "width": 512,
      "height": 512,
      "batch_size": 32
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "空Latent"
    }
  },
  "10": {
    "inputs": {
      "samples": [
        "7",
        0
      ],
      "vae": [
        "2",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE解碼"
    }
  },
  "13": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": 1.5,
      "samples": [
        "7",
        0
      ]
    },
    "class_type": "LatentUpscaleBy",
    "_meta": {
      "title": "Latent按係數縮放"
    }
  },
  "14": {
    "inputs": {
      "seed": 1079132525953378,
      "steps": 30,
      "cfg": 6.5,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 0.6,
      "model": [
        "20",
        0
      ],
      "positive": [
        "88",
        0
      ],
      "negative": [
        "69",
        0
      ],
      "latent_image": [
        "13",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "K採樣器"
    }
  },
  "20": {
    "inputs": {
      "model_name": "mm_sd_v15.ckpt",
      "beta_schedule": "sqrt_linear (AnimateDiff)",
      "motion_scale": 1.1,
      "apply_v2_models_properly": true,
      "model": [
        "22",
        0
      ],
      "context_options": [
        "25",
        0
      ]
    },
    "class_type": "ADE_AnimateDiffLoaderWithContext",
    "_meta": {
      "title": "AnimateDiff Loader [Legacy] 🎭🅐🅓①"
    }
  },
  "22": {
    "inputs": {
      "ckpt_name": "meinamix_v12Final.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Checkpoint載入器(簡易)"
    }
  },
  "25": {
    "inputs": {
      "context_length": 16,
      "context_stride": 1,
      "context_overlap": 8,
      "context_schedule": "uniform",
      "closed_loop": false,
      "fuse_method": "pyramid",
      "use_on_equal_length": false,
      "start_percent": 0,
      "guarantee_steps": 1
    },
    "class_type": "ADE_AnimateDiffUniformContextOptions",
    "_meta": {
      "title": "Context Options◆Looped Uniform 🎭🅐🅓"
    }
  },
  "45": {
    "inputs": {
      "frame_rate": 8,
      "loop_count": 0,
      "filename_prefix": "txt2video_animediff_api_gen",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": true,
      "trim_to_audio": false,
      "pingpong": false,
      "save_output": true,
      "images": [
        "10",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine 🎥🅥🅗🅢"
    }
  },
  "46": {
    "inputs": {
      "samples": [
        "14",
        0
      ],
      "vae": [
        "2",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE解碼"
    }
  },
  "49": {
    "inputs": {
      "strength": 1,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "88",
        0
      ],
      "negative": [
        "69",
        0
      ],
      "control_net": [
        "54",
        0
      ],
      "image": [
        "71",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "ControlNet應用(進階)"
    }
  },
  "50": {
    "inputs": {
      "seed": 1079132525953378,
      "steps": 30,
      "cfg": 6.5,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 0.6,
      "model": [
        "20",
        0
      ],
      "positive": [
        "49",
        0
      ],
      "negative": [
        "49",
        1
      ],
      "latent_image": [
        "61",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "K採樣器"
    }
  },
  "51": {
    "inputs": {
      "samples": [
        "50",
        0
      ],
      "vae": [
        "2",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE解碼"
    }
  },
  "52": {
    "inputs": {
      "frame_rate": 8,
      "loop_count": 0,
      "filename_prefix": "txt2video_animediff_api_gen",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": true,
      "trim_to_audio": false,
      "pingpong": false,
      "save_output": true,
      "images": [
        "51",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine 🎥🅥🅗🅢"
    }
  },
  "54": {
    "inputs": {
      "control_net_name": "control_sd15_canny.pth",
      "tk_optional": [
        "56",
        1
      ]
    },
    "class_type": "ControlNetLoaderAdvanced",
    "_meta": {
      "title": "ControlNet載入器(進階)"
    }
  },
  "56": {
    "inputs": {
      "base_multiplier": 0.825,
      "flip_weights": false,
      "uncond_multiplier": 1
    },
    "class_type": "ScaledSoftControlNetWeights",
    "_meta": {
      "title": "縮放柔和ControlNet權重"
    }
  },
  "61": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": 1.5,
      "samples": [
        "7",
        0
      ]
    },
    "class_type": "LatentUpscaleBy",
    "_meta": {
      "title": "Latent按係數縮放"
    }
  },
  "69": {
    "inputs": {
      "text": "(low quality, nsfw, worst quality, text, letterboxed:1.4), (deformed, distorted, disfigured:1.3), easynegative, hands, bad-hands-5, blurry, ugly, embedding:easynegative",
      "clip": [
        "4",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP文本編碼器"
    }
  },
  "71": {
    "inputs": {
      "resolution": 512,
      "image": [
        "46",
        0
      ]
    },
    "class_type": "AnimeLineArtPreprocessor",
    "_meta": {
      "title": "AnimeLineArt動漫線稿預處理器"
    }
  },
  "88": {
    "inputs": {
      "text": "a girl dance",
      "clip": [
        "4",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP文本編碼器"
    }
  }
}
"""

@app.route("/generate_video", methods=["POST"])
def generate_video_endpoint():
    """
    接收前端傳來的影片生成請求，
    根據描述與參數組合工作流程 JSON，
    呼叫 ComfyUI 產生影片，
    搬移生成的 MP4 檔案，
    並回傳對外 HTTPS 影片 URL。
    """
    data = request.json
    description = data.get("text", "").strip()
    if not description:
        return jsonify({"error": "請提供有效的描述文字"}), 400

    try:
        duration = int(data.get("duration", 4))
    except ValueError:
        duration = 4
    try:
        frame_rate = int(data.get("frame_rate", 8))
    except ValueError:
        frame_rate = 8
    try:
        seed = int(data.get("seed", 103))
    except ValueError:
        seed = 103

    # 更新影片生成的工作流程參數
    try:
        prompt = json.loads(prompt_text)
    except json.JSONDecodeError as e:
        return jsonify({"error": "工作流程 JSON 格式錯誤", "details": str(e)}), 500

    # 使用翻譯後的描述作為提示詞
    prompt["88"]["inputs"]["text"] = description
    prompt["7"]["inputs"]["cfg"] = 7
    prompt["7"]["inputs"]["sampler_name"] = "euler"
    prompt["7"]["inputs"]["scheduler"] = "karras"
    prompt["9"]["inputs"]["batch_size"] = duration * frame_rate
    prompt["20"]["inputs"]["model_name"] = "mm_sd_v15.ckpt"
    prompt["54"]["inputs"]["model_name"] = "control_sd15_canny.pth"
    prompt["7"]["inputs"]["seed"] = seed

    print("🚀 發送工作流程到 ComfyUI...")
    resp_data = queue_prompt(prompt)
    if not resp_data or "prompt_id" not in resp_data:
        return jsonify({"error": "ComfyUI API 回應錯誤"}), 500

    prompt_id = resp_data["prompt_id"]
    print(f"🔹 取得 prompt_id: {prompt_id}")

    wait_for_completion(prompt_id)
    time.sleep(5)  # 視情況調整等待時間

    print("✅ 任務完成，開始搬移影片檔案...")
    mp4_filename = move_output_files(prompt_id)
    if not mp4_filename:
        return jsonify({"error": "搬移影片失敗"}), 500

    video_url = f"https://textvideo.picturesmagician.com/get_video/{mp4_filename}?t={int(time.time())}"
    print("🔹 回傳影片 URL:", video_url)
    return jsonify({"video_url": video_url})

@app.route("/get_video/<path:filename>", methods=["GET"])
def get_video(filename):
    file_path = os.path.join(target_dir, filename)
    if not os.path.exists(file_path):
        return jsonify({"error": "檔案不存在"}), 404
    return send_from_directory(target_dir, filename)

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5008, debug=False)


=== 線稿上色.py ===
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import shutil
import time
import uuid
import base64
import urllib.request
import websocket  # 請先安裝 websocket-client: pip install websocket-client
from flask import Flask, request, jsonify, send_from_directory, make_response
from flask_cors import CORS

app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}})

# ----------------------------
# 檢查點到 ControlNet 的對應表
# ----------------------------
CHECKPOINT_TO_CONTROLNET = {
    "anythingelseV4_v45.safetensors":                "sd1.5_lineart.safetensors",
    "meinamix_v12Final.safetensors":                 "sd1.5_lineart.safetensors",
    "sdxlUnstableDiffusers_nihilmania.safetensors":  "sdxl_canny.safetensors",
    "sdxlYamersRealistic5_v5Rundiffusion.safetensor": "sdxl_canny.safetensors",
}
DEFAULT_CONTROLNET = "control_sd15_canny.pth"

# ----------------------------
# 文生模式工作流程 JSON (完整，未省略任何節點)
# ----------------------------
text_workflow_json = r"""
{
  "1": {
    "inputs": {
      "ckpt_name": "meinamix_v12Final.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {"title": "Checkpoint載入器(簡易)"}
  },
  "2": {
    "inputs": {
      "text": "1girl, solo, long_hair, breasts, looking_at_viewer, blush, open_mouth, bangs, blue_eyes, simple_background, long_sleeves, white_background, bow, jewelry, upper_body, white_hair, hair_bow, earrings, parted_lips, two_side_up, black_bow, hair_intakes",
      "clip": ["1", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {"title": "CLIP文本編碼器"}
  },
  "3": {
    "inputs": {
      "text": "mutated hands \\nfingers, deformed,bad\\nanatomy,disfigured,poorly drawn\\nface,mutated,extra\\nlimb,ugly,poorly drawn\\nhands,missing limb,floating\\nlimbs,disconnected\\nlimbs,malformed hands,out of\\nfocus,long neck,long body,\\n",
      "clip": ["1", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {"title": "CLIP文本編碼器"}
  },
  "4": {
    "inputs": {
      "seed": 595055991379893,
      "steps": 20,
      "cfg": 8,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 1,
      "model": ["1", 0],
      "positive": ["18", 0],
      "negative": ["18", 1],
      "latent_image": ["48", 0]
    },
    "class_type": "KSampler",
    "_meta": {"title": "K採樣器"}
  },
  "7": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": ["8", 0]
    },
    "class_type": "SaveImage",
    "_meta": {"title": "儲存圖像"}
  },
  "8": {
    "inputs": {
      "samples": ["4", 0],
      "vae": ["9", 0]
    },
    "class_type": "VAEDecode",
    "_meta": {"title": "VAE解碼"}
  },
  "9": {
    "inputs": {
      "vae_name": "kl-f8-anime2.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {"title": "VAE載入器"}
  },
  "18": {
    "inputs": {
      "strength": 1.5,
      "start_percent": 0,
      "end_percent": 1,
      "positive": ["2", 0],
      "negative": ["3", 0],
      "control_net": ["19", 0],
      "image": ["47", 0],
      "vae": ["9", 0]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {"title": "ControlNet應用(進階)"}
  },
  "19": {
    "inputs": {
      "control_net_name": "control_sd15_canny.pth"
    },
    "class_type": "ControlNetLoader",
    "_meta": {"title": "ControlNet載入器"}
  },
  "47": {
    "inputs": {
      "low_threshold": 100,
      "high_threshold": 200,
      "resolution": 512,
      "image": ["49", 0]
    },
    "class_type": "CannyEdgePreprocessor",
    "_meta": {"title": "Canny線條預處理器"}
  },
  "48": {
    "inputs": {
      "width": 512,
      "height": 512,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {"title": "空Latent"}
  },
  "49": {
    "inputs": {
      "image_path": ""
    },
    "class_type": "ZwngLoadImagePathOrURL",
    "_meta": {"title": "Load 輔助線稿圖(圖生)"}
  },
  "50": {
    "inputs": {
      "images": ["49", 0]
    },
    "class_type": "PreviewImage",
    "_meta": {"title": "預覽輔助線稿"}
  }
}
"""

# ----------------------------
# 圖生模式 Workflow JSON (完整，未省略任何節點)
#  其中節點 48: EmptyLatentImage
#       節點 51: Load 主線稿圖
# ----------------------------
image_workflow_json = r"""
{
  "1": {
    "inputs": {
      "ckpt_name": "meinamix_v12Final.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {"title": "Checkpoint載入器(簡易)"}
  },
  "2": {
    "inputs": {
      "text": "example prompt",
      "clip": ["1", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {"title": "CLIP文本編碼器"}
  },
  "3": {
    "inputs": {
      "text": "mutated hands \\nfingers, deformed,bad\\nanatomy,disfigured,poorly drawn\\nface,mutated,extra\\nlimb,ugly,poorly drawn\\nhands,missing limb,floating\\nlimbs,disconnected\\nlimbs,malformed hands,out of\\nfocus,long neck,long body,\\n",
      "clip": ["1", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {"title": "CLIP文本編碼器"}
  },
  "4": {
    "inputs": {
      "seed": 595055991379893,
      "steps": 20,
      "cfg": 8,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 1,
      "model": ["1", 0],
      "positive": ["18", 0],
      "negative": ["18", 1],
      "latent_image": ["48", 0]
    },
    "class_type": "KSampler",
    "_meta": {"title": "K採樣器"}
  },
  "7": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": ["8", 0]
    },
    "class_type": "SaveImage",
    "_meta": {"title": "儲存圖像"}
  },
  "8": {
    "inputs": {
      "samples": ["4", 0],
      "vae": ["9", 0]
    },
    "class_type": "VAEDecode",
    "_meta": {"title": "VAE解碼"}
  },
  "9": {
    "inputs": {
      "vae_name": "kl-f8-anime2.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {"title": "VAE載入器"}
  },
  "18": {
    "inputs": {
      "strength": 1.5,
      "start_percent": 0,
      "end_percent": 1,
      "positive": ["2", 0],
      "negative": ["3", 0],
      "control_net": ["19", 0],
      "image": ["47", 0],
      "vae": ["9", 0]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {"title": "ControlNet應用(進階)"}
  },
  "19": {
    "inputs": {
      "control_net_name": "control_sd15_canny.pth"
    },
    "class_type": "ControlNetLoader",
    "_meta": {"title": "ControlNet載入器"}
  },
  "47": {
    "inputs": {
      "low_threshold": 100,
      "high_threshold": 200,
      "resolution": 512,
      "image": ["49", 0]
    },
    "class_type": "CannyEdgePreprocessor",
    "_meta": {"title": "Canny線條預處理器"}
  },
  "48": {
    "inputs": {
      "width": 512,
      "height": 512,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {"title": "空Latent"}
  },
  "49": {
    "inputs": {
      "image_path": ""
    },
    "class_type": "ZwngLoadImagePathOrURL",
    "_meta": {"title": "Load 輔助線稿圖(圖生)"}
  },
  "50": {
    "inputs": {
      "images": ["49", 0]
    },
    "class_type": "PreviewImage",
    "_meta": {"title": "預覽輔助線稿"}
  },
  "51": {
    "inputs": {
      "image_path": ""
    },
    "class_type": "ZwngLoadImagePathOrURL",
    "_meta": {"title": "Load 主線稿圖(圖生)"}
  }
}
"""

# ----------------------------
# ComfyUI 伺服器與資料夾設定
# ----------------------------
server_address     = "127.0.0.1:8188"
comfyui_output_dir = r"D:\comfyui\ComfyUI_windows_portable\ComfyUI\output"
target_dir_text    = r"D:\大模型文生線稿上色圖"
target_dir_image   = r"D:\大模型圖生線稿上色圖"
TEMP_IMAGE_DIR     = r"D:\comfyui\temp_images"
EXTERNAL_API_URL   = "https://linecolor.picturesmagician.com"

for d in (target_dir_text, target_dir_image, TEMP_IMAGE_DIR):
    os.makedirs(d, exist_ok=True)

# ----------------------------
# 輔助函式
# ----------------------------
def queue_prompt(workflow_dict):
    client_id = str(uuid.uuid4())
    payload   = {"prompt": workflow_dict, "client_id": client_id}
    data      = json.dumps(payload).encode("utf-8")
    req = urllib.request.Request(
        f"http://{server_address}/prompt",
        data=data,
        headers={"Content-Type":"application/json"}
    )
    with urllib.request.urlopen(req, timeout=60) as resp:
        result = json.loads(resp.read().decode("utf-8"))
        result["client_id"] = client_id
        return result

def wait_for_completion(prompt_id, client_id):
    ws = websocket.create_connection(f"ws://{server_address}/ws?clientId={client_id}", timeout=60)
    while True:
        msg = ws.recv()
        m = json.loads(msg) if isinstance(msg, str) else {}
        if m.get("type") == "executing":
            d = m.get("data", {})
            if d.get("prompt_id") == prompt_id and d.get("node") is None:
                break
    ws.close()

def find_latest_png(directory):
    pngs = [f for f in os.listdir(directory) if f.lower().endswith(".png")]
    return max(pngs, key=lambda fn: os.path.getctime(os.path.join(directory, fn))) if pngs else None

def get_final_image_filename(prompt_id):
    url = f"http://{server_address}/history/{prompt_id}"
    with urllib.request.urlopen(url, timeout=30) as resp:
        hist = json.loads(resp.read().decode("utf-8")).get(prompt_id, {})
    for nid in ("7",):
        for info in hist.get("outputs", {}).get(nid, {}).get("images", []):
            fn = info.get("filename")
            if fn and fn.lower().endswith(".png"):
                return fn
    return find_latest_png(comfyui_output_dir)

def move_output_files(prompt_id, target_folder):
    fn = get_final_image_filename(prompt_id)
    if not fn:
        return None
    src = os.path.join(comfyui_output_dir, fn)
    suffix = prompt_id.replace("-", "")[:8]
    new_fn = f"{suffix}_{fn}"
    dst = os.path.join(target_folder, new_fn)
    shutil.move(src, dst)
    return new_fn

def apply_cn(workflow, cn):
    if "18" in workflow:
        inp = workflow["18"]["inputs"]
        inp["strength"]      = float(cn.get("strength", 1.5))
        inp["start_percent"] = float(cn.get("start_percent", 1.0))
        inp["end_percent"]   = float(cn.get("end_percent", 1.0))
    return workflow

# ----------------------------
# 文生模式路由
# ----------------------------
@app.route("/lineart_color_text", methods=["POST"])
def lineart_color_text():
    data = request.get_json()
    print("Received /lineart_color_text parameters:")
    for k, v in data.items():
        print(f"  {k}: {v}")

    if not data or "prompt" not in data:
        return jsonify({"error":"缺少提示詞"}), 400

    try:
        b64 = data["line_art_image"].split(",", 1)[1]
        img = base64.b64decode(b64)
        fn  = f"lineart_{uuid.uuid4().hex}.png"
        path= os.path.join(TEMP_IMAGE_DIR, fn)
        with open(path, "wb") as f:
            f.write(img)
        data["line_art_image"] = path
    except Exception as e:
        return jsonify({"error":f"線稿圖解碼失敗: {e}"}), 400

    wf = json.loads(text_workflow_json)

    # 區分 checkpoint / vae
    if data.get("ckpt_name"):
        wf["1"]["inputs"]["ckpt_name"] = data["ckpt_name"]
    if data.get("vae_name"):
        wf["9"]["inputs"]["vae_name"]  = data["vae_name"]

    # 其他參數
    wf["2"]["inputs"]["text"]         = data["prompt"]
    wf["4"]["inputs"]["cfg"]          = int(data.get("cfg_scale", 8))
    wf["4"]["inputs"]["sampler_name"] = data.get("sampler", "euler")
    wf["4"]["inputs"]["scheduler"]    = data.get("scheduler", "normal")
    wf["4"]["inputs"]["seed"]         = int(data.get("seed", 0))
    wf["4"]["inputs"]["denoise"]      = float(data.get("denoise_strength", 1.0))
    wf["47"]["inputs"]["low_threshold"]  = int(data.get("low_threshold", 100))
    wf["47"]["inputs"]["high_threshold"] = int(data.get("high_threshold", 200))

    # 自動對應 ControlNetLoader 節點 (19)
    selected_ckpt = data.get("ckpt_name", "")
    cn_name = CHECKPOINT_TO_CONTROLNET.get(selected_ckpt, DEFAULT_CONTROLNET)
    wf["19"]["inputs"]["control_net_name"] = cn_name

    wf["49"]["inputs"]["image_path"] = data["line_art_image"]

    if data.get("control_net_params"):
        wf = apply_cn(wf, data["control_net_params"])

    print("🚀 文生模式發送中…")
    resp = queue_prompt(wf)
    if not resp or "prompt_id" not in resp:
        return jsonify({"error":"ComfyUI 回應異常"}), 500

    pid, cid = resp["prompt_id"], resp["client_id"]
    wait_for_completion(pid, cid)
    fn = move_output_files(pid, target_dir_text)
    if not fn:
        return jsonify({"error":"搬檔失敗"}), 500

    url = f"{EXTERNAL_API_URL}/get_image/{fn}?t={int(time.time())}"
    return jsonify({"image_url": url})

# ----------------------------
# 圖生模式路由
# ----------------------------
@app.route("/lineart_color_image", methods=["POST"])
def lineart_color_image():
    data = request.get_json()
    print("Received /lineart_color_image parameters:")
    for k, v in data.items():
        print(f"  {k}: {v}")

    if not data or "prompt" not in data or "image" not in data:
        return jsonify({"error":"缺少提示詞或主圖"}), 400

    try:
        b64 = data["image"].split(",", 1)[1]
        img = base64.b64decode(b64)
        fn  = f"main_{uuid.uuid4().hex}.png"
        path= os.path.join(TEMP_IMAGE_DIR, fn)
        with open(path, "wb") as f:
            f.write(img)
        data["image"] = path
    except Exception as e:
        return jsonify({"error":f"主圖解碼失敗: {e}"}), 400

    if data.get("line_art_image"):
        try:
            b64 = data["line_art_image"].split(",", 1)[1]
            img = base64.b64decode(b64)
            fn  = f"aux_{uuid.uuid4().hex}.png"
            ap  = os.path.join(TEMP_IMAGE_DIR, fn)
            with open(ap, "wb") as f:
                f.write(img)
            data["line_art_image"] = ap
        except Exception as e:
            return jsonify({"error":f"輔助線稿解碼失敗: {e}"}), 400
    else:
        data["line_art_image"] = data["image"]

    wf = json.loads(image_workflow_json)

    # 區分 checkpoint / vae
    if data.get("ckpt_name"):
        wf["1"]["inputs"]["ckpt_name"] = data["ckpt_name"]
    if data.get("vae_name"):
        wf["9"]["inputs"]["vae_name"]  = data["vae_name"]

    # 其他參數
    wf["2"]["inputs"]["text"]         = data["prompt"]
    wf["4"]["inputs"]["cfg"]          = int(data.get("cfg_scale", 8))
    wf["4"]["inputs"]["sampler_name"] = data.get("sampler", "euler")
    wf["4"]["inputs"]["scheduler"]    = data.get("scheduler", "normal")
    wf["4"]["inputs"]["seed"]         = int(data.get("seed", 0))
    wf["4"]["inputs"]["denoise"]      = float(data.get("denoise_strength", 1.0))
    wf["47"]["inputs"]["low_threshold"]  = int(data.get("low_threshold", 100))
    wf["47"]["inputs"]["high_threshold"] = int(data.get("high_threshold", 200))

    # 自動對應 ControlNetLoader 節點 (19)
    selected_ckpt = data.get("ckpt_name", "")
    cn_name = CHECKPOINT_TO_CONTROLNET.get(selected_ckpt, DEFAULT_CONTROLNET)
    wf["19"]["inputs"]["control_net_name"] = cn_name

    wf["49"]["inputs"]["image_path"] = data["line_art_image"]
    wf["51"]["inputs"]["image_path"] = data["image"]

    if data.get("control_net_params"):
        wf = apply_cn(wf, data["control_net_params"])

    print("🚀 圖生模式發送中…")
    resp = queue_prompt(wf)
    if not resp or "prompt_id" not in resp:
        return jsonify({"error":"ComfyUI 回應異常"}), 500

    pid, cid = resp["prompt_id"], resp["client_id"]
    wait_for_completion(pid, cid)
    fn = move_output_files(pid, target_dir_image)
    if not fn:
        return jsonify({"error":"搬檔失敗"}), 500

    url = f"{EXTERNAL_API_URL}/get_image/{fn}?t={int(time.time())}"
    return jsonify({"image_url": url})

# ----------------------------
# 圖片代理 API & 啟動服務
# ----------------------------
@app.route("/get_image/<path:filename>", methods=["GET"])
def get_image(filename):
    t = os.path.join(target_dir_text, filename)
    i = os.path.join(target_dir_image, filename)
    if os.path.exists(t):
        resp = make_response(send_from_directory(target_dir_text, filename))
    elif os.path.exists(i):
        resp = make_response(send_from_directory(target_dir_image, filename))
    else:
        return jsonify({"error":"檔案不存在"}), 404
    resp.headers.update({
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache"
    })
    return resp

if __name__ == "__main__":
    # 開發測試用，正式部署請改用 gunicorn/uwsgi
    app.run(host="0.0.0.0", port=5006, debug=False)


